---
title: 2022-Intent Contrastive Learning for Sequential Recommendation
description:
date: 2022-05-25
categories:
 - WWW
tags:
 - CL
 - Graph
 - Rec
 - Sequential
 - EM
excerpt_separator: <!--more--> 
---

## æ‘˜è¦

ç”¨æˆ·çš„æ½œåœ¨æ„å›¾ï¼ˆlatent intentsï¼‰å¯¹äºåºåˆ—æ¨èæ¨¡å‹ï¼ˆSRï¼‰æ˜¯ä¸ªæŒ‘æˆ˜ã€‚**ä½œè€…è°ƒæŸ¥æ½œåœ¨æ„å›¾çš„å¥½å¤„å¹¶æœ‰æ•ˆåˆ©ç”¨å®ƒä»¬è¿›è¡Œåºåˆ—æ¨èï¼Œæå‡ºICLï¼Œä¸€ç§åœ¨åºåˆ—æ¨¡å‹ä¸­åˆ©ç”¨æ½œåœ¨æ„å›¾å˜é‡çš„ä¸€èˆ¬å­¦ä¹ èŒƒå¼ã€‚**å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ä»æœªæ ‡è®°çš„ç”¨æˆ·è¡Œä¸ºåºåˆ—ä¸­å­¦ä¹ ç”¨æˆ·æ„å›¾åˆ†å¸ƒå‡½æ•°ï¼Œå¹¶é€šè¿‡è€ƒè™‘å­¦ä¹ åˆ°çš„æ„å›¾ï¼Œä½¿ç”¨å¯¹æ¯”è‡ªç›‘ç£å­¦ä¹ (SSL)ä¼˜åŒ–SRæ¨¡å‹æ¥æ”¹è¿›æ¨èã€‚å…·ä½“æ¥è¯´ï¼Œä½œè€…**å¼•å…¥ä¸€ä¸ªæ½œåœ¨å˜é‡æ¥è¡¨ç¤ºç”¨æˆ·æ„å›¾**ï¼Œå¹¶é€šè¿‡**èšç±»**æ¥å­¦ä¹ æ½œåœ¨å˜é‡çš„åˆ†å¸ƒå‡½æ•°ã€‚ä½œè€…å»ºè®®é€šè¿‡å¯¹æ¯”SSLå°†å­¦ä¹ åˆ°çš„æ„å›¾åˆ©ç”¨åˆ°SRæ¨¡å‹ä¸­ï¼Œè¿™å°†**æœ€å¤§åŒ–åºåˆ—è§†å›¾ä¸å…¶ç›¸åº”æ„å›¾ä¹‹é—´çš„ä¸€è‡´æ€§**ã€‚è®­ç»ƒåœ¨æ„å›¾è¡¨ç¤ºå­¦ä¹ å’Œå¹¿ä¹‰æœŸæœ›æœ€å¤§åŒ–(**EM**)æ¡†æ¶å†…çš„SRæ¨¡å‹ä¼˜åŒ–æ­¥éª¤ä¹‹é—´äº¤æ›¿è¿›è¡Œã€‚å°†ç”¨æˆ·æ„å›¾ä¿¡æ¯èåˆåˆ°SRä¸­ä¹Ÿæé«˜äº†æ¨¡å‹çš„é²æ£’æ€§ã€‚<!--more-->

![title](https://sunjc911.github.io/assets/images/ICL/title.png)

## ä»‹ç»

é¡ºåºæ¨èçš„ç›®çš„æ˜¯é€šè¿‡å¯¹ç”¨æˆ·è¿‡å»çš„è¡Œä¸ºåºåˆ—å»ºæ¨¡ï¼Œå‡†ç¡®åœ°æè¿°ç”¨æˆ·çš„åŠ¨æ€å…´è¶£ã€‚ä½†æ˜¯**æ¶ˆè´¹è¡Œä¸ºå¯èƒ½ä¼šå—åˆ°å…¶ä»–æ½œåœ¨å› ç´ å½±å“ã€‚è¿™ä¿ƒä½¿æˆ‘ä»¬æŒ–æ˜ç”¨æˆ·å…±äº«çš„æ½œåœ¨æ„å›¾ï¼Œå¹¶ä½¿ç”¨å­¦ä¹ åˆ°çš„æ„å›¾æ¥æŒ‡å¯¼ç³»ç»Ÿæä¾›å»ºè®®ã€‚**

ç°å­˜çš„å·¥ä½œéœ€è¦è¾…åŠ©ä¿¡æ¯ï¼ˆside informationï¼‰æ¥æ„å»ºç”¨æˆ·æ„å›¾æ¨¡å‹ï¼Œä½†è¿™äº›ä¿¡æ¯ä¸èƒ½ä¸€ç›´å¯ç”¨ï¼›æˆ–æ ¹æ®ç‰©å“åˆ†ç±»ä¿¡æ¯ï¼Œä½†åˆ†ç±»ä¿¡æ¯ä¸èƒ½å‡†ç¡®è¡¨è¾¾ç”¨æˆ·æ„å›¾ï¼›æˆ–æ ¹æ®å•ä¸ªç”¨æˆ·çš„æ„å›¾è®­ç»ƒï¼Œä½†å¿½è§†äº†ä¸ç”¨ç”¨æˆ·æ½œåœ¨æ„å›¾çš„ç›¸å…³æ€§ã€‚

ä»ç”¨æˆ·è¡Œä¸ºä¸­æœ‰æ•ˆåœ°å»ºæ¨¡æ½œåœ¨æ„å›¾æå‡ºäº†**ä¸¤ä¸ªæŒ‘æˆ˜**ã€‚é¦–å…ˆï¼Œ**æ²¡æœ‰ç”¨æˆ·æ„å›¾çš„æ ‡ç­¾æ•°æ®**ï¼Œå”¯ä¸€æ•°æ®å°±æ˜¯äº¤äº’æ•°æ®ï¼Œä½†ä¸ç”¨è¡Œä¸ºå¯èƒ½å…·æœ‰ç›¸åŒçš„æ½œåœ¨æ„å›¾ã€‚ç¬¬äºŒï¼Œéœ€è¦æ½œåœ¨æ„å›¾å˜é‡å’Œåºåˆ—embedding**æ­£äº¤**ï¼Œä¸ç„¶ä¼šäº§ç”Ÿå†—ä½™ä¿¡æ¯ã€‚

**é’ˆå¯¹æŒ‘æˆ˜ï¼Œæå‡ºICLï¼Œå¼•å…¥å˜é‡è¡¨ç¤ºæ½œåœ¨æ„å›¾ï¼Œèšç±»è¯¥å˜é‡æ¥å­¦ä¹ æ½œåœ¨å˜é‡çš„åˆ†å¸ƒå‡½æ•°ã€‚å¯¹æ¯”å­¦ä¹ æœ€å¤§åŒ–åºåˆ—å’Œæ½œåœ¨æ„å›¾çš„ä¸€è‡´æ€§å’Œæœ€å¤§åŒ–æ•°æ®å¢å¼ºçš„ä¸€è‡´æ€§ã€‚ä½¿ç”¨EMç®—æ³•äº¤æ›¿æ›´æ–°åˆ†å¸ƒå‡½æ•°å’Œå‚æ•°ã€‚**

## é¢„å¤‡çŸ¥è¯†

### **EMç®—æ³•**

https://mp.weixin.qq.com/s/Rk-F9QZxh-hCDDpdfw6k9g

### é—®é¢˜å®šä¹‰

å¸¸è§„å®šä¹‰ï¼Œåºåˆ—é•¿åº¦å¤šé€€å°‘è¡¥ã€‚ç›®çš„æ˜¯é¢„æµ‹next itemã€‚

### Deep SR Models for Next Item Prediction

ä¸ºäº†ä¸å¤±å»æ™®é€‚æ€§ï¼Œå®šä¹‰ä¸€ä¸ªåºåˆ—ç¼–ç å™¨$$f_{\theta}(\cdot)$$ç¼–ç ä¸€ä¸ªåºåˆ—$$\mathrm{S}^{u}$$ï¼Œè¾“å‡ºç”¨æˆ·å…¨æ—¶åˆ»å…´è¶£è¡¨ç¤º$$\mathrm{H}^{u}=f_{\theta}\left(\mathrm{S}^{u}\right)$$ã€‚ç›®æ ‡å¯å®šåˆ¶ä¸ºå¯»æ‰¾æœ€ä¼˜ç¼–ç å™¨å‚æ•°$$\theta$$æœ€å¤§åŒ–åœ¨å…¨æ—¶åˆ»ä¸Šç»™å®šğ‘ä¸ªåºåˆ—ä¸‹ä¸€é¡¹çš„å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼š


$$
\theta^{*}=\underset{\theta}{\arg \max } \sum_{u=1}^{N} \sum_{t=2}^{T} \ln P_{\theta}\left(s_{t}^{u}\right)
$$


ç­‰ä»·äºæœ€å°åŒ–adaptedäºŒå…ƒäº¤å‰ç†µ(BCE)æŸå¤±ï¼š


$$
\begin{gathered}
\mathcal{L}_{\text {NextItem }}=\sum_{u=1}^{N} \sum_{t=2}^{T} \mathcal{L}_{\text {NextItem }}(u, t), \\
\\
\mathcal{L}_{\text {NextItem }}(u, t)=-\log \left(\sigma\left(\mathbf{h}_{t-1}^{u} \cdot \mathrm{s}_{t}^{u}\right)\right)-\sum_{n e g} \log \left(1-\sigma\left(\mathbf{h}_{t-1}^{u} \cdot \mathrm{s}_{n e g}^{u}\right)\right),
\end{gathered}
$$


è´Ÿæ ·æœ¬åŠ æƒåºŸç®—åŠ›ï¼Œæ ¹æ®æ–‡çŒ®ä½¿ç”¨æŠ½æ ·softmaxæŠ€æœ¯ï¼Œåœ¨æ¯ä¸ªåºåˆ—çš„æ¯ä¸ªæ—¶åˆ»éšæœºé€‰ä¸€ä¸ªè´Ÿæ ·æœ¬ï¼Œ$$\sigma$$æ˜¯sigmoidã€‚

### Contrastive SSL in SR


$$
\tilde{S}_{1}^{u}=g_{1}^{u}\left(S^{u}\right), \tilde{S}_{2}^{u}=g_{2}^{u}\left(S^{u}\right) \text {, s.t. } g_{1}^{u}, g_{2}^{u} \sim \mathcal{G}
$$


$$\mathcal{G}$$ä¸ºæ•°æ®è½¬æ¢å‡½æ•°é›†ï¼Œg1å’Œg2ä»ä¸­é—´éšæœºé€‰ã€‚å°†$$\tilde{S}_{1}^{u}$$å’Œ$$\tilde{S}_{2}^{u}$$é€šè¿‡$$f_{\theta}(\cdot)$$ç¼–ç æˆ $$\tilde{\mathbf{H}}_{1}^{u}$$å’Œ$$\tilde{\mathbf{H}}_{2}^{u}$$å¹¶èšåˆæˆåºåˆ—çš„å‘é‡è¡¨ç¤º$$\tilde{\mathbf{h}}_{1}^{u}$$å’Œ$$\tilde{\mathbf{h}}_{2}^{u}$$ã€‚é€šè¿‡InfoNCEä¼˜åŒ–$$\theta$$ï¼š


$$
\begin{gathered}
\mathcal{L}_{\text {SeqCL }}=\mathcal{L}_{\text {SeqCL }}\left(\tilde{\mathbf{h}}_{1}^{u}, \tilde{\mathbf{h}}_{2}^{u}\right)+\mathcal{L}_{\text {SeqCL }}\left(\tilde{\mathbf{h}}_{2}^{u}, \tilde{\mathbf{h}}_{1}^{u}\right) \\
\\
\mathcal{L}_{\text {SeqCL }}\left(\tilde{\mathbf{h}}_{1}^{u}, \tilde{\mathbf{h}}_{2}^{u}\right)=-\log \frac{\exp \left(\operatorname{sim}\left(\tilde{\mathbf{h}}_{1}^{u}, \tilde{\mathbf{h}}_{2}^{u}\right)\right)}{\sum_{n e g} \exp \left(\operatorname{sim}\left(\tilde{\mathbf{h}}_{1}^{u}, \tilde{\mathbf{h}}_{n e g}\right)\right)},
\end{gathered}
$$


### Latent Factor Modeling in SR

ç®—æ³•æœ€ä¸»è¦çš„å°±æ˜¯å¾—åˆ°æœ€ä½³$$\theta$$ã€‚å‡è®¾æœ‰Kä¸ªä¸åŒçš„ç”¨æˆ·æ„å›¾ï¼ˆä¹°ç¤¼ç‰©ï¼Œä¹°æ¸”å…·ç­‰ï¼‰ï¼Œé‚£ä¹ˆæ„å›¾å˜é‡å¯è®¾ä¸º$$c=\left\{c\right\}_{i=1}^{K}$$ï¼Œåˆ™æ¯ä¸ªç”¨æˆ·å¯èƒ½å’ŒæŸä¸€é¡¹äº¤äº’çš„æ¦‚ç‡ä¸ºï¼š


$$
P_{\theta}\left(s^{u}\right)=\mathbb{E}_{(c)}\left[P_{\theta}\left(s^{u}, c\right)\right]
$$


ç”¨æˆ·æ„å›¾æ˜¯æ½œåœ¨çš„å‘é‡ï¼Œå› ä¸ºcæˆ‘ä»¬ä¸èƒ½ç›´æ¥è§‚å¯Ÿåˆ°ã€‚å¦‚æœæ²¡æœ‰cï¼Œæˆ‘ä»¬æ²¡æ³•ä¼°è®¡å‚æ•°$$\theta$$ï¼Œè€Œæ²¡æœ‰$$\theta$$ï¼Œæˆ‘ä»¬å°±æ²¡æ³•æ¨æ–­cã€‚æ‰€ä»¥éœ€è¦ç”¨EMç®—æ³•ã€‚

## æ–¹æ³•

![overall](https://sunjc911.github.io/assets/images/ICL/overall.png)

Eæ­¥æ›´æ–°åˆ†å¸ƒå‡½æ•°Q(c)ï¼ŒMæ­¥æ›´æ–°$$\theta$$

é¦–å…ˆè®²æ€ä¹ˆæ¨å¯¼å‡ºç›®æ ‡å‡½æ•°ç”¨æ¥å°†æ½œåœ¨å˜é‡cå»ºæ¨¡æˆSRæ¨¡å‹ï¼Œå¦‚ä½•ä¼˜åŒ–ç›®æ ‡å‡½æ•°å³$$\theta$$ï¼Œå¹¶ä¸”åœ¨EMæ¡†æ¶ä¸‹ä¼°è®¡cçš„åˆ†å¸ƒå‡½æ•°ã€‚ä¹‹åæè¿°æ•´ä½“è®­ç»ƒç­–ç•¥ã€‚æœ€åè®²ç»†èŠ‚åˆ†æã€‚

### Intent Contrastive Learning

#### Modeling Latent Intent for SR

åŸºäº


$$
\theta^{*}=\underset{\theta}{\arg \max } \sum_{u=1}^{N} \sum_{t=2}^{T} \ln P_{\theta}\left(s_{t}^{u}\right)
\\\\
P_{\theta}\left(s^{u}\right)=\mathbb{E}_{(c)}\left[P_{\theta}\left(s^{u}, c\right)\right]
$$


é‡å†™ç›®æ ‡å‡½æ•°ä¸ºï¼š


$$
\theta^{*}=\underset{\theta}{\arg \max } \sum_{u=1}^{N} \sum_{t=1}^{T} \ln \mathbb{E}_{(c)}\left[P_{\theta}\left(s_{t}^{u}, c_{i}\right)\right]
$$


å‡è®¾cæœä»Q(c)åˆ†å¸ƒï¼Œ$$\sum_{c}Q(c_{i})=1$$å¹¶ä¸”$$Q(c_{i})â‰¥1$$ï¼Œå°±æœ‰ï¼š


$$
\begin{array}{r}
\sum_{u=1}^{N} \sum_{t=1}^{T} \ln \mathbb{E}_{(c)}\left[P_{\theta}\left(s_{t}^{u}, c_{i}\right)\right]=\sum_{u=1}^{N} \sum_{t=1}^{T} \ln \sum_{i=1}^{K} P_{\theta}\left(s_{t}^{u}, c_{i}\right) \\
=\sum_{u=1}^{N} \sum_{t=1}^{T} \ln \sum_{i=1}^{K} Q\left(c_{i}\right) \frac{P_{\theta}\left(s_{t}^{u}, c_{i}\right)}{Q\left(c_{i}\right)} .
\end{array}
$$


é€šè¿‡Jensenä¸ç­‰å¼è½¬åŒ–ä¸ºï¼š


$$
\begin{gathered}
\geq \sum_{u=1}^{N} \sum_{t=1}^{T} \sum_{i=1}^{K} Q\left(c_{i}\right) \ln \frac{P_{\theta}\left(s_{t}^{u}, c_{i}\right)}{Q\left(c_{i}\right)} \\
\propto \sum_{u=1}^{N} \sum_{t=1}^{T} \sum_{i=1}^{K} Q\left(c_{i}\right) \cdot \ln P_{\theta}\left(s_{t}^{u}, c_{i}\right)
\end{gathered}
$$


å½“$$Q\left(c_{i}\right)=P_{\theta}\left(c_{i} \mid s_{t}^{u}\right)$$æ—¶ä¸º=å·ã€‚ä¸ºäº†ç®€å•èµ·è§ï¼Œå½“ä¼˜åŒ–ä¸‹ç•Œçš„æ—¶å€™åªå…³æ³¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥ï¼š


$$
\sum_{u=1}^{N} \sum_{i=1}^{K} Q\left(c_{i}\right) \cdot \ln P_{\theta}\left(S^{u}, c_{i}\right)
$$


å…¶ä¸­$$Q\left(c_{i}\right)=P_{\theta}\left(c_{i} \mid S^{u}\right)$$ã€‚

è¿™æ ·å°±å¾—åˆ°äº†ç›®æ ‡å‡½æ•°çš„ä¸‹ç•Œã€‚ä½†æ˜¯è¿™ä¸ªå¼å­ä¸å¥½ç›´æ¥ä¼˜åŒ–å› ä¸ºQ(c)ä¸çŸ¥é“ã€‚æ‰€ä»¥éµå¾ªEMç®—æ³•å»ä¼˜åŒ–ã€‚

#### Intent Representation Learning

ä¸ºäº†å­¦ä¹ Q(c)ï¼Œéœ€è¦Kä¸ªç°‡å¿ƒï¼ŒQ(c)åˆ†å¸ƒå‡½æ•°å¦‚ä¸‹ï¼š


$$
Q\left(c_{i}\right)=P_{\theta}\left(c_{i} \mid S^{u}\right)= \begin{cases}1 & \text { if } S^{u} \text { in cluster i} \\
0 & \text { else }\end{cases} \\
$$


åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨â€œèšåˆå±‚â€è¡¨ç¤ºæ‰€æœ‰ä½ç½®æ­¥éª¤ä¸Šçš„å¹³å‡æ± åŒ–æ“ä½œã€‚æˆ‘ä»¬å°†å…¶ä»–å…ˆè¿›çš„èšåˆæ–¹æ³•(å¦‚åŸºäºæ³¨æ„åŠ›çš„æ–¹æ³•)**ç•™ç»™æœªæ¥çš„å·¥ä½œç ”ç©¶**ã€‚

#### Intent Contrastive SSL with FNM

Q(c)å·²ç»çŸ¥é“å¦‚ä½•ä¼°è®¡ã€‚ä¸ºäº†æœ€å¤§åŒ–ç›®æ ‡å‡½æ•°ï¼Œæˆ‘ä»¬è¿˜éœ€è¦å®šä¹‰$$P_{\theta}\left(S^{u}, c_{i}\right)$$ã€‚å‡è®¾å…ˆéªŒæ„å›¾éµå¾ªå‡åŒ€åˆ†å¸ƒã€‚åœ¨ç»™å®šcçš„æ¡ä»¶ä¸‹,$$\S^{u}$$çš„æ¡ä»¶åˆ†å¸ƒæ˜¯l2å½’ä¸€åŒ–çš„å„å‘åŒæ€§é«˜æ–¯åˆ†å¸ƒ(çƒå½¢åˆ†å¸ƒï¼Œå„ä¸ªæ–¹å‘æ–¹å·®éƒ½ä¸€æ ·çš„å¤šç»´é«˜æ–¯åˆ†å¸ƒ)ï¼Œåˆ™$$P_{\theta}\left(S^{u}, c_{i}\right)$$å¯é‡å†™ä¸ºï¼š


$$
P_{\theta}\left(S^{u}, c_{i}\right)=P_{\theta}\left(c_{i}\right) P_{\theta}\left(S^{u} \mid c_{i}\right)=\frac{1}{K} \cdot P_{\theta}\left(S^{u} \mid c_{i}\right) \\
\propto \frac{1}{K} \cdot \frac{\exp \left(-\left(\mathbf{h}^{u}-\mathbf{c}_{i}\right)^{2}\right)}{\sum_{j=1}^{K} \exp \left(-\left(\mathbf{h}_{i}^{u}-\mathbf{c}_{j}\right)^{2}\right)}\\
\propto \frac{1}{K} \cdot \frac{\exp \left(\mathbf{h}^{u} \cdot \mathbf{c}_{i}\right)}{\sum_{j=1}^{K} \exp \left(\mathbf{h}^{u} \cdot \mathbf{c}_{j}\right)}
$$


æ‰€ä»¥ç›®æ ‡å‡½æ•°ç­‰ä»·äºæœ€å°åŒ–ä¸‹é¢çš„æŸå¤±å‡½æ•°ï¼š


$$
-\sum_{v=1}^{N} \log \frac{\exp \left(\operatorname{sim}\left(\mathbf{h}^{u}, \mathbf{c}_{i}\right)\right)}{\sum_{j=1}^{K} \exp \left(\operatorname{sim}\left(\mathbf{h}^{u}, \mathbf{c}_{j}\right)\right)}
$$


ä¸Šå¼å¯¹æ¯”å•ä¸ªåºåˆ—å’Œæ½œåœ¨æ„å›¾çš„ä¸€è‡´æ€§ã€‚ä¹‹å‰SeqCL lossçš„æ•°æ®å¢å¼ºæ˜¯å¿…é¡»çš„ï¼Œè€ŒICLçš„æ•°æ®å¢å¼ºæ˜¯å¯é€‰çš„ï¼Œå› ä¸ºå¯¹æ¯”çš„æ˜¯åºåˆ—å’Œæ½œåœ¨æ„å›¾ã€‚æœ¬æ–‡åŠ å…¥æ•°æ®æ‰©å……ï¼š


$$
\mathcal{L}_{\mathrm{ICL}}=\mathcal{L}_{\mathrm{ICL}}\left(\tilde{\mathbf{h}}_{1}^{u}, \mathbf{c}_{u}\right)+\mathcal{L}_{\mathrm{ICL}}\left(\tilde{\mathbf{h}}_{2}^{u}, \mathbf{c}_{u}\right) ,\\
\mathcal{L}_{\mathrm{ICL}}\left(\tilde{\mathbf{h}}_{1}^{u}, \mathbf{c}_{u}\right)=-\log \frac{\exp \left(\operatorname{sim}\left(\tilde{\mathbf{h}}_{1}^{u}, \mathbf{c}_{u}\right)\right)}{\sum_{n e g} \exp \left(\operatorname{sim}\left(\tilde{\mathbf{h}}_{1}^{u}, \mathbf{c}_{n e g}\right)\right)}
$$


$$c_{neg}$$æ˜¯batchä¸­æ‰€æœ‰çš„æ„å›¾ã€‚ç›´æ¥ä¼˜åŒ–ä¸Šå¼å¯èƒ½ä¼šé€ æˆå‡é˜´æ€§ï¼Œå› ä¸ºåœ¨ä¸€ä¸ªbatchä¸­ç”¨æˆ·å¯èƒ½æœ‰ç›¸åŒçš„æ„å›¾ã€‚æ‰€ä»¥æå‡ºä¸€ç§è´Ÿæ ·æœ¬æŠ½æ ·æŠ€æœ¯FNMï¼š


$$
\mathcal{L}_{\mathrm{ICL}}\left(\tilde{\mathbf{h}}_{1}^{u}, \mathbf{c}_{u}\right)=-\log \frac{\exp \left(\operatorname{sim}\left(\tilde{\mathbf{h}}_{1}^{u}, \mathbf{c}_{u}\right)\right)}{\sum_{v=1}^{N} \mathbb{1}_{v \notin \mathcal{F}} \exp \left(\operatorname{sim}\left(\tilde{\mathbf{h}}_{1}, \mathbf{c}_{v}\right)\right)}
$$


å…¶ä¸­Fæ˜¯ä¸€ç»„å’Œuæœ‰ç›¸åŒæ„å›¾çš„ç”¨æˆ·ã€‚

### Multi-Task Learning


$$
\mathcal{L}=\mathcal{L}_{NextItem} + ğœ†Â·\mathcal{L}_{ICL}+ğ›½Â·\mathcal{L}_{SeqCL}
$$


åŸºäºTransformerç¼–ç å™¨å»ºæ¨¡æˆICLRecã€‚

## EXPERIMENTS

æ•°æ®åªæ˜¯ç”¨â€˜5-coreâ€™ï¼Œæ„æ€æ˜¯ç”¨æˆ·æˆ–è€…é¡¹ç›®è‡³å°‘æœ‰5ä¸ªäº¤äº’è®°å½•æ‰ä¼šè¢«é€‰ä¸­ã€‚

ç»“æœï¼š

![exp](https://sunjc911.github.io/assets/images/ICL/exp.png)

æ¶ˆèå®éªŒï¼š

![ablation](https://sunjc911.github.io/assets/images/ICL/ablation.png)

## Code

### å¤„ç†æ•°æ®

```
def generate_rating_matrix_valid(user_seq, num_users, num_items):
    # three lists are used to construct sparse matrix
    row = []
    col = []
    data = []
    for user_id, item_list in enumerate(user_seq):
        for item in item_list[:-2]:  #
            row.append(user_id)
            col.append(item)
            data.append(1)

    row = np.array(row)
    col = np.array(col)
    data = np.array(data)
    rating_matrix = csr_matrix((data, (row, col)), shape=(num_users, num_items))

    return rating_matrix

def get_user_seqs(data_file):
    lines = open(data_file).readlines()
    user_seq = []
    item_set = set()
    for line in lines:
        user, items = line.strip().split(" ", 1)
        items = items.split(" ")
        items = [int(item) for item in items]
        user_seq.append(items)
        item_set = item_set | set(items)
    max_item = max(item_set)

    num_users = len(lines)
    num_items = max_item + 2

    valid_rating_matrix = generate_rating_matrix_valid(user_seq, num_users, num_items)
    test_rating_matrix = generate_rating_matrix_test(user_seq, num_users, num_items)
    return user_seq, max_item, valid_rating_matrix, test_rating_matrix

user_seq, max_item, valid_rating_matrix, test_rating_matrix = get_user_seqs(args.data_file)

args.item_size = max_item + 2
args.mask_id = max_item + 1

```

torch.utils.data.Dataset

https://blog.csdn.net/weixin_44211968/article/details/123744513

```
class RecWithContrastiveLearningDataset(Dataset):
    def __init__(self, args, user_seq, test_neg_items=None, data_type="train", similarity_model_type="offline"):
        self.args = args
        self.user_seq = user_seq
        self.test_neg_items = test_neg_items
        self.data_type = data_type
        self.max_len = args.max_seq_length
        # currently apply one transform, will extend to multiples
        self.augmentations = {
            "crop": Crop(tao=args.tao),
            "mask": Mask(gamma=args.gamma),
            "reorder": Reorder(beta=args.beta),
            "random": Random(tao=args.tao, gamma=args.gamma, beta=args.beta),
        }
        if self.args.augment_type not in self.augmentations:
            raise ValueError(f"augmentation type: '{self.args.augment_type}' is invalided")
        print(f"Creating Contrastive Learning Dataset using '{self.args.augment_type}' data augmentation")
        self.base_transform = self.augmentations[self.args.augment_type]
        # number of augmentations for each sequences, current support two
        self.n_views = self.args.n_views
        
# mainè°ƒç”¨ä¸Šé¢çš„class
cluster_dataset = RecWithContrastiveLearningDataset(
    args, user_seq[: int(len(user_seq) * args.training_data_ratio)], data_type="train"
)
cluster_sampler = SequentialSampler(cluster_dataset)
cluster_dataloader = DataLoader(cluster_dataset, sampler=cluster_sampler, batch_size=args.batch_size)

train_dataset = RecWithContrastiveLearningDataset(
    args, user_seq[: int(len(user_seq) * args.training_data_ratio)], data_type="train"
)
train_sampler = RandomSampler(train_dataset)
train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.batch_size)

eval_dataset = RecWithContrastiveLearningDataset(args, user_seq, data_type="valid")
eval_sampler = SequentialSampler(eval_dataset)
eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.batch_size)

test_dataset = RecWithContrastiveLearningDataset(args, user_seq, data_type="test")
test_sampler = SequentialSampler(test_dataset)
test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args.batch_size)
```

```
cur_rec_tensors = (
    torch.tensor(user_id, dtype=torch.long),  # user_id for testing
    torch.tensor(copied_input_ids, dtype=torch.long),
    torch.tensor(target_pos, dtype=torch.long),
    torch.tensor(target_neg, dtype=torch.long),
    torch.tensor(answer, dtype=torch.long),
) # tuple:5
```

![subsequent_mask](https://sunjc911.github.io/assets/images/ICL/subsequent_mask.png)
