---
title: 深度学习推荐系统
description: 
date: 2023-04-22
categories:
 - Rec面试
tags:
 - Rec
 - 面试
excerpt_separator: <!--more--> 

---

**加油**

<!--more-->

## 问题

[常见损失函数](https://blog.csdn.net/yanyuxiangtoday/article/details/119788949)

[L1L2正则化](https://zhuanlan.zhihu.com/p/137073968)

[梯度下降求导_LR](https://blog.csdn.net/qq_35890572/article/details/107123956)

[极大似然估计](https://lulaoshi.info/machine-learning/linear-model/maximum-likelihood-estimation.html#%E6%A6%82%E7%8E%87)

[GBDT系列](https://blog.csdn.net/XiaoYi_Eric/article/details/80167968)

随机梯度下降，批梯度下降等梯度下降法的区别

特征缩放，特征归一化等方法

## 第一章 互联网的增长引擎——推荐系统

### 推荐系统的作用与意义

用户角度: 推荐系统解决在“信息过载”的情况下，用户如何高效获得感兴趣信息的问题。

公司角度:推荐系统解决产品能够最大限度地吸引用户、留存用户、增加用户黏性提高用户转化率的问题，从而达到公司商业目标连续增长的目的。需要注意的是，设计推荐系统的最终目标是达成公司的商业目标、增加公司收益这应是推荐工程师站在公司角度考虑问题的出发点。

### 推荐系统的架构

(1) 互联网企业的核心需求是“增长”，而推荐系统正处在“增长引擎”的核心位置(2) 推荐系统要解决的“用户痛点”是用户如何在“信息过载”的情况下高效地获得感兴趣的信息。

![1](https://sunjc911.github.io/assets/images/DeepRec/1.png)

### 推荐系统的模型部分

“**召回层**”一般利用高效的召回规则、算法或简单的模型，快速从海量的候选集中召回用户可能感兴趣的物品。
“**排序层（重点与研究重心）**”利用排序模型对初筛的候选集进行精排序。
“补充策略与算法层”，也被称为“再排序层**”，可以在将推荐列表返回用户之前，为兼顾结果的“多样性”“流行度”“新鲜度”等指标，结合一些补充的策略和算法对推荐列表进行定的调整，最终形成用户可见的推荐列表。

**模型权重**：**离线训练**的特点是可以利用全量样本和特征，使模型逼近全局最优点;**在线更新**则可以准实时地“消化”新的数据样本，更快地反映新的数据变化趋势，满足模型实时性的需求。

**评估模型效果**：离线评估和线上A/B测

## 第二章 前深度学习时代的重要算法

协同过滤、逻辑回归、因子分解机等传统推荐模型仍然凭借其可解释性强、硬件环境要求低易于快速训练和部署。

传统推荐模型是深度学习推荐模型的基础。

![2](https://sunjc911.github.io/assets/images/DeepRec/2.png)

### 协同过滤CF

“协同过滤”就是协同大家的反馈、评价和意见一起对海量的信息进行过滤从中筛选出目标用户可能感兴趣的信息的推荐过程。

![3](https://sunjc911.github.io/assets/images/DeepRec/3.png)

#### UserCF

##### 用户相似度计算

###### 余弦相似度

余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小。余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫"余弦相似性"。

![cos](https://sunjc911.github.io/assets/images/DeepRec/cos.png)

###### 皮尔逊相关系数

相比余弦相似度，皮尔逊相关系数通过使用用户平均分对各独立评分进行修正，减小了用户评分偏置的影响。

![p](https://sunjc911.github.io/assets/images/DeepRec/p.png)

![p2](https://sunjc911.github.io/assets/images/DeepRec/p2.png)

理论上，任何合理的“向量相似度定义方式”都可以作为相似用户计算的标准。

###### 最终结果的排序

![4](https://sunjc911.github.io/assets/images/DeepRec/4.png)

###### UserCF缺点

（1）用户数远大于物品数，用户相似度**矩阵开销大**，用户数增长时矩阵空间复杂度以n平方的速度增长，存储系统难以承受。

（2）用户历史数据**向量非常稀疏**，不适用于正反馈获取困难的场景。

#### ItemCF

构建物品相似度矩阵，相似度计算方法与UserCF相同。

···

(4) 利用物品相似度矩阵，针对目标用户历史行为中的正反馈物品，找出相似的Top k个物品，组成相似物品集合。
(5) 对相似物品集合中的物品，利用相似度分值进行排序，生成最终的推荐列表。在第5步中，如果一个物品与多个用户行为历史中的正反馈物品相似，那么该物品最终的相似度应该是多个相似度的累加，如(式2-5) 所示。·

![5](https://sunjc911.github.io/assets/images/DeepRec/5.png)

#### UserCF和ItemCF的应用场景

UserCF：社交、发现热点、跟踪热点、新闻

ItemCF：电商、视频推荐

#### 协同过滤的优缺点

优点：直观、可解释性强

缺点：不具备较强泛化能力，产生头部效应（热门商品容易和大量物品产生相似，冷门商品向量稀疏则反过来很少被推荐），处理稀疏向量的能力弱

### 矩阵分解MF

针对CF的头部效应明显、泛化能力较弱的问题。在CF**共现矩阵的基础**上，加入**隐向量**的概念，加强模型处理稀疏矩阵的能力，针对性地解决了协同过滤存在的主要问题。

矩阵分解算法则期望为每一个用户和视频生成一个隐向量，将用户和视频定位到隐向量的表示空间上，距离相近的用户和视频表明兴趣特点接近，在推荐过程中，就应该把距离相近的视频推荐给目标用户。任意用户与物品之间都可以得到预测分。

![6](https://sunjc911.github.io/assets/images/DeepRec/6.png)

用户和物品的隐向量通过CF的共现矩阵得到。

![MF](https://sunjc911.github.io/assets/images/DeepRec/MF.png)

mxn分解为mxk和kxn。k小隐向量小泛化能力高，反之则反。

![MF2](https://sunjc911.github.io/assets/images/DeepRec/MF2.png)

#### 矩阵分解的求解过程

##### 特征值分解ED

只适用于方阵，这里不行。

##### 奇异值分解SVD

![MF3](https://sunjc911.github.io/assets/images/DeepRec/MF3.png)

完美解决MF但有缺陷：

（1）要求共现矩阵稠密。共现矩阵稀疏，若要用需填充。

（2）计算复杂度O（mn平方）

##### 梯度下降GD（重要）

![GD](https://sunjc911.github.io/assets/images/DeepRec/GD.png)

##### 正则化

![reg](https://sunjc911.github.io/assets/images/DeepRec/reg.png)

q=1 L1正则化；2 L2正则化

对于加入了正则化项的损失函数来说，模型权重的值越大，损失函数越大。梯度下降是**朝着损失小的方向**发展的，因此正则化项其实是希望在尽量不影响原模型与数据集之间损失的前提下，**使模型的权重变小**，权重的减小自然会让模型的输出波动更小，从而达到**让模型更稳定**的目的。

可以加上偏差系数修正预测分数。

![7](https://sunjc911.github.io/assets/images/DeepRec/7.png)

##### 矩阵分解的优缺点

优点：泛化能力强，缓解数据稀疏问题；空间复杂度低（n+m）k；更好的扩展性和灵活性。

缺点：没发使用用户物品上下文特征。

### 逻辑回归LR

CF和MF利用相似度进行推荐。LR将推荐问题看作**分类问题**，预测正样本的概率对物品进行排序，转化为**点击率（Click Through Rate, CTR）**预估问题。综合利用用户物品上下文等特征。利用“感知机MLP”这种NN的基本单元，是深度学习的基础。

各特征加权和再施以sigmod函数

离散转为数值型特征向量，训练，得到点击物品的概率，根据概率排序进行推荐。

#### 数学形式

![LR1](https://sunjc911.github.io/assets/images/DeepRec/LR1.png)

![LR2](https://sunjc911.github.io/assets/images/DeepRec/LR2.png)

![LR3](https://sunjc911.github.io/assets/images/DeepRec/LR3.png)

![LR4](https://sunjc911.github.io/assets/images/DeepRec/LR4.png)

#### 权重训练——梯度下降法

目的是对目标函数求导，得到梯度方向，向对应梯度相反方向进行规定步长的迭代搜索，找到一个函数的局部最小值。反正为梯度上升法。

具体见问题章节内的内容

**利用模型的数学形式找出目标函数，并通过求导得到梯度下降的公式**

#### 逻辑回归的优缺点

优点：数学含义上的支撑；可解释性强；工程化的需要

缺点：表达能力不强，**只对单一特征做简单加权**，无法进行特征交叉、特征筛选等高级操作，会造成信息损失。

### POLY2

在LR的基础上对特征进行**暴力组合**，其中权重系数为单独的参数，非两个向量的内积（FM改进了这里）

![POLY1](https://sunjc911.github.io/assets/images/DeepRec/POLY1.png)

#### 缺陷

采用one-hot处理类别数据，导致向量极度稀疏，特征交叉后更稀疏，导致权重缺乏有效数据进行训练，无法收敛；权重参数数量n变为n平方。

### 因子分解机FM

为了解决POLY2的缺陷。

![FM1](https://sunjc911.github.io/assets/images/DeepRec/FM1.png)

用两个向量的内积取代了POLY2单一的权重系数。具体来说，**FM为每个特征学习一个隐向量权重。在特征交叉时，使用两个特征的隐向量的内积作为交叉特征的权重**，与MF异曲同工。把MF的用户物品的隐向量拓展到了所有特征上。

参数从POLY2的n平方变为nk，k为隐向量维度，n>>k。

#### 因子分解机的优缺点

优点：很好解决数据稀疏问题。虽然丢失某些具体特征组合的精确记忆能力，但是泛化能力大幅度提高。

### 特征域感知因子分解机FFM



基于FM，引入特征域感知，使模型表达能力更强。

![FFM1](https://sunjc911.github.io/assets/images/DeepRec/FFM1.png)

每个**特征对应**的不是唯一一个隐向量，而是**一组隐向量**。

![FFM2](https://sunjc911.github.io/assets/images/DeepRec/FFM2.png)

https://blog.csdn.net/weixin_44441131/article/details/119827464

引入更多有价值信息，表达能力更强，但是参数量为nkf，复杂度为kn平方。

### GBDT+LR——特征工程模型化的开端

如果做再高维度的特征交叉会组合爆炸和复杂度过高。

Facebook利用GBDT自动进行特征筛选和组合，进而生成新的离散特征向量，再把该特征向量当作LR模型输入，预测CTR的模型结构。GBDT和LR分别**独立**训练。

![GBDTLR1](https://sunjc911.github.io/assets/images/DeepRec/GBDTLR1.png)

#### GBDT

**决策树组成的森林**，学习方法是**梯度提升**。容易过拟合，会丢失大量特征的数值信息。

具体GBDT系列见问题章节内容。

![GBDT](https://sunjc911.github.io/assets/images/DeepRec/GBDT.png)

![GBDT1](https://sunjc911.github.io/assets/images/DeepRec/GBDT1.png)

![GBDT2](https://sunjc911.github.io/assets/images/DeepRec/GBDT2.png)

#### GBDT+LR开启特征工程新趋势

GBDT+LR组合模型的提出，意味着**特征工程可以完全交由一个独立的模型**来完成，模型的输入可以是原始的特征向量，**不必在特征工程上投入过多的人工筛选和模型设计的精力**，实现真正的**端到端** (End to End) 训练。

### 大规模分段线性模型LS-PLM（混合逻辑回归MLR）——阿里

Large Scale Piece-wise Linear Model， Mixed Logistic Regression

影响力大，与3层DNN相似。

在LR的基础上采用分而治之，先对样本进行分片，再在样本分片中应用LR进行CTR预估。

在LR基础上**加入聚类**，先对全量样本进行聚类，再对每个分类LR进行CTR预估。

![MLR1](https://sunjc911.github.io/assets/images/DeepRec/MLR1.png)

![MLR2](https://sunjc911.github.io/assets/images/DeepRec/MLR2.png)

#### 优势

端到端的非线性学习能力；模型的稀疏性强，建模引入L1、L2和1范数，使得模型具有较高的稀疏度，部署更加轻量级，效率高。

#### whyL1范数比L2范数更容易产生稀疏解？

左红L2，右红L1，蓝色为损失函数曲线。

![MLR3](https://sunjc911.github.io/assets/images/DeepRec/MLR3.png)

b图在顶点处相交，除了相切处维度不为零，其他都为0，所以更稀疏。

#### 从DL的角度审视LS-PLM

LS-PLM可以看作一个加入了注意力 (Attention) 机制的三层神经网络模型，其中输入层是样本的特征向量，中间层是由 m 个神经元组成的隐层，其中 m 是分片的个数，对于一个CTR预估问题，LS-PLM的最后一层自然是由单一神经元组成的输出层。

那么，注意力机制又是在哪里应用的呢? 其实是在隐层和输出层之间，神经元之间的权重是由分片函数得出的注意力得分来确定的。也就是说，样本属于哪个分片的概率就是其注意力得分。

### 总结

![21](https://sunjc911.github.io/assets/images/DeepRec/21.png)

![22](https://sunjc911.github.io/assets/images/DeepRec/22.png)

## 第三章 深度学习在推荐系统的应用

表达能力更强，结构更加灵活

![DL](https://sunjc911.github.io/assets/images/DeepRec/DL.png)

### AutoRec——单隐层神经网络推荐模型

自编码器与CF结合

#### 基本原理

**利用CF的共现矩阵，完成用户或物品向量的自编码**。再利用自编码的结果预估评分再排序。

##### 自编码器

指能够完成数据“自编码”的模型。将输入**转换成向量的形式**表达。假设其数据向量为 r，自编码器的作用是将向量r作为输入，通过自编码器后，得到的输出向量尽量接近其本身。

![AR1](https://sunjc911.github.io/assets/images/DeepRec/AR1.png)

一般来说，重建函数的参数数量远小于输入向量的维度数量，因此自编码器相当于完成了**数据压缩和降维**的工作。

经过自编码器生成的输出向量，由于经过了自编码器的“泛化”过程，**不会完全等同于输入向量**，也因此**具备了一定的缺失维度的预测能力**，这也是自编码器能用于推荐系统的原因。

#### AutoRec模型的结构

单隐层NN

![AR2](https://sunjc911.github.io/assets/images/DeepRec/AR2.png)

![AR3](https://sunjc911.github.io/assets/images/DeepRec/AR3.png)

##### 什么是神经元、神经网络、梯度反向传播

神经元（感知机）与神经网络

![AR4](https://sunjc911.github.io/assets/images/DeepRec/AR4.png)

![AR5](https://sunjc911.github.io/assets/images/DeepRec/AR5.png)

前向传播和反向传播

前向传播的目的是在当前网络参数的基础上得到模型对输入的预估值，也就是常说的模型推断过程。在得到预估值之后，就可以利用损失函数(Loss Function) 的定义计算模型的损失。

利用梯度下降法反向更新权重。利用求导过程中的链式法则。

#### 基于AutoRec模型的推荐过程

![AR6](https://sunjc911.github.io/assets/images/DeepRec/AR6.png)

#### 优缺点

优点：使用NN，有一定泛化和表达能力。

缺点：过于简单导致表达能力不足。

与Word2vec完全一致，但优化目标和训练方法不同。

### Deep Crossing——经典的深度学习框架

微软的深度学习框架在Rec中的完整应用。

完整地解决了从特征工程、稀疏向量稠密化、多层神经网络进行优化目标拟合等一系列深度学习在推荐系统中的应用问题，为后续的研究打下了良好的基础。

#### 应用场景

Bing搜索引擎中返回相关广告，尽可能增加其点击率。准确预测广告点击率并作为广告排序的指标之一，是非常重要的，且是该模型的优化目标。

分为三类特征。可被处理为one/multi-hot向量的类别特征；计数特征；进一步处理的特征。

![DR](https://sunjc911.github.io/assets/images/DeepRec/DR.png)

处理完特征后进行CTR预估。

深度学习网络的特点是可以根据需求灵活地对网络结构进行调整，从而达成**从原始特征向量到最终的优化目标的端到端的训练**目的。

#### 网络结构

为完成端到端的训练，Deep Crossing模型要在其内部网络中解决如下问题。

(1)离散类特征编码后过于稀疏，不利于直接输入神经网络进行训练，如何解决**稀疏特征向量稠密化**的问题。
(2) 如何解决**特征自动交叉组合**的问题
(3) 如何在输出层中**达成**问题设定的**优化目标**
Deep Crossing模型分别设置了不同的神经网络层来解决上述问题。如图3-6所示，其网络结构主要包括4层-Embedding层、Stacking层、Multiple Residual Units层和Scoring层。

![DR1](https://sunjc911.github.io/assets/images/DeepRec/DR1.png)

![DR2](https://sunjc911.github.io/assets/images/DeepRec/DR2.png)

Stacking层: Stacking层(堆叠层) 的作用比较简单，是把不同的Embedding特征和数值型特征**拼接**在一起，形成新的包含全部特征的特征向量，该层通常也被称为连接(concatenate )层。

![DR3](https://sunjc911.github.io/assets/images/DeepRec/DR3.png)

Scoring层: Scoring层作为输出层，就是为了拟合优化目标而存在的。对于**CTR 预估这类二分类问题**，Scoring 层往往使用的是逻辑回归模型，而对于图像分类等多分类问题Scoring层往往采用softmax模型。

##### 残差网络及特点

残差单元（Residual Unit）组成

![DR4](https://sunjc911.github.io/assets/images/DeepRec/DR4.png)

![DR5](https://sunjc911.github.io/assets/images/DeepRec/DR5.png)

传统MLP越深就过拟合，测试集表现越差。RU可以减少过拟合。

NN越深，**梯度消失**越严重。梯度消失现象是指在梯度反向传播过程中，越靠近输入端，梯度的幅度越小，参数收敛的速度越慢。为了解决这个问题，残差单元使用了 **ReLU 激活函数取代原来的sigmoid 激活函数**。此外，输入向量**短路**相当于直接把梯度毫无变化地传递到下一层，这也使残差网络的收敛速度更快。

#### DR对特征交叉方法的革命

将全部特征交叉的任务交给模型。只需要调整NN的深度进行特征之间的“深度交叉”。

### NeuralCF模型——CF与深度学习的结合

何向南YYDS

#### 深度学习视角重新审视矩阵分解模型

隐向量为Embedding，内积获得得分为输出层

#### 结构

多层神经网络+输出层 代替 MF中的内积操作。收益直观：一是让用户向量和物品向量做更**充分的交叉**，得到更多有价值的特征组合信息: 二是**引入更多的非线性特征**，让模型的表达能力更强。

![NCF](https://sunjc911.github.io/assets/images/DeepRec/NCF.png)

框住的是互操作层，将内积改为其他操作称为”广义矩阵分解“模型GMF。

NCF再进行stacking，使得模型有更强的特征组合和非线性能力。

![NCF1](https://sunjc911.github.io/assets/images/DeepRec/NCF1.png)

##### Softmax函数

作为输出层解决多分类问题的目标拟合问题。

![NCF2](https://sunjc911.github.io/assets/images/DeepRec/NCF2.png)

![NCF3](https://sunjc911.github.io/assets/images/DeepRec/NCF3.png)

往往与交叉熵损失函数一起用：

![NCF4](https://sunjc911.github.io/assets/images/DeepRec/NCF4.png)

![NCF5](https://sunjc911.github.io/assets/images/DeepRec/NCF5.png)

#### NCF优缺点

优点：隐向量改为Embedding，利用互操作特征交叉，灵活拼接。

缺点：基于CF，没有其他类型特征，浪费了其他有用信息，没有对互操作做进一步探究。

NN理论上能拟合任意函数。模型不是越复杂越好，要防止过拟合。复杂模型往往需要更多数据和更长训练时间。

### PNN——加强特征交叉能力

引入乘积层，给出特征交互方式的几种设计思路，用于解决CTR预估。

#### 网络架构

用product layer乘积层代替Deep Crossing中的stacking层，更加针对性地获取特征之间的交叉信息。

![PNN](https://sunjc911.github.io/assets/images/DeepRec/PNN.png)

可以输入更多特征。而不是NCF那样的。

#### Product层的多种特征交叉方式

该层由内积操作（图中z部分）和外积（outer product）操作（图中p部分）。

内积操作为经典的向量内积运算。

![PNN1](https://sunjc911.github.io/assets/images/DeepRec/PNN1.png)

![PNN2](https://sunjc911.github.io/assets/images/DeepRec/PNN2.png)

#### PNN优缺点

优点：强调Embedding向量之间的交叉方式是多样化的。更容易捕获特征的交叉信息。

缺点：外积中为效率而使用平**均池化会忽略原始特征中包含的有价值信息**。

如何使得特征交叉方式更高效，后续模型给出解决方案。

### Wide&Deep模型——记忆能力和泛化能力的综合

谷歌，单层Wide和多层Deep组成的混合模型。wide让模型具有较强的”记忆能力（memorization）“，deep使模型具有”泛化能力（generalization）“。正是这样的结构特点，使模型兼具了逻辑回归和深度神经网络的优点--**能够快速处理并记忆大量历史行为特征，并且具有强大的表达能力**，不仅在当时迅速成为业界争相应用的主流模型，而且衍生出了大量以Wide&Deep模型为基础结构的混合模型，**影响力一直延续到至今**。

#### 模型的记忆能力和泛化能力

“记忆能力”可以被理解为**模型直接学习并利用历史数据中物品或者特征的“共现频率”的能力**。一般来说，协同过滤、逻辑回归等简单模型有较强的“记忆能力”。由于这类模型的结构简单，原始数据往往可以直接影响推荐结果，产生类似于“如果点击过A，就推荐B”这类规则式的推荐，这就相当于模型直接记住了历史数据的分布特点，并利用这些记忆进行推荐。

![WD](https://sunjc911.github.io/assets/images/DeepRec/WD.png)

“泛化能力”可以被理解为**模型传递特征的相关性，以及发掘稀疏甚至从未出现过的稀有特征与最终标签相关性的能力**。矩阵分解比协同过滤的泛化能力强，因为矩阵分解引入了隐向量这样的结构，使得数据稀少的用户或者物品也能生成隐向量，从而获得有数据支撑的推荐得分，这就是非常典型的**将全局数据传递到稀疏物品上，从而提高泛化能力**的例子。再比如，深度神经网络通过特征的多次自动组合，可以深度发掘数据中潜在的模式，即使是非常稀疏的特征向量输入，也能得到较稳定平滑的推荐概率，这就是简单模型所缺乏的“泛化能力”

#### 模型结构

![WD1](https://sunjc911.github.io/assets/images/DeepRec/WD1.png)

Wide& Deep模型把单输入层的Wide部分与由Embedding层和多隐层组成的Deep部分连接起来，一起输入最终的输出层。单层的Wide部分善于处理大量稀疏的id类特征: Deep部分利用神经网络表达能力强的特点，进行深层的特征交叉，挖掘藏在特征背后的数据模式。最终，利用逻辑回归模型，输出层将 Wide部分和Deep部分组合起来，形成统一的模型。

![WD2](https://sunjc911.github.io/assets/images/DeepRec/WD2.png)

![WD3](https://sunjc911.github.io/assets/images/DeepRec/WD3.png)

#### Deep&Cross（DCN）——WD的进化

使用Cross网络代替Wide部分

![WD4](https://sunjc911.github.io/assets/images/DeepRec/WD4.png)

Corss网络的目的是**增加特征之间的交互力度**，使用多层交叉层（Cross layer）对输入向量进行特征交叉。

![WD5](https://sunjc911.github.io/assets/images/DeepRec/WD5.png)

二阶部分类似PNN的外积。

![WD6](https://sunjc911.github.io/assets/images/DeepRec/WD6.png)

#### Wide&Deep影响力

DeepFM、NFM等模型可以看作其延伸。

成功的关键：(1) **抓住**了业务问题的**本质**特点，能够**融合**传统模型记忆能力和深度学习模型泛化能力的**优势**。
(2) 模型的**结构并不复杂**，比较容易在工程上实现、训练和上线，这加速了其在业界的推广应用。

### FM与深度学习模型的结合

#### FNN——用FM的隐向量完成Embedding层初始化

![FNN](https://sunjc911.github.io/assets/images/DeepRec/FNN.png)

FNN在哪里与FM模型进行了结合呢？关键在于Embedding层的改进。

参数初始化如果运气不好极端，会导致Embedding层收敛慢。

##### 为什么Embedding层的收敛速度往往很慢

1.参数量巨大。权重占据整个网络权重的大部分。

2.输入向量过于稀疏。随机梯度下降只更新与非零特征相连的Embedding层权重。

针对此问题。FNN的解决思路是用FM模型训练好的各特征隐向量初始化Embedding层的参数。相当于引入先验，加速收敛过程。FM公式：

![FNN1](https://sunjc911.github.io/assets/images/DeepRec/FNN1.png)

w为1阶权重，v为二阶隐向量。

![FNN2](https://sunjc911.github.io/assets/images/DeepRec/FNN2.png)

![FNN3](https://sunjc911.github.io/assets/images/DeepRec/FNN3.png)

#### DeepFM——用FM代替Wide部分

![DFM](https://sunjc911.github.io/assets/images/DeepRec/DFM.png)

![DFM1](https://sunjc911.github.io/assets/images/DeepRec/DFM.png)

#### NFM——FM的神经网络化尝试

FM和FFM最多到二阶特征交叉，再高就组合爆炸，限制表达能力。能不能用NN来改进FM。

NFM用一个表达能力更强的函数替代原FM中二阶隐向量内积的部分。

![NFM](https://sunjc911.github.io/assets/images/DeepRec/NFM.png)

用下面的网络结构作为f（x）函数替代二阶

![NFM1](https://sunjc911.github.io/assets/images/DeepRec/NFM1.png)

![NFM2](https://sunjc911.github.io/assets/images/DeepRec/NFM2.png)

肚脐眼为element-wise product元素积，即对应元素相乘。

![NFM3](https://sunjc911.github.io/assets/images/DeepRec/NFM3.png)

#### 基于FM的深度学习模型的优缺点

优点：FNN、DeepFM、NFM都在经典多层NN的基础上加入了针对性的特征交叉操作，让模型具备更强的非线性表达能力。

缺点：特征工程的思路几乎穷尽，模型提升空间小。

### 注意力机制的应用

#### AFM——引入注意力机制的FM

NFM模型的延续。在NFM模型中，对特征交叉池化层后的特征向量进行”加和池化“，会“一视同仁”地对待所有交叉特征，不考虑不同特征对结果的影响程度，消解了有价值的信息。

AFM模型引入注意力机制是通过在特征交叉层和最终的输出层之间加入注意力网络实现。注意力网络的作用是为每一个交叉特征提供权重，也就是注意力得分。

![AFM](https://sunjc911.github.io/assets/images/DeepRec/AFM.png)

![AFM1](https://sunjc911.github.io/assets/images/DeepRec/AFM1.png)

![AFM2](https://sunjc911.github.io/assets/images/DeepRec/AFM1.png)

#### DIN——引入注意力机制的深度学习网络

更具有业务气息。应用于阿里巴巴的电商广告推荐。

![DIN](https://sunjc911.github.io/assets/images/DeepRec/DIN.png)

![DIN1](https://sunjc911.github.io/assets/images/DeepRec/DIN1.png)

![DIN2](https://sunjc911.github.io/assets/images/DeepRec/DIN2.png)

如果留意图3-24中的红线，可以发现商铺id只跟用户历史行为中的商铺 id序列发生作用，商品 id只跟用户的商品 id序列发生作用，因为注意力的轻重更应该由同类信息的相关性决定。
DIN模型与基于 FM的 AFM模型相比，是一次更典型的改进深度学习网络的尝试，而且由于出发点是具体的业务场景，也给了推荐工程师更多实质性的启发。

### DIEN——序列模型与推荐系统的结合

DIN的进化版本。创新在于用序列模型模拟了用户兴趣的进化过程。

#### DIEN的进化动机

历史行为都是一个随时间排序的序列。一定存在强或弱的前后依赖关系。AFM和DIN获得的注意力得分与时间无关，即序列无关。

序列信息的重要性：（1）加强最近行为对下次行为预测的影响。（2）序列模型能够学习到购买趋势的信息。

#### DIEN模型的架构

![DIEN](https://sunjc911.github.io/assets/images/DeepRec/DIEN.png)

![DIEN1](https://sunjc911.github.io/assets/images/DeepRec/DIEN1.png)

![DIEN2](https://sunjc911.github.io/assets/images/DeepRec/DIEN2.png)

#### 兴趣抽取层的结构

基本结构GRU门循环单元。相比于传统的RNN循环神经网络和LSTM长短期记忆网络。GRU解决了RNN的梯度消失问题。与LSTM相比，GRU的参数量更少，训练收敛速度更快。

![DIEN3](https://sunjc911.github.io/assets/images/DeepRec/DIEN3.png)

![DIEN4](https://sunjc911.github.io/assets/images/DeepRec/DIEN4.png)

#### 兴趣进化层的结构

最大特点：加入注意力机制。

![DIEN5](https://sunjc911.github.io/assets/images/DeepRec/DIEN5.png)

#### 序列模型对推荐系统的启发

具备强大的序列表达能力，非常适合预估用户经过一系列行为后的下一次动作。

模型复杂度较高，训练复杂度较高，服务过程中延迟大，增大其上线的难度，需要在工程上着重优化。

### 强化学习与推荐系统的结合

### 总结

![3o1](https://sunjc911.github.io/assets/images/DeepRec/3o1.png)

![3o2](https://sunjc911.github.io/assets/images/DeepRec/3o2.png)

![3o3](https://sunjc911.github.io/assets/images/DeepRec/3o3.png)

## 第四章 Embedding技术在推荐系统中的应用

### 什么是Embedding

用一个低维稠密的向量“表示”一个对象。“表示”意味着 Embedding向量能够表达相应对象的某些特征，同时向量之间的距离反映了对象之间的相似性。

#### Embedding的重要性

1.推荐中大量使用独热编码、id编码，导致极度稀疏，深度学习的结构特点不利于稀疏特征向量的处理。用Embedding层将高维稀疏转为低维稠密。所以为DL的基础操作。

2.本身就是重要的特征向量。表达能力更强，尤其是Graph Embedding技术提出后。

3.基于Embedding的相似度内积更适用于召回。

### Word2Vec——经典的Embedding方法

谷歌，使得词向量从NLP推广到搜广推领域。

#### 什么是Word2Vec

![WV](https://sunjc911.github.io/assets/images/DeepRec/WV.png)

T为句子长度，选择2c+1的滑动窗口。

![WV1](https://sunjc911.github.io/assets/images/DeepRec/WV1.png)

什么是输出向量表达和输入向量表达？

![WV2](https://sunjc911.github.io/assets/images/DeepRec/WV2.png)

![WV3](https://sunjc911.github.io/assets/images/DeepRec/WV3.png)

![WV4](https://sunjc911.github.io/assets/images/DeepRec/WV4.png)

#### Word2Vec的“负采样”训练方法

![WV5](https://sunjc911.github.io/assets/images/DeepRec/WV5.png)

![WV6](https://sunjc911.github.io/assets/images/DeepRec/WV6.png)

#### Word2Vec对Embedding技术的意义

牛逼。从另一个角度看，在 Word2vec 的研究中提出的模型结构、目标函数、负采样方法及负采样中的目标函数，在后续的研究中被重复使用并被屡次优化。掌握Word2vec 中的每个细节成了研究 Embedding 的基础。从这个意义上讲，熟练掌握本节内容非常重要。

### Item2vec——Word2vec在推荐系统领域的推广

Word2vec对词序列进行embedding，那么rec中可以对用户购买序列进行embedding。

#### 基本原理

利用用户向量和物品向量的相似性，可以直接在推荐系统的召回层快速得到候选集合，或在排序层直接用于最终推荐列表的排序。

![IV](https://sunjc911.github.io/assets/images/DeepRec/IV.png)

#### “广义”Item2vec

任何生成物品向量的方法都可以成为Item2vec。如双塔模型。

![IV1](https://sunjc911.github.io/assets/images/DeepRec/IV1.png)

![IV2](https://sunjc911.github.io/assets/images/DeepRec/IV2.png)

#### 优缺点

优点：推广Word2vec，大大拓展应用场景。广义上的Item2vec模型其实是物品向量化方法的统称。

缺点：只能利用序列数据。

### Graph Embedding——引入更多结构信息的图嵌入技术

![GE](https://sunjc911.github.io/assets/images/DeepRec/GE.png)

Graph Embedding是一种对图结构中的节点进行Embedding编码的方法。最终生成的节点 Embedding 向量一般包含图的结构信息及附近节点的局部相似性信息。

#### Deep Walk——基础的Graph Embedding方法

在由**物品组成的图结构**上进行随机游走，然后产生大量物品序列，然后作为样本输入到Word2vec进行训练，得到物品的Embedding。

![GE1](https://sunjc911.github.io/assets/images/DeepRec/GE1.png)

![GE2](https://sunjc911.github.io/assets/images/DeepRec/GE2.png)

#### Node2vec——同质性和结构性的权衡

基于Deep Walk，它通过调整随机游走权重的方法使Graph Embedding的结果更倾向于体现网络的司质性 (homophily) 或结构性 (structural equivalence) 。

具体地讲，网络的“同质性”指的是距离相近节点的Embedding应尽量近似，如图 4-8所示，节点u 与其相连的节点 s1、S2、S3、S4的 Embedding 表达应该是接近的，这就是网络“同质性”的体现。

“结构性”指的是结构上相似的节点的 Embedding 应尽量近似，图 4-8 中节点 U 和节点 s6都是各自局域网络的中心节点，结构上相似，其 Embedding 的表达也应该近似，这是“结构性”的体现。

![GE3](https://sunjc911.github.io/assets/images/DeepRec/GE3.png)

![GE4](https://sunjc911.github.io/assets/images/DeepRec/GE4.png)

![GE5](https://sunjc911.github.io/assets/images/DeepRec/GE5.png)

![GE6](https://sunjc911.github.io/assets/images/DeepRec/GE6.png)

Node2vec 所体现的网络的同质性和结构性在推荐系统中可以被很直观的解释。同质性相同的物品很可能是同品类、同属性，或者经常被一同购买的商品，而结构性相同的物品则是各品类的爆款、各品类的最佳凑单商品等拥有类似趋势或者结构性属性的商品。毫无疑问，二者在推荐系统中都是非常重要的特征表达。由于 Node2vec 的这种灵活性，以及发掘不同图特征的能力，甚至可以把不同Node2vec生成的偏向“结构性”的Embedding结果和偏向“同质性”的Embedding结果共同输入后续的深度学习网络，以保留物品的不同图特征信息。

#### EGES——阿里巴巴的综合性Graph Embedding方法

在Deep Walk生成的Graph Embedding基础上引入补充信息。

为了使冷启动的商品获得合理的初始Embedding，引入补充信息side information来丰富Embedding信息的来源。

生成Graph Embedding的第一步是生成物品关系图，通过用户行为序列可以生成物品关系图，也可以利用“相同属性”“相同类别”等信息建立物品之间的边，生成基于内容的知识图谱。而基于知识图谱生成的物品向量可以被称为补充信息 Embedding向量。当然，根据补充信息类别的不同，可以有多个补充信息Embedding向量。

![GE7](https://sunjc911.github.io/assets/images/DeepRec/GE7.png)

![GE8](https://sunjc911.github.io/assets/images/DeepRec/GE8.png)

### Embedding与深度学习推荐系统的结合

作为深度学习推荐系统不可分割的一部分，Embedding技术主要应用在如下三个方向。
(1) 在深度学习网络中作为Embedding层，完成从**高维稀疏特征向量到低维稠密**特征向量的转换。
(2)作为预训练的Embedding特征向量，与其他特征向量连接后，一同输入深度学习网络进行训练。
(3) 通过计算用户和物品的Embedding相似度，Embedding可以直接作为推荐系统的召回层或者召回策略之一。

#### 深度学习网络中的Embedding层

![GE9](https://sunjc911.github.io/assets/images/DeepRec/GE9.png)

![GE10](https://sunjc911.github.io/assets/images/DeepRec/GE10.png)

#### Embedding预训练方法

为解决Embedding层训练开销大的问题。

FNN模型就是采用的预训练，利用FM模型的各特征隐向量作为初始化Embedding权重，从而加快网络收敛速度。

若想更快收敛，可以固定Embedding权重，仅更新上层网络的权重，这是更彻底的预训练方法。

再延伸一下，Embedding的本质是建立高维向量到低维向量的映射，而“映射”的方法并不局限于神经网络，可以是任何异构模型。例如，2.6节介绍的GBDT+LR组合模型，其中GBDT部分在本质上就是进行了一次Embedding操作，利用GBDT模型完成Embedding预训练，再将Embedding输入单层神经网络(即逻辑回归) 进行CTR预估

通常，Graph Embedding的训练只能独立于推荐模型进行，所以预训练受青睐。

诚然，将Embedding过程与深度神经网络的训练过程割裂会损失一定的信息，但训练过程的独立也带来了训练灵活性的提升。举例来说，物品或用户的Embedding是比较稳定的(因为用户的兴趣、物品的属性不可能在几天内发生巨大的变化)，Embedding的训练频率其实不需要很高，甚至可以降低到周的级别，但上层神经网络为了尽快抓住最新的数据整体趋势信息，往往需要高频训练甚至实时训练。使用不同的训练频率更新Embedding模型和神经网络模型，是训练开销和模型效果二者之间权衡后的最优方案。

#### Embedding作为推荐系统召回层的方法

Embedding自身表达能力的增强使得直接利用Embedding生成推荐列表成了可行的选择。因此，利用Embedding向量的相似性，将Embedding作为推荐系统召回层的方案逐渐被推广开来。其中，YouTube推荐系统召回层(如图4-14所示) 的解决方案是典型的利用Embedding进行候选物品召回的做法。

![GE11](https://sunjc911.github.io/assets/images/DeepRec/GE11.png)

![GE12](https://sunjc911.github.io/assets/images/DeepRec/GE12.png)

![GE13](https://sunjc911.github.io/assets/images/DeepRec/GE13.png)

### 局部敏感哈希——让Embedding插上翅膀的快速搜索方法

Embedding最重要的用法之一是作为推荐系统的召回层，解决相似物品的召回问题。推荐系统召回层的主要功能是快速地将待推荐物品的候选集从十万、百万量级的规模减小到几千甚至几百量级的规模，避免将全部候选物品直接输入深度学习模型造成的计算资源浪费和预测延迟问题。
Embedding技术凭借其能够综合多种信息和特征的能力，相比传统的基于规则的召回方法，更适于解决推荐系统的召回问题。在实际工程中，能否应用Embedding的关键就在于能否使用Embedding技术“快速”处理几十万甚至上百万候选集，避免增大整个推荐系统的响应延迟。

#### “快速”Embedding最近邻搜索

基于内积需要对候选集合中的所有物品进行遍历。

由于用户和物品的Embedding同处于一个向量空间内，所以召回与用户向量最相似的物品Embedding向量的过程其实是一个在向量空间内搜索最近邻的过程。如果能够找到高维空间快速搜索最近邻点的方法，那么相似Embedding的快速搜索问题就迎刃而解了。

需要建立kd树。但其结构较为复杂，且往往需要回溯保证效果。

#### 局部敏感哈希（Locality Sensitive Hashing，LSH）的基本原理

主流的快速Embedding向量最近邻搜索方法。

让相邻的点落入同一个桶，这样在最近邻搜索时，仅需要在一个桶或者相邻的几个桶内的元素中进行搜。如果每个桶的元素在一个常数附近，可以将时间复杂度降为常数级别。如何构建桶？以基于欧氏距离的最近邻搜索为例。

在欧式空间中，将高维空间的点映射到低维空间，原本相近的点在低维空间中肯定依然相近，但原本远离的点则有一定概率变成相近的点。利用低维空间可以保留高维空间相近距离关系的性质，就可以构造局部敏感哈希“桶。

![GE14](https://sunjc911.github.io/assets/images/DeepRec/GE14.png)

#### 局部敏感哈希多桶策略

采用多个哈希函数进行分桶，存在一个待解决的问题: 到底是通过“与”(And) 操作还是“或”(Or) 操作生成最终的候选集。如果通过“与”操作 (“点A和点B在哈希函数1的同一桶中”并且“点A和点B在哈希函数2的同一桶中”) 生成候选集，那么候选集中近邻点的准确率将提高，候选集的规模减小使需要遍历计算的量降低，减少了整体的计算开销，但有可能会漏掉一些近邻点(比如分桶边界附近的点) :如果通过“或”操作 (“点A和点B在哈希函数1的同一桶中”或者“点A和点B在哈希函数2的同一桶中”) 生成候选集，那么候选集中近邻点的召回率提高，但候选集的规模变大，计算开销升高。到底使用几个哈希函数，是用“与”操作还是“或”操作来生成近邻点的候选集，需要在准确率和召回率之间权衡才能得出结论。

如果使用余弦相似度作为距离标准，如何分桶？

余弦相似度衡量的是两个向量间夹角的大小，夹角小的向量即为“近邻”，因此可以使用固定间隔的超平面将向量空间分割成不同哈希桶。同样，可以通过选择不同组的超平面提高局部敏感哈希方法的准确率或召回率。当然，距离的定义方法远不止“欧氏距离”和“余弦相似度”两种，还包括“曼哈顿距离”“切比雪夫距离”“汉明距离”等，局部敏感哈希的方法也随距离定义的不同有所不同。但局部敏感哈希通过分桶方式保留部分距离信息，大规模降低近邻点候选集的本质思想是通用的。

### 总结

![GE15](https://sunjc911.github.io/assets/images/DeepRec/GE15.png)

推荐模型是驱动推荐系统达成推荐效果的引擎，也是所有推荐系统团队投入精力最多的部分。读者也一定能够在之前的学习中感受到推荐模型在学术界和业界的发展进化速度之快。我们要清楚的是，对于一个成熟的推荐系统，除了推荐模型，还要考虑召回策略、冷启动、探索与利用、模型评估、线上服务等诸多方面的问题。

## 第五章——多角度审视推荐系统

(1) 推荐系统如何选取和处理特征?
(2)推荐系统召回层的主要策略有哪些?
(3))推荐系统实时性的重要性体现在哪儿?有哪些提高实时性的方法?
(4)如何根据具体场景构建推荐模型的优化目标?
(5)如何基于用户动机改进模型结构?
(6) 推荐系统冷启动问题的解决方法有哪些?
(7) 什么是“探索与利用”问题? 有哪些主流的解决方法?

### 推荐系统的特征工程

Garbage in garbage out

机器学习模型的能力边界**在于对数据的拟合和泛化，那么数据及表达数据的特征本身就决定了机器学习模型效果的上限。**

因此，特征工程对推荐系统效果提升的作用是无法替代的。为了构建一个“好”的特征工程，需要依次解决三个问题:
(1) 构建特征工程应该遵循的基本原则是什么?
(2) 有哪些常用的特征类别?
(3) 如何在原始特征的基础上进行特征处理，生成可供推荐系统训练和推断用的特征向量?

#### 构建推荐系统特征工程的原则

特征的本质是对某个行为过程相关信息的抽象表达。

从具体行为转化为抽象特征，必然涉及信息的损失。因为原始行为需要的存储空间过大，且有冗余无用的信息影响模型泛化。

**尽可能让特征工程抽取出的一组特征能够保留推荐环境及用户行为过程中的所有有用信息，尽量摒弃冗余信息。**

如何抽取特征代表”用户点击某个电影“这一行为。

![FE](https://sunjc911.github.io/assets/images/DeepRec/FE.png)

心情无法抽取所以舍弃。

#### 推荐系统中的常用特征

1.用户行为数据

**常用且最关键**

![FE1](https://sunjc911.github.io/assets/images/DeepRec/FE1.png)

隐性反馈越发重要，因为显性反馈收集难度大且数据量小。仅用显性不足以支撑模型训练到收敛。所以**挖掘隐性反馈是目前特征挖掘的重点。**

具体用户行为特征处理上，1是将id序列转换为multi-hot向量将其作为特征向量；另一种是用预训练的Embedding，然后通过mean或者DIN的注意力机制生成历史行为Embedding，将其作为特征向量。

2.用户关系数据

物以类聚，人以群分。显性和隐性关系，或者叫强弱关系。用户与用户之间可以通过“关注”“好友关系”等连接建立“强关系”，也可以通过“互相点赞”“同处一个社区”，甚至“同看一部电影”建立“弱关系。

在推荐系统中，利用用户关系数据的方式不尽相同，可以将用户关系作为召回层的一种物品召回方式;也可以通过用户关系建立关系图，使用 Graph Embedding的方法生成用户和物品的 Embedding; 还可以直接利用关系数据，通过“好友”的特征为用户添加新的属性特征:甚至可以利用用户关系数据直接建立社会化推荐系统。

3.属性、标签类数据

![FE2](https://sunjc911.github.io/assets/images/DeepRec/FE2.png)

![FE3](https://sunjc911.github.io/assets/images/DeepRec/FE3.png)

**用户属性、物品属性、标签类数据最重要。**

4.内容类数据

内容需要通过NLP、CV等手段提取内容信息再输入推荐系统。如CV目标检测提取狗标签。

5.上下文信息

推荐行为产生的场景的信息。时间地点等。如傍晚看浪漫电影，深夜看恐怖电影。

6.统计类特征

通过统计方法计算出，如历史CVR、CTR、流行度等。连续特征归一化后即可输入。本质是粗粒度的预测指标。与预测目标有较强相关性。

7.组合类特征

通过特征组合生成的新特征，如年龄加性别组成的人口属性分段特征。

#### 常用的特征处理方法

模型输入往往是数字组成的特征向量。

1.连续性特征处理

归一化、离散化、加非线性函数等方法

![FE4](https://sunjc911.github.io/assets/images/DeepRec/FE4.png)

2.类别特征处理

one-hot和multi-hot

##### 什么是multi-hot

与多个物品的交互行为、一个东西被打上多个同类别标签等。一个用户买了10个东西，一共1000个，则10个东西打上1，其他为0。

问题：特征维度过大，过于稀疏导致欠拟合，权重参数过多导致收敛慢。所以后续用Embedding技术将其转化为稠密向量。

#### 特征工程与业务理解

从这个意义上讲，传统的人工特征组合、过滤的工作已经不存在了，取而代之的是将特征工程与模型结构统一思考、整体建模的深度学习模式。不变的是，只有深入了解业务的运行模式，了解用户在业务场景下的思考方式和行为动机，才能精确地抽取出最有价值的特征，构建成功的深度学习模型。

### 推荐系统召回层的主要策略

召回负责海量缩小到几百几千个，排序负责精准排序。前面的模型主要用于排序。

#### 召回层和排序层的功能特点

![R](https://sunjc911.github.io/assets/images/DeepRec/R.png)

**召回层**:待计算的候选集合大、速度快、模型简单、特征较少，尽量让用户感兴趣的物品在这个阶段能够被快速召回，即保证相关物品的召回率。
**排序层**:首要目标是得到精准的排序结果。需处理的物品数量少，可利用较多特征使用比较复杂的模型。

召回层如何平衡计算速度和召回率？多路召回

#### 多路召回策略

所谓“多路召回策略”，就是指采用不同的策略、特征或简单模型，分别召回一部分候选集，然后把候选集混合在一起供后续排序模型使用的策略。
可以明显地看出，“多路召回策略”是在“计算速度”和“召回率”之间进行权衡的结果其中，各简单策略保证候选集的快速召回，从不同角度设计的策略保证召回率接近理想的状态，不至于损害排序效果。

![R1](https://sunjc911.github.io/assets/images/DeepRec/R1.png)

**召回策略的选择与业务强相关。**K通过线上A/B测试确定合理的取值范围。

虽然多路召回是实用的工程方法，但从策略选择到候选集大小参数的调整**都需要人工参与**，**策略之间的信息也是割裂**的，无法综合考虑不同策略对一个物品的影响。那么，是否存在一个综合性强且计算速度也能满足需求的召回方法呢? 基于Embedding的召回方法
给出了可行的方案。

#### 基于Embedding的召回方法

深度学习得到Embedding后局部敏感哈希进行快速的Embedding最近邻计算。

多路召回中使用的信息都可以作为Embedding 的side information融进Embedding向量如EGES。相当于在利用Embedding召回的过程中，考虑到了多路召回的多种策略。

Embedding召回的另一个优势在于**评分的连续性**。多路召回中不同召回策略产生的相似度、热度等分值不具备可比性，无法据此决定每个召回策略放回候选集的大小。Embedding召回可以把Embedding间的**相似度作为唯一的判断标准**，因此可以随意限定召回的候选集大小。
生成Embedding的方法也绝不是唯一的，除了第4章介绍的Item2vec、Graph Embedding等方法，矩阵分解、因子分解机等简单模型也完全可以得出用户和物品的Embedding向量。在实际应用中可以根据效果确定最优的召回层Embedding的生成方法。

### 推荐系统的实时性

#### 为什么重要

模型更新的间隔时间越长，推荐系统的效果越差:反过来说，模型更新得越频繁，实时性越好，损失越小，效果越好。

用户角度当然希望快速刷到自己感兴趣的。只要推荐系统能感知用户反馈、实时地满足用户的期望目标，就能提高推荐的效果，这就是推荐系统“实时性”作用的直观体现。

从机器学习的角度讲，推荐系统实时性的重要之处体现在以下两个方面:
(1) 推荐系统的更新速度越快，代表用户最近习惯和爱好的特征更新越快，越能为用户进行更有时效性的推荐
(2) 推荐系统更新得越快，模型越容易发现最新流行的数据模式 (data pattern)越能让模型快速抓住最新的流行趋势。
这两方面的原因直接对应着推荐系统实时性的两大要素:一是推荐系统“特征”的实时性:二是推荐系统“模型”的实时性。

#### 推荐系统”特征“的实时性

实时收集和更新输入特征，使推荐系统总使用最新的特征进行预测和推荐。实时性差会丧失最可能增加用户粘性和留存度的时机。

![T](https://sunjc911.github.io/assets/images/DeepRec/T.png)

1.客户端实时特征

在一次session中用户点击三个物品。很显然是即时兴趣，如果及时改变推荐结果，用户体验增加。

如果采用传统的流计算平台 (图5-7中的Flink) ，甚至批处理计算平台 (图5-7中的Spark) ，则由于延迟问题，;系统可能无法在3分钟之内就把session内部的行为历史存储到特征数据库(如Redis)中，这就导致用户的推荐结果不会马上受到session内部行为的影响无法做到推荐结果的实时更新。
如果客户端能够缓存 session 内部的行为，将其作为与上下文特征同样的实时特征传给推荐服务器，那么推荐模型就能够实时地得到 session 内部的行为特征，进行实时的推荐。这就是利用客户端实时特征进行实时推荐的优势所在。

2.流计算平台的准实时特征处理

Storm、Spark、Flink进行准实时特征处理是推荐系统的标配。

所谓流计算平台，是**将日志以流的形式进行微批处理** (mini batch) 。由于每次需要等待并处理一小批日志，流计算平台**并非完全实时**的平台，但它的优势是能够进行一些简单的统计类特征的计算，比如一个物品在该时间窗口内的曝光次数，点击次数、一个用户在该时间窗口内的点击话题分布，等等。
流计算平台计算出的特征**可以立刻存入特征数据库供推荐模型使用**。虽然无法实时地根据用户行为改变用户结果，但**分钟级别的延迟**基本可以保证推荐系统能够准实时地引入用户的近期行为。

3.分布式批处理平台的全量特征处理

HDFS为主的分布式存储系统，Spark等分布式批处理计算平台，进行全量特征的计算和提取。

用途：模型训练和离线评估；特征保存入特征数据库，供之后的线上模型使用。

无法满足实施推荐，但用户下次登录时进行更准确的推荐。

#### 推荐系统”模型“的实时性

从更全局的角度考虑问题。

特征的实时性力图用更准确的特征描述用户、物品和相关场景，从而让推荐系统给出更符合当时场景的推荐结果。而模型的实时性则是希望更快地抓住全局层面的新数据模式，发现新的趋势和相关性。

以某电商网站“双11”的大量促销活动为例，特征的实时性会根据用户最近的行为更快地发现用户可能感兴趣的商品，但绝对不会发现一个刚刚流行起来的爆款商品、一个刚刚开始的促销活动，以及与该用户相似的人群最新的偏好。要发现这类全局性的数据变化，需要实时地更新推荐模型。

![T1](https://sunjc911.github.io/assets/images/DeepRec/T1.png)

1.全量更新

“全量更新”是指模型利用某时间段内的所有训练样本进行训练。全量更新是最常用的模型训练方式，但它需要等待所有训练数据都“落盘”(记录在HDFS等大数据存储系统中)才可进行，并且训练全量样本的时间往往较长，因此全量更新也是实时性最差的模型更新方式。与之相比，“增量更新”的训练方式可以有效提高训练效率。

2.增量更新

增量更新仅将新加入的样本“喂”给模型进行增量训练。从技术上讲，深度学习模型往往采用随机梯度下降(SGD) 法及其变种进行学习，模型对增量样本的学习相当于在原有样本的基础上继续输入增量样本进行梯度下降。增量更新的缺点是:增量更新的模型往往无法找到全局最优点，因此在实际的推荐系统中，经常采用增量更新与全局更新相结合的方式，在进行了几轮增量更新后，在业务量较小的时间窗口进行全局更新，纠正模型在增量更新过程中积累的误差。

3.在线学习

在线学习是进行模型实时更新的主要方法，也就是在获得一个新的样本的同时更新模型。与增量更新一样，在线学习在技术上也通过SGD的训练方式实现，但由于需要在线上环境进行模型的训练和大量模型相关参数的更新和存储，工程上的要求相对比较高。

在线学习的另一个附带问题是模型的稀疏性不强，例如，在一个输入特征向量达到几百万维的模型中，如果模型的稀疏性好，就可以在模型效果不受影响的前提下，仅让极小部分特征对应的权重非零，从而让上线的模型体积很小(因为可以摒弃所有权重为 0的特征)，这有利于加快整个模型服务的过程。但如果使用SGD的方式进行模型更新，相比batch的方式，容易产生大量小权重的特征，这就增大了模型体积，从而增大模型部署和更新的难度。为了在在线学习过程中兼顾训练效果和模型稀疏性，有大量相关的研究，最著名的包括微软的FOBOS[1]、谷歌的FTRL[2]等，
在线学习的另一个方向是将强化学习与推荐系统结合，在3.10节介绍的强化学习推荐模型 DRN 中，应用了一种竞争梯度下降算法，它通过“随机探索新的深度学习模型参数并根据实时效果反馈进行参数调整”的方法进行在线学习，这是在强化学习框架下提高模型实时性的有效尝试。

4.局部更新

提高模型实时性的另一个改进方向是进行模型的局部更新，大致的思路是降低训练效率低的部分的更新频率，提高训练效率高的部分的更新频率。这种方式的代表是Facebook的“GBDT+LR”模型。
2.6节已经介绍过“GBDT+LR”的模型结构，模型利用GBDT进行自动化的特征工程利用 LR拟合优化目标。GBDT是串行的，需要依次训练每一棵树，因此训练效率低，更新的周期长，如果每次都同时训练“GBDT+LR”整个模型，那么GBDT的低效问题将拖慢IR的更新速度。为了兼顾GBDT的特征处理能力和 LR 快速拟合优化目标的能力，Facebook采取的部署方法是每天训练一次GBDT模型，固定GBDT模型后，实时训练LR模型以快速捕捉数据整体的变化。通过模型的局部更新，做到GBDT和LR能力的权衡。
“模型局部更新”的做法较多应用在“Embedding层+神经网络”的深度学习模型中，Embedding层参数由于占据了深度学习模型参数的大部分，其训练过程会拖慢模型整体的收敛速度，因此业界往往采用 **Embedding 层单独预训练，Embedding层以上的模型部分高频更新的混合策略，这也是“模型局部更新”思想的又一次应用。**

5.客户端模型实时更新

在本节介绍“特征”实时性的部分，提到了客户端“实时特征”的方法。既然客户端是最接近用户的部分，实时性最强，那么能否在客户端就根据当前用户的行为历史更新模型呢？

客户端模型实时更新在推荐系统业界仍处于探索阶段。对于一些计算机视觉类的模型可以通过模型压缩的方式生成轻量级模型，部署于客户端，但对于推荐模型这类“重量级”的模型，往往需要依赖服务器端较强大的计算资源和丰富的特征数据进行模型服务。但客户端往往可以保存和更新模型一部分的参数和特征，比如当前用户的Embedding向量。

这里的逻辑和动机是，在深度学习推荐系统中，模型往往要接受用户Embedding和物品Embedding两个关键的特征向量。对于物品Embedding的更新，一般需要全局的数据,因此只能在服务器端进行更新;而对用户Embedding来说，则更多依赖用户自身的数据那么把用户Embedding的更新过程移植到客户端来做，能实时地把用户最近的行为数据反映到用户的Embedding中来，从而可以在客户端通过实时改变用户Embedding的方式完成推荐结果的实时更新。
这里用一个最简单的例子来说明该过程。如果用户Embedding是由用户点击过的物品Embedding进行平均得到的，那么最先得到用户最新点击物品信息的客户端，就可以根据用户点击物品的Embedding实时更新用户Embedding，并保存该Embedding。在下次推荐时将更新后的用户Embedding传给服务器，服务器端可根据最新的用户Embedding返回实
时推荐内容。

#### ”木桶理论“看待推荐系统的迭代升级

”抓住一点，重点提升“是工程师应该采取的策略。这一点是木桶理论里最短的木板。替换或者改进它。

从更高的角度看待整个推荐系统的迭代升级问题，“木桶理论”也同样适用。推荐系统的模**型**部分和工程部分总是**迭代进行、交替优化**的。当通过改进模型增加推荐效果的尝试受阻或者成本较高时，可以将优化的方向聚焦在工程部分，从而达到花较少的精力，达成更显著效果的目的。

### 如何合理设定推荐系统中的优化目标

某知名互联网人物说过:“不要用战术上的勤奋掩盖战略上的懒惰”。这句话同样适用于技术的创新和应用。如果一项技术本身是新颖的、先进的，但应用的方向与实际需求的方向有偏差，那这项技术的成果不可能是显著的。**在推荐系统中，如果你的推荐模型的优化目标是不准确的，即使模型的评估指标做得再好，也肯定与实际所希望达到的目标南辕北辙**。所以，不要犯战略性的失误、合理设定推荐系统的优化目标是每位推荐工程师在构建推荐系统之前应该着重思考的问题。
设定一个“合理”的推荐系统优化目标，首先需要确立一个“合理”的原则。对一家商业公司而言，在绝大多数情况下，推荐系统的目标都是完成某个商业目标，所以根据公司的商业目标来制定推荐系统的优化目标理应作为“合理”的战略性目标。下面通过YouTube和阿里巴巴推荐系统的例子进一步说明这一点。

#### YouTube以观看时长为优化目标的合理性

YouTube的主要商业模式是免费视频带来的广告收入，它的视频广告会阶段性地出现在视频播放之前和视频播放的过程中，因此YouTube的广告收入是与用户观看时长成正比的。为了完成公司的商业目标，YouTube推荐系统的优化目标并不是点击率、播放率等通常意义上的 CTR 预估类的优化目标，而是用户的播放时长。
不可否认的是，点击率等指标与用户播放时长有相关性，但二者之间仍存在一些“优化动机”上的差异。如果以点击率为优化目标，那么推荐系统会倾向于推荐“标题党”“预览图劲爆”的短视频，而如果以播放时长为优化目标，那么推荐系统应将视频的长短、视频的质量等特征考虑进来，此时推荐一个高质量的“电影”或“连续剧”就是更好的选择。推荐目标的差异会导致推荐系统倾向性的不同，进而影响到能否完成“增加用户播放时长”这商业目标。
在YouTube的推荐系统排序模型(如图5-9所示) 中，引入播放时长作为优化目标的方式非常巧妙。YouTube排序模型原本是把推荐问题当作分类问题对待的，即预测用户是
否点击某个视频。既然是分类问题，理论上应很难预测播放时长(预测播放时长应该是回归模型做的事情)。但 YouTube 巧妙地把播放时长转换成正样本的权重，输出层利用加权逻辑回归(Weighted Logistic) 进行训练，预测过程中利用e^{Wx+b}算式计算样本的概率 (Odds) ，这概率就是模型对播放时长的预测(这里的论证并不严谨，在8.3节中还会进一步讨论YouTube排序模型的推断过程) 。

YouTube对于播放时长的预测符合其广告赢利模式和商业利益，从中也可以看出制定个合理的优化目标对于实现推荐系统的商业目标是必要日关键的。

![T2](https://sunjc911.github.io/assets/images/DeepRec/T2.png)

相比视频类公司，对阿里巴巴等电商类公司来说，自然不存在播放时长这样的指标，那么阿里巴巴在设计其推荐系统优化目标时，考虑的关键因素有哪些呢?

#### 模型优化和应用场景的统一性

优化目标的制定还应该考虑的要素是模型优化场景和应用场景的统一性，在这一点上阿里巴巴的多目标优化模型给出了一个很好的例子。
在天猫、淘宝等电商类网站上做推荐，用户从登录到购买的过程可以抽象成两步:(1) 产品曝光，用户浏览商品详情页。
(2) 用户产生购买行为。
与YouTube等视频网站不同，对电商类网站而言，公司的商业目标是通过推荐使用户产生更多的购买行为。按照“优化目标应与公司商业目标一致”的原则，电商类推荐模型应该是一个CVR预估模型。
由于购买转化行为是在第二步产生的，因此在训练 CVR 模型时，直观的做法是采用点击数据+转化数据(图 5-10 中灰色和深灰色区域数据) 练 CVR 模型。在使用CVR模型时，因为用户登录后直接看到的并不是具体的商品详情页，而是首页或者列表页，因此CVR模型需要在产品曝光的场景(图5-10中最外层圈内的数据) 下进行预估。这就导致了训练场景与预估场景不一致的问题。模型在不同的场景下肯定会产生有偏的预估结果，进而导致应用效果的损失

![T3](https://sunjc911.github.io/assets/images/DeepRec/T3.png)

为了达到同时优化CTR和CVR模型的目的，阿里巴巴提出了多目标优化模型ESMM(Entire Space Multi-task Model) [4]。ESMM可以被当作一个同时模拟“曝光到点击”和“点击
到转化”两个阶段的模型。从模型结构(如图5-11) 上看，底层的Embedding层是CVR部分和CTR部分共享的，共享 Embedding层的目的主要是解决 CVR任务正样本稀疏的问题，利用CTR的数据生成更准确的用户和物品的特征表达。
中间层是CVR部分和CTR部分各自利用完全隔离的神经网络拟合自己的优化目标一pCVR (post-click CVR，点击后转化率)和 pCTR(post-view Click-through Rate，曝光后点击率) 。最终，将pCVR和pCTR相乘得到pCTCVR。

![T4](https://sunjc911.github.io/assets/images/DeepRec/T4.png)

ESMM同时将pCVR、PCTR和pCTCVR融合进一个统一的模型，因此模型可以一次性得出所有三个优化目标的值，在模型应用的过程中，也可以根据合适的应用场景选择与之相对应的目标进行预测。正因如此，阿里巴巴通过构建ESMM这一多目标优化模型同时解决了“训练空间和预测空间不一致”及“同时利用点击和转化数据进行全局优化”两个关键的
问题。无论是YouTube，还是阿里巴巴，虽然他们的推荐系统的模型结构截然不同，但在设计推荐系统优化目标时，他们都充分考虑了真正的商业目标和应用场景，力图在训练模型的阶段“仿真”预测阶段的场景和目标，这是读者在设计自己的推荐系统时首先要遵循的原则。

#### 优化目标是和其他团队的接口性工作

需要协调一致，才能共同完成推荐系统的商业目标。

在协调的过程中，技术团队抱怨产品团队频繁修改需求，产品团队抱怨技术团队没有充分理解他们的设计意图，二者之间往往有结构性的矛盾。如果找一个最可能的切入点，最大限度地解耦产品团队和技术团队的工作，那么最合适的点就是推荐系统优化目标的设计。
只有设定好合适的优化目标，技术团队才能够专心于模型的改进和结构的调整，避免把过于复杂晦涩的推荐系统技术细节暴露给外界。而产品团队也只有设定好合理的优化目标，才能让推荐系统服务于公司的整体商业利益和产品整体的设计目标。诚然，这个过程少不了各团队之间的矛盾、妥协与权衡，但只有在动手解决问题之前协商好优化目标，才能在今后的工作中最大限度地避免战略性的错误和推诿返工，尽可能最大化公司的商业利益和各团队的工作效率。

### 推荐系统中比模型结构更重要的是什么

#### 有解决推荐问题的”银弹“吗？

到这里也基本可以给出题目中问题的答案了--在构建推荐模型的过程中，从应用场景出发，基于用户行为和数据的特点，提出合理的改进模型的动机才是最重要的。
换句话说，推荐模型的结构不是构建一个好的推荐系统的“银弹”，**真正的“银弹”是你对用户行为和应用场景的观察，基于这些观察，改进出最能表达这些观察的模型结构。**下面用三个例子对这句话做进一步的解释。

#### Netflix对用户行为的观察

发现除了影片的排序，海报也是影响点击率的重要元素。通过A/B测试后着手对预览图生成进行优化，以提高推荐结果整体的点击率。

使用简单的线性”探索和利用“模型验证哪种组合文字图片组合才是最适合用户的个性化海报。

**从用户和场景出发解决问题。**

#### 观察用户行为，在模型中加入有价值的用户信息

缺少点击和播放样本，怎么解决数据稀疏问题？

**从用户的角度理解问题，发现有价值的信号。**

广义上讲，引入新的有价值信息相当于为推荐系统增加新的“水源”，而改进模型结构则是对已有“水源”的进一步挖掘。通常，新水源带来的收益更高，开拓难度却小于对已有水源的持续挖掘。

#### DIN模型的改进动机

出发点同样是**用户行为特点。**

天猫、淘宝作为综合性的电商网站，**只有收集与候选物品相关的用户历史行为记录才是有价值的**。基于这个出发点，引入相关物品的开关和权重结构，最终发现注意力机制恰巧是能够解释这个动机的最合适的技术结构。反过来，如果单纯从技术角度出发，为了验证注意力机制是否有效而应用注意力机制，则有“本末倒置”的嫌疑，因为这不是业界解决问题的常规思路，而是试探性的技术验证过程，这种纯“猜测”型的验证无疑会大幅增加工作量。

#### 算法工程师不能只是”炼金术士“

从用户的角度思考问题，构建模型。

### 冷启动的解决办法

具体地讲，冷启动问题根据数据匮乏情况的不同，主要分为三类:

(1) 用户冷启动，新用户注册后，没有历史行为数据时的个性化推荐。
(2) 物品冷启动，系统加入新物品后(新的影片、新的商品等) ，在该商品还没有交互记录时，如何将该物品推荐给用户。
(3) 系统冷启动，在推荐系统运行之初，缺乏所有相关历史数据时的推荐。

针对不同应用场景，解决冷启动问题需要比较专业的洞察，根据领域专家意见制定合理的冷启动策略。总体上讲，可以把主流的冷启动策略归为以下三类:
(1) 基于规则的冷启动过程。
(2) 丰富冷启动过程中可获得的用户和物品特征。
(3) 利用主动学习、迁移学习和“探索与利用”机制。

#### 基于规则的冷启动过程

在冷启动过程中，由于数据的缺乏，个性化推荐引擎无法有效工作，自然可以让系统回退到“前推荐系统”时代，采用基于规则的推荐方法。例如，在用户冷启动场景下，可以使用“热门排行榜”“最近流行趋势”“最高评分”等**榜单作为默认的推荐列表**。事实上，大多数音乐、视频等应用都是采用这类方法作为冷启动的默认规则。
更进一步，可以参考专家意见建立一些个性化物品列表，根据用户有限的信息，例如注册时填写的年龄、性别、基于 IP 推断出的地址等信息做**粗粒度的规则推荐**。例如，利用点击率等目标构建一个用户属性的决策树，在每个决策树的叶节点建立冷启动榜单，在新用户完成注册后，根据用户有限的注册信息，寻找决策树上对应的叶节点榜单，完成用户冷启动过程。
在物品冷启动场景下，可以根据一些规则找到该物品的相似物品，利用相似物品的推荐逻辑完成物品的冷启动过程。当然，寻找相似物品的过程是与业务强相关的。本节以Airbnb为例说明该过程。通过价格、房屋属性、距离进行聚类得到新商品的Embedding。

依赖领域专家对业务的洞察。

#### 丰富冷启动过程中可获得的用户和物品特征

基于规则的冷启动与模型是割裂的。

该方法在模型中加入更多用户或者物品的属性特征，而非历史数据特征。

属性特征可以用于粗粒度推荐。包括：用户注册信息，第三方DMP，物品内容特征，引导用户输入的冷启动特征。

#### 利用主动学习、迁移学习和”探索与利用“机制

1.主动学习

主动学习不仅利用已有数据进行建模，还会主动发现哪些数据是急需的，发出询问，获得反馈，加速过程。

![T5](https://sunjc911.github.io/assets/images/DeepRec/T5.png)

与强化学习一脉相承。

2.迁移学习

迁移其他领域的知识。如ESSM模型，CTR模型生成的Embedding共享给CVR模型。

3."探索与利用"机制

“探索与利用”机制是解决冷启动问题的另一个有效思路。简单地讲，探索与利用是在**“探索新数据”和“利用旧数据”之间进行平衡**，使系统既能利用旧数据进行推荐，达到推荐系统的商业目标，又能高效地探索冷启动的物品是否是“优质”物品，使冷启动物品获得曝光的倾向，快速收集冷启动数据。
这里以最经典的探索与利用方法UCB (Upper Confidence Bound，置信区间上界)[7]讲解探索与利用的原理。
(式 5-2) 是用 UCB方法计算每个物品的得分的公式。其中 x_j为观测到的第j个物品的平均回报(这里的平均回报可以是点击率、转化率、播放率等) ，n_j为目前为止向用户曝光第j个物品的次数，n 为到目前为止曝光所有物品的次数之和。

![T6](https://sunjc911.github.io/assets/images/DeepRec/T6.png)

#### ”巧妇难为无米之炊“的困境

米：数据；巧妇：算法工程师

没米搞点粗粮先。即利用粗粒度的特征、属性进行冷启动先。

边吃边买米。利用冷启动的机制解决冷启动问题，一步一步使得Embedding准确。

### 探索与利用

不仅要捞鱼塘里的老鱼，还要往里加鱼苗。

这里的“捞鱼”行为指的就是推荐系统一味使用历史数据，根据用户历史进行推荐，不注重发掘用户新的兴趣、新的优质物品。那么，“投放鱼苗”的行为自然就是推荐系统主动试探用户新的兴趣点，主动推荐新的物品，发掘有潜力的优质物品。
给用户推荐的机会是有限的，推荐用户喜欢的内容和探索用户的新兴趣这两件事都会占用宝贵的推荐机会，在推荐系统中应该如何权衡这两件事呢?这就是“探索与利用”试图解决的问题。

三大类方法：

(1) 传统的探索与利用方法: 这类方法将问题简化成多臂老虎机问题。主要的算法有e-Greedy (e贪婪)、Thompson Sampling (汤普森采样)和 UCB。该类解决方法着重解决新物品的探索和利用，方法中并不考虑用户、上下文等因素，因此是非个性化的探索与
利用方法。

(2) 个性化的探索与利用方法: 该类方法有效地结合了个性化推荐特点和探索与利用的思想，在考虑用户、上下文等因素的基础上进行探索与利用的权衡，因此被称为个性化探索与利用方法。

(3) 基于模型的探索与利用方法: 该类方法将探索与利用的思想融入推荐模型之中将深度学习模型和探索与利用的思想有效结合，是近年来的热点方向。

#### 传统的探索与利用方法

主要是解决多臂老虎机问题（Multi-Armed Bandit problem，MAB）

##### 基础知识——多臂老虎机

一个人看到一排老虎机(一种有一个摇臂的机器，投入一定金额，摇动摇臂，随机获得一定收益)，它们的外表一模一样，但每个老虎机获得回报的期望不同，刚开始这个人不知道这些老虎机获得回报的期望和概率分布，如果有N次机会，按什么顺序选择老虎机可以收益最大化呢? 这就是多臂老虎机问题(如图5-17所示)。

![T7](https://sunjc911.github.io/assets/images/DeepRec/T7.png)

###### 1.ε-Greedy算法

ε-Greedy算法的主要流程是: 选一个[0，1]的数ε，每次以ε的概率在所有老虎机中进行随机选择，以(1-ε)的概率选择截至当前平均收益最大的老虎机，在摇臂后，根据回报值对老虎机的回报期望进行更新。
这里ε的值代表对“探索”的偏好程度，每次以概率ε去“探索”，以 (1-ε) 的概率来“利用”，基于被选择的物品的回报更新该物品的回报期望。本质上讲，“探索”的过程其实是一个收集未知信息的过程，而“利用”的过程则是对已知信息的“贪心”利用过程，ε这一概率值正是“探索”和“利用”的权衡点。

ε-Greedy算法是非常简单实用的探索与利用算法，但其对探索部分和利用部分的划分还略显粗暴和生硬。例如，在进行了一段时间的探索后，再进行探索的收益已经没有之前大了，这时应该逐渐减小e的值，增加利用部分的占比:另外，对每个老虎机进行完全“随机”的探索也不是高效的探索策略，例如有的老虎机已经积累了丰富的信息，不用再进行探索来收集信息了，这时就应该让探索的机会更倾向于那不常被选择的老虎机。为了改进ε-Greedy算法的这些缺陷，启发式探索与利用算法被提出。

###### 2.汤普森采样算法

Thompson Sampling[8]是一种经典的启发式探索与利用算法。该算法假设每个老虎机能够赢钱(这里假设赢钱的数额一致)的概率是p，同时概率p的分布符合beta (win，lose)分布，每个老虎机都维护一组beta分布的参数，即win，lose。每次试验后，选中一个老虎机，摇臂后，有收益(这里假设收益是二值的，0或1) 则该老虎机的win参数增加1，否则该老虎机的lose参数增加1。
每次选择老虎机的方式是:利用每个老虎机现有的beta分布产生一个随机数b，逐一生成每个老虎机的随机数，选择随机数中最大的那个老虎机进行尝试。综上，Thompson Sampling算法流程的伪代码如代码5-2所示。

![T8](https://sunjc911.github.io/assets/images/DeepRec/T8.png)

![T9](https://sunjc911.github.io/assets/images/DeepRec/T9.png)

通过Thompson Sampling选择下一次行动时，action 3的收益期望是三者中最低的，如果按照纯“利用”的思路，是不应该选择action 3这个“老虎机”的; 但基于 action 3 的 beta 分布图形，可以很明显地看出其概率分布有一部分落在action 1和action 2概率分布右侧，而
且概率并不小 (10%~20%)。也就是说，通过Thompson Sampling选择action 3这一“老虎机”的机会并不小。这就利用了Thompson Sampling对新物品的倾向性。

###### 3.UCB算法

![T10](https://sunjc911.github.io/assets/images/DeepRec/T10.png)

对于 UCB 的一系列严格证明涉及更多的理论知识，在此不再过多扩展。只需要定性地清楚 UCB 的上界形式相当于老虎机收益期望的严格的置信区间即可。
UCB和Thompson Sampling都是工程中常用的探索与利用方法，但这类传统的探索与利用方法无法解决引入个性化特征的问题。这严重限制了探索与利用方法在个性化推荐场景下的使用，为此，个性化的探索与利用方法被提出。

#### 个性化的探索与利用方法

传统的探索与利用方法的弊端是无法引入用户的上下文和个性化信息，只能进行全局性的探索。事实上，在用户冷启动场景下，即使是已经被探索充分的商品，对于新用户仍是陌生的，用户对于这个商品的态度是未知的:另外，一个商品在不同上下文中的表现也不尽相同，比如一个商品在首页的表现和在品类页的表现很可能由于页面上下文环境的变化而截然不同。因此，在传统的探索与利用方法的基础上，引入个性化信息是非常重要的这类方法通常被称为基于上下文的多臂老虎机算法(Contextual-Bandit Algorithm)，其中最具代表性的算法是2010年由雅虎实验室提出的LiUCB算法[9]。俺不懂。

#### 基于模型的探索与利用方法

无论是传统的探索与利用方法，还是以LinUCB为代表的个性化的探索与利用方法，都存在一个显著的问题一-无法与深度学习模型进行有效的整合。例如，对LinUCB来说应用的前提就是假设推荐模型是一个线性模型，如果把预测模型改为一个深度学习模型
那么LinUCB的理论框架就不再自洽了。如果 CTR 预测模型或者推荐模型是一个深度学习模型，那么如何将探索与利用的思想与模型进行有效整合呢? 这里要再次回顾 3.10 节介绍的强化学习模型DRN。在DRN中，对于已经训练好的当前网络Q，通过对其模型参数W添加一个较小的随机扰动AW，得到新的模型参数，这里称W对应的网络为探索网络O。再通过系统的实时效果反馈决定是保留探索网络O还是沿用当前网络Q。
可以看出，DRN 对于深度学习模型的探索过程是非启发式的，但这种与模型结构无关的方法也使 DRN 中的模型探索方式适用于任何深度学习模型。它有效地把探索与利用的思想与深度学习模型结合起来，通过对模型参数随机扰动的方法探索式地优化模型。与此同时，模型参数的随机扰动也带来了推荐结果的变化和更新，自然实现了对不同内容的探索，这是“探索与利用”的思想在DRN模型中的直接体现。

#### ”探索与利用“机制在推荐系统中的应用

(1)物品冷启动。对新加入的物品或者长久没有互动信息的长尾物品来说，探索与利用算法对**新物品和长尾物品有天然的倾向性**，因此可以帮助这类物品快速收集用户反馈，快速度过冷启动期，并在较少伤害系统整体收益的前提下，快速找到有潜力的物品，丰
富优质的物品候选集。

(2) 发掘用户新兴趣。本节开头已经介绍过，如果推荐系统总是利用现有数据为用户推荐物品，相当于对用户的已发掘兴趣进行“涸泽而渔”的利用，短期内用户可能满足于当前的推荐结果，但很可能快速疲倦并离开。为了发掘用户新兴趣，推荐系统有必要进行一定程度的探索，维持用户的长期兴趣。另外，用户兴趣本身也在不断的改变和进化，需要通过探索不断抓住用户兴趣改变的趋势。

(3) 增加结果多样性。探索与利用也是增加推荐结果多样性的手段。增加结果多样性对于推荐系统的好处主要有两方面，一方面是让用户能明显感觉到结果的丰富性:另一方面是减少大量同质化内容同时出现时用户的厌倦情绪。

总的来说，探索与利用思想是所有推荐系统不可或缺的补充。相比推荐模型的优化目标--利用已有数据做到现有条件下的利益最大化，探索与利用的思想实际上是着眼于未来的，着眼于用户的长期兴趣和公司的长期利益，算法工程师不仅需要充分理解这一点，更需要制定算法目标的决策者有更深的理解，做出更有利于公司长远发展的决策。

## 第六章 深度学习推荐系统的工程实现