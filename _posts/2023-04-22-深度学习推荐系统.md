---
title: 深度学习推荐系统
description: 
date: 2023-04-22
categories:
 - Rec面试
tags:
 - Rec
 - 面试
excerpt_separator: <!--more--> 

---

**加油**

<!--more-->

## 问题

[常见损失函数](https://blog.csdn.net/yanyuxiangtoday/article/details/119788949)

[L1L2正则化](https://zhuanlan.zhihu.com/p/137073968)

[梯度下降求导_LR](https://blog.csdn.net/qq_35890572/article/details/107123956)

[极大似然估计](https://lulaoshi.info/machine-learning/linear-model/maximum-likelihood-estimation.html#%E6%A6%82%E7%8E%87)

[GBDT系列](https://blog.csdn.net/XiaoYi_Eric/article/details/80167968)

随机梯度下降，批梯度下降等梯度下降法的区别

特征缩放，特征归一化等方法

[mAP和NDCG](https://zhuanlan.zhihu.com/p/485001411)

## 第一章 互联网的增长引擎——推荐系统

### 推荐系统的作用与意义

用户角度: 推荐系统解决在“信息过载”的情况下，用户如何高效获得感兴趣信息的问题。

公司角度:推荐系统解决产品能够最大限度地吸引用户、留存用户、增加用户黏性提高用户转化率的问题，从而达到公司商业目标连续增长的目的。需要注意的是，设计推荐系统的最终目标是达成公司的商业目标、增加公司收益这应是推荐工程师站在公司角度考虑问题的出发点。

### 推荐系统的架构

(1) 互联网企业的核心需求是“增长”，而推荐系统正处在“增长引擎”的核心位置(2) 推荐系统要解决的“用户痛点”是用户如何在“信息过载”的情况下高效地获得感兴趣的信息。

![1](https://sunjc911.github.io/assets/images/DeepRec/1.png)

### 推荐系统的模型部分

“**召回层**”一般利用高效的召回规则、算法或简单的模型，快速从海量的候选集中召回用户可能感兴趣的物品。
“**排序层（重点与研究重心）**”利用排序模型对初筛的候选集进行精排序。
“补充策略与算法层”，也被称为“再排序层**”，可以在将推荐列表返回用户之前，为兼顾结果的“多样性”“流行度”“新鲜度”等指标，结合一些补充的策略和算法对推荐列表进行定的调整，最终形成用户可见的推荐列表。

**模型权重**：**离线训练**的特点是可以利用全量样本和特征，使模型逼近全局最优点;**在线更新**则可以准实时地“消化”新的数据样本，更快地反映新的数据变化趋势，满足模型实时性的需求。

**评估模型效果**：离线评估和线上A/B测

## 第二章 前深度学习时代的重要算法

协同过滤、逻辑回归、因子分解机等传统推荐模型仍然凭借其可解释性强、硬件环境要求低易于快速训练和部署。

传统推荐模型是深度学习推荐模型的基础。

![2](https://sunjc911.github.io/assets/images/DeepRec/2.png)

### 协同过滤CF

“协同过滤”就是协同大家的反馈、评价和意见一起对海量的信息进行过滤从中筛选出目标用户可能感兴趣的信息的推荐过程。

![3](https://sunjc911.github.io/assets/images/DeepRec/3.png)

#### UserCF

##### 用户相似度计算

###### 余弦相似度

余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小。余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫"余弦相似性"。

![cos](https://sunjc911.github.io/assets/images/DeepRec/cos.png)

###### 皮尔逊相关系数

相比余弦相似度，皮尔逊相关系数通过使用用户平均分对各独立评分进行修正，减小了用户评分偏置的影响。

![p](https://sunjc911.github.io/assets/images/DeepRec/p.png)

![p2](https://sunjc911.github.io/assets/images/DeepRec/p2.png)

理论上，任何合理的“向量相似度定义方式”都可以作为相似用户计算的标准。

###### 最终结果的排序

![4](https://sunjc911.github.io/assets/images/DeepRec/4.png)

###### UserCF缺点

（1）用户数远大于物品数，用户相似度**矩阵开销大**，用户数增长时矩阵空间复杂度以n平方的速度增长，存储系统难以承受。

（2）用户历史数据**向量非常稀疏**，不适用于正反馈获取困难的场景。

#### ItemCF

构建物品相似度矩阵，相似度计算方法与UserCF相同。

···

(4) 利用物品相似度矩阵，针对目标用户历史行为中的正反馈物品，找出相似的Top k个物品，组成相似物品集合。
(5) 对相似物品集合中的物品，利用相似度分值进行排序，生成最终的推荐列表。在第5步中，如果一个物品与多个用户行为历史中的正反馈物品相似，那么该物品最终的相似度应该是多个相似度的累加，如(式2-5) 所示。·

![5](https://sunjc911.github.io/assets/images/DeepRec/5.png)

#### UserCF和ItemCF的应用场景

UserCF：社交、发现热点、跟踪热点、新闻

ItemCF：电商、视频推荐

#### 协同过滤的优缺点

优点：直观、可解释性强

缺点：不具备较强泛化能力，产生头部效应（热门商品容易和大量物品产生相似，冷门商品向量稀疏则反过来很少被推荐），处理稀疏向量的能力弱

### 矩阵分解MF

针对CF的头部效应明显、泛化能力较弱的问题。在CF**共现矩阵的基础**上，加入**隐向量**的概念，加强模型处理稀疏矩阵的能力，针对性地解决了协同过滤存在的主要问题。

矩阵分解算法则期望为每一个用户和视频生成一个隐向量，将用户和视频定位到隐向量的表示空间上，距离相近的用户和视频表明兴趣特点接近，在推荐过程中，就应该把距离相近的视频推荐给目标用户。任意用户与物品之间都可以得到预测分。

![6](https://sunjc911.github.io/assets/images/DeepRec/6.png)

用户和物品的隐向量通过CF的共现矩阵得到。

![MF](https://sunjc911.github.io/assets/images/DeepRec/MF.png)

mxn分解为mxk和kxn。k小隐向量小泛化能力高，反之则反。

![MF2](https://sunjc911.github.io/assets/images/DeepRec/MF2.png)

#### 矩阵分解的求解过程

##### 特征值分解ED

只适用于方阵，这里不行。

##### 奇异值分解SVD

![MF3](https://sunjc911.github.io/assets/images/DeepRec/MF3.png)

完美解决MF但有缺陷：

（1）要求共现矩阵稠密。共现矩阵稀疏，若要用需填充。

（2）计算复杂度O（mn平方）

##### 梯度下降GD（重要）

![GD](https://sunjc911.github.io/assets/images/DeepRec/GD.png)

##### 正则化

![reg](https://sunjc911.github.io/assets/images/DeepRec/reg.png)

q=1 L1正则化；2 L2正则化

对于加入了正则化项的损失函数来说，模型权重的值越大，损失函数越大。梯度下降是**朝着损失小的方向**发展的，因此正则化项其实是希望在尽量不影响原模型与数据集之间损失的前提下，**使模型的权重变小**，权重的减小自然会让模型的输出波动更小，从而达到**让模型更稳定**的目的。

可以加上偏差系数修正预测分数。

![7](https://sunjc911.github.io/assets/images/DeepRec/7.png)

##### 矩阵分解的优缺点

优点：泛化能力强，缓解数据稀疏问题；空间复杂度低（n+m）k；更好的扩展性和灵活性。

缺点：没发使用用户物品上下文特征。

### 逻辑回归LR

CF和MF利用相似度进行推荐。LR将推荐问题看作**分类问题**，预测正样本的概率对物品进行排序，转化为**点击率（Click Through Rate, CTR）**预估问题。综合利用用户物品上下文等特征。利用“感知机MLP”这种NN的基本单元，是深度学习的基础。

各特征加权和再施以sigmod函数

离散转为数值型特征向量，训练，得到点击物品的概率，根据概率排序进行推荐。

#### 数学形式

![LR1](https://sunjc911.github.io/assets/images/DeepRec/LR1.png)

![LR2](https://sunjc911.github.io/assets/images/DeepRec/LR2.png)

![LR3](https://sunjc911.github.io/assets/images/DeepRec/LR3.png)

![LR4](https://sunjc911.github.io/assets/images/DeepRec/LR4.png)

#### 权重训练——梯度下降法

目的是对目标函数求导，得到梯度方向，向对应梯度相反方向进行规定步长的迭代搜索，找到一个函数的局部最小值。反正为梯度上升法。

具体见问题章节内的内容

**利用模型的数学形式找出目标函数，并通过求导得到梯度下降的公式**

#### 逻辑回归的优缺点

优点：数学含义上的支撑；可解释性强；工程化的需要

缺点：表达能力不强，**只对单一特征做简单加权**，无法进行特征交叉、特征筛选等高级操作，会造成信息损失。

### POLY2

在LR的基础上对特征进行**暴力组合**，其中权重系数为单独的参数，非两个向量的内积（FM改进了这里）

![POLY1](https://sunjc911.github.io/assets/images/DeepRec/POLY1.png)

#### 缺陷

采用one-hot处理类别数据，导致向量极度稀疏，特征交叉后更稀疏，导致权重缺乏有效数据进行训练，无法收敛；权重参数数量n变为n平方。

### 因子分解机FM

为了解决POLY2的缺陷。

![FM1](https://sunjc911.github.io/assets/images/DeepRec/FM1.png)

用两个向量的内积取代了POLY2单一的权重系数。具体来说，**FM为每个特征学习一个隐向量权重。在特征交叉时，使用两个特征的隐向量的内积作为交叉特征的权重**，与MF异曲同工。把MF的用户物品的隐向量拓展到了所有特征上。

参数从POLY2的n平方变为nk，k为隐向量维度，n>>k。

#### 因子分解机的优缺点

优点：很好解决数据稀疏问题。虽然丢失某些具体特征组合的精确记忆能力，但是泛化能力大幅度提高。

### 特征域感知因子分解机FFM



基于FM，引入特征域感知，使模型表达能力更强。

![FFM1](https://sunjc911.github.io/assets/images/DeepRec/FFM1.png)

每个**特征对应**的不是唯一一个隐向量，而是**一组隐向量**。

![FFM2](https://sunjc911.github.io/assets/images/DeepRec/FFM2.png)

https://blog.csdn.net/weixin_44441131/article/details/119827464

引入更多有价值信息，表达能力更强，但是参数量为nkf，复杂度为kn平方。

### GBDT+LR——特征工程模型化的开端

如果做再高维度的特征交叉会组合爆炸和复杂度过高。

Facebook利用GBDT自动进行特征筛选和组合，进而生成新的离散特征向量，再把该特征向量当作LR模型输入，预测CTR的模型结构。GBDT和LR分别**独立**训练。

![GBDTLR1](https://sunjc911.github.io/assets/images/DeepRec/GBDTLR1.png)

#### GBDT

**决策树组成的森林**，学习方法是**梯度提升**。容易过拟合，会丢失大量特征的数值信息。

具体GBDT系列见问题章节内容。

![GBDT](https://sunjc911.github.io/assets/images/DeepRec/GBDT.png)

![GBDT1](https://sunjc911.github.io/assets/images/DeepRec/GBDT1.png)

![GBDT2](https://sunjc911.github.io/assets/images/DeepRec/GBDT2.png)

#### GBDT+LR开启特征工程新趋势

GBDT+LR组合模型的提出，意味着**特征工程可以完全交由一个独立的模型**来完成，模型的输入可以是原始的特征向量，**不必在特征工程上投入过多的人工筛选和模型设计的精力**，实现真正的**端到端** (End to End) 训练。

### 大规模分段线性模型LS-PLM（混合逻辑回归MLR）——阿里

Large Scale Piece-wise Linear Model， Mixed Logistic Regression

影响力大，与3层DNN相似。

在LR的基础上采用分而治之，先对样本进行分片，再在样本分片中应用LR进行CTR预估。

在LR基础上**加入聚类**，先对全量样本进行聚类，再对每个分类LR进行CTR预估。

![MLR1](https://sunjc911.github.io/assets/images/DeepRec/MLR1.png)

![MLR2](https://sunjc911.github.io/assets/images/DeepRec/MLR2.png)

#### 优势

端到端的非线性学习能力；模型的稀疏性强，建模引入L1、L2和1范数，使得模型具有较高的稀疏度，部署更加轻量级，效率高。

#### whyL1范数比L2范数更容易产生稀疏解？

左红L2，右红L1，蓝色为损失函数曲线。

![MLR3](https://sunjc911.github.io/assets/images/DeepRec/MLR3.png)

b图在顶点处相交，除了相切处维度不为零，其他都为0，所以更稀疏。

#### 从DL的角度审视LS-PLM

LS-PLM可以看作一个加入了注意力 (Attention) 机制的三层神经网络模型，其中输入层是样本的特征向量，中间层是由 m 个神经元组成的隐层，其中 m 是分片的个数，对于一个CTR预估问题，LS-PLM的最后一层自然是由单一神经元组成的输出层。

那么，注意力机制又是在哪里应用的呢? 其实是在隐层和输出层之间，神经元之间的权重是由分片函数得出的注意力得分来确定的。也就是说，样本属于哪个分片的概率就是其注意力得分。

### 总结

![21](https://sunjc911.github.io/assets/images/DeepRec/21.png)

![22](https://sunjc911.github.io/assets/images/DeepRec/22.png)

## 第三章 深度学习在推荐系统的应用

表达能力更强，结构更加灵活

![DL](https://sunjc911.github.io/assets/images/DeepRec/DL.png)

### AutoRec——单隐层神经网络推荐模型

自编码器与CF结合

#### 基本原理

**利用CF的共现矩阵，完成用户或物品向量的自编码**。再利用自编码的结果预估评分再排序。

##### 自编码器

指能够完成数据“自编码”的模型。将输入**转换成向量的形式**表达。假设其数据向量为 r，自编码器的作用是将向量r作为输入，通过自编码器后，得到的输出向量尽量接近其本身。

![AR1](https://sunjc911.github.io/assets/images/DeepRec/AR1.png)

一般来说，重建函数的参数数量远小于输入向量的维度数量，因此自编码器相当于完成了**数据压缩和降维**的工作。

经过自编码器生成的输出向量，由于经过了自编码器的“泛化”过程，**不会完全等同于输入向量**，也因此**具备了一定的缺失维度的预测能力**，这也是自编码器能用于推荐系统的原因。

#### AutoRec模型的结构

单隐层NN

![AR2](https://sunjc911.github.io/assets/images/DeepRec/AR2.png)

![AR3](https://sunjc911.github.io/assets/images/DeepRec/AR3.png)

##### 什么是神经元、神经网络、梯度反向传播

神经元（感知机）与神经网络

![AR4](https://sunjc911.github.io/assets/images/DeepRec/AR4.png)

![AR5](https://sunjc911.github.io/assets/images/DeepRec/AR5.png)

前向传播和反向传播

前向传播的目的是在当前网络参数的基础上得到模型对输入的预估值，也就是常说的模型推断过程。在得到预估值之后，就可以利用损失函数(Loss Function) 的定义计算模型的损失。

利用梯度下降法反向更新权重。利用求导过程中的链式法则。

#### 基于AutoRec模型的推荐过程

![AR6](https://sunjc911.github.io/assets/images/DeepRec/AR6.png)

#### 优缺点

优点：使用NN，有一定泛化和表达能力。

缺点：过于简单导致表达能力不足。

与Word2vec完全一致，但优化目标和训练方法不同。

### Deep Crossing——经典的深度学习框架

微软的深度学习框架在Rec中的完整应用。

完整地解决了从特征工程、稀疏向量稠密化、多层神经网络进行优化目标拟合等一系列深度学习在推荐系统中的应用问题，为后续的研究打下了良好的基础。

#### 应用场景

Bing搜索引擎中返回相关广告，尽可能增加其点击率。准确预测广告点击率并作为广告排序的指标之一，是非常重要的，且是该模型的优化目标。

分为三类特征。可被处理为one/multi-hot向量的类别特征；计数特征；进一步处理的特征。

![DR](https://sunjc911.github.io/assets/images/DeepRec/DR.png)

处理完特征后进行CTR预估。

深度学习网络的特点是可以根据需求灵活地对网络结构进行调整，从而达成**从原始特征向量到最终的优化目标的端到端的训练**目的。

#### 网络结构

为完成端到端的训练，Deep Crossing模型要在其内部网络中解决如下问题。

(1)离散类特征编码后过于稀疏，不利于直接输入神经网络进行训练，如何解决**稀疏特征向量稠密化**的问题。
(2) 如何解决**特征自动交叉组合**的问题
(3) 如何在输出层中**达成**问题设定的**优化目标**
Deep Crossing模型分别设置了不同的神经网络层来解决上述问题。如图3-6所示，其网络结构主要包括4层-Embedding层、Stacking层、Multiple Residual Units层和Scoring层。

![DR1](https://sunjc911.github.io/assets/images/DeepRec/DR1.png)

![DR2](https://sunjc911.github.io/assets/images/DeepRec/DR2.png)

Stacking层: Stacking层(堆叠层) 的作用比较简单，是把不同的Embedding特征和数值型特征**拼接**在一起，形成新的包含全部特征的特征向量，该层通常也被称为连接(concatenate )层。

![DR3](https://sunjc911.github.io/assets/images/DeepRec/DR3.png)

Scoring层: Scoring层作为输出层，就是为了拟合优化目标而存在的。对于**CTR 预估这类二分类问题**，Scoring 层往往使用的是逻辑回归模型，而对于图像分类等多分类问题Scoring层往往采用softmax模型。

##### 残差网络及特点

残差单元（Residual Unit）组成

![DR4](https://sunjc911.github.io/assets/images/DeepRec/DR4.png)

![DR5](https://sunjc911.github.io/assets/images/DeepRec/DR5.png)

传统MLP越深就过拟合，测试集表现越差。RU可以减少过拟合。

NN越深，**梯度消失**越严重。梯度消失现象是指在梯度反向传播过程中，越靠近输入端，梯度的幅度越小，参数收敛的速度越慢。为了解决这个问题，残差单元使用了 **ReLU 激活函数取代原来的sigmoid 激活函数**。此外，输入向量**短路**相当于直接把梯度毫无变化地传递到下一层，这也使残差网络的收敛速度更快。

#### DR对特征交叉方法的革命

将全部特征交叉的任务交给模型。只需要调整NN的深度进行特征之间的“深度交叉”。

### NeuralCF模型——CF与深度学习的结合

何向南YYDS

#### 深度学习视角重新审视矩阵分解模型

隐向量为Embedding，内积获得得分为输出层

#### 结构

多层神经网络+输出层 代替 MF中的内积操作。收益直观：一是让用户向量和物品向量做更**充分的交叉**，得到更多有价值的特征组合信息: 二是**引入更多的非线性特征**，让模型的表达能力更强。

![NCF](https://sunjc911.github.io/assets/images/DeepRec/NCF.png)

框住的是互操作层，将内积改为其他操作称为”广义矩阵分解“模型GMF。

NCF再进行stacking，使得模型有更强的特征组合和非线性能力。

![NCF1](https://sunjc911.github.io/assets/images/DeepRec/NCF1.png)

##### Softmax函数

作为输出层解决多分类问题的目标拟合问题。

![NCF2](https://sunjc911.github.io/assets/images/DeepRec/NCF2.png)

![NCF3](https://sunjc911.github.io/assets/images/DeepRec/NCF3.png)

往往与交叉熵损失函数一起用：

![NCF4](https://sunjc911.github.io/assets/images/DeepRec/NCF4.png)

![NCF5](https://sunjc911.github.io/assets/images/DeepRec/NCF5.png)

#### NCF优缺点

优点：隐向量改为Embedding，利用互操作特征交叉，灵活拼接。

缺点：基于CF，没有其他类型特征，浪费了其他有用信息，没有对互操作做进一步探究。

NN理论上能拟合任意函数。模型不是越复杂越好，要防止过拟合。复杂模型往往需要更多数据和更长训练时间。

### PNN——加强特征交叉能力

引入乘积层，给出特征交互方式的几种设计思路，用于解决CTR预估。

#### 网络架构

用product layer乘积层代替Deep Crossing中的stacking层，更加针对性地获取特征之间的交叉信息。

![PNN](https://sunjc911.github.io/assets/images/DeepRec/PNN.png)

可以输入更多特征。而不是NCF那样的。

#### Product层的多种特征交叉方式

该层由内积操作（图中z部分）和外积（outer product）操作（图中p部分）。

内积操作为经典的向量内积运算。

![PNN1](https://sunjc911.github.io/assets/images/DeepRec/PNN1.png)

![PNN2](https://sunjc911.github.io/assets/images/DeepRec/PNN2.png)

#### PNN优缺点

优点：强调Embedding向量之间的交叉方式是多样化的。更容易捕获特征的交叉信息。

缺点：外积中为效率而使用平**均池化会忽略原始特征中包含的有价值信息**。

如何使得特征交叉方式更高效，后续模型给出解决方案。

### Wide&Deep模型——记忆能力和泛化能力的综合

谷歌，单层Wide和多层Deep组成的混合模型。wide让模型具有较强的”记忆能力（memorization）“，deep使模型具有”泛化能力（generalization）“。正是这样的结构特点，使模型兼具了逻辑回归和深度神经网络的优点--**能够快速处理并记忆大量历史行为特征，并且具有强大的表达能力**，不仅在当时迅速成为业界争相应用的主流模型，而且衍生出了大量以Wide&Deep模型为基础结构的混合模型，**影响力一直延续到至今**。

#### 模型的记忆能力和泛化能力

“记忆能力”可以被理解为**模型直接学习并利用历史数据中物品或者特征的“共现频率”的能力**。一般来说，协同过滤、逻辑回归等简单模型有较强的“记忆能力”。由于这类模型的结构简单，原始数据往往可以直接影响推荐结果，产生类似于“如果点击过A，就推荐B”这类规则式的推荐，这就相当于模型直接记住了历史数据的分布特点，并利用这些记忆进行推荐。

![WD](https://sunjc911.github.io/assets/images/DeepRec/WD.png)

“泛化能力”可以被理解为**模型传递特征的相关性，以及发掘稀疏甚至从未出现过的稀有特征与最终标签相关性的能力**。矩阵分解比协同过滤的泛化能力强，因为矩阵分解引入了隐向量这样的结构，使得数据稀少的用户或者物品也能生成隐向量，从而获得有数据支撑的推荐得分，这就是非常典型的**将全局数据传递到稀疏物品上，从而提高泛化能力**的例子。再比如，深度神经网络通过特征的多次自动组合，可以深度发掘数据中潜在的模式，即使是非常稀疏的特征向量输入，也能得到较稳定平滑的推荐概率，这就是简单模型所缺乏的“泛化能力”

#### 模型结构

![WD1](https://sunjc911.github.io/assets/images/DeepRec/WD1.png)

Wide& Deep模型把单输入层的Wide部分与由Embedding层和多隐层组成的Deep部分连接起来，一起输入最终的输出层。单层的Wide部分善于处理大量稀疏的id类特征: Deep部分利用神经网络表达能力强的特点，进行深层的特征交叉，挖掘藏在特征背后的数据模式。最终，利用逻辑回归模型，输出层将 Wide部分和Deep部分组合起来，形成统一的模型。

![WD2](https://sunjc911.github.io/assets/images/DeepRec/WD2.png)

![WD3](https://sunjc911.github.io/assets/images/DeepRec/WD3.png)

#### Deep&Cross（DCN）——WD的进化

使用Cross网络代替Wide部分

![WD4](https://sunjc911.github.io/assets/images/DeepRec/WD4.png)

Corss网络的目的是**增加特征之间的交互力度**，使用多层交叉层（Cross layer）对输入向量进行特征交叉。

![WD5](https://sunjc911.github.io/assets/images/DeepRec/WD5.png)

二阶部分类似PNN的外积。

![WD6](https://sunjc911.github.io/assets/images/DeepRec/WD6.png)

#### Wide&Deep影响力

DeepFM、NFM等模型可以看作其延伸。

成功的关键：(1) **抓住**了业务问题的**本质**特点，能够**融合**传统模型记忆能力和深度学习模型泛化能力的**优势**。
(2) 模型的**结构并不复杂**，比较容易在工程上实现、训练和上线，这加速了其在业界的推广应用。

### FM与深度学习模型的结合

#### FNN——用FM的隐向量完成Embedding层初始化

![FNN](https://sunjc911.github.io/assets/images/DeepRec/FNN.png)

FNN在哪里与FM模型进行了结合呢？关键在于Embedding层的改进。

参数初始化如果运气不好极端，会导致Embedding层收敛慢。

##### 为什么Embedding层的收敛速度往往很慢

1.参数量巨大。权重占据整个网络权重的大部分。

2.输入向量过于稀疏。随机梯度下降只更新与非零特征相连的Embedding层权重。

针对此问题。FNN的解决思路是用FM模型训练好的各特征隐向量初始化Embedding层的参数。相当于引入先验，加速收敛过程。FM公式：

![FNN1](https://sunjc911.github.io/assets/images/DeepRec/FNN1.png)

w为1阶权重，v为二阶隐向量。

![FNN2](https://sunjc911.github.io/assets/images/DeepRec/FNN2.png)

![FNN3](https://sunjc911.github.io/assets/images/DeepRec/FNN3.png)

#### DeepFM——用FM代替Wide部分

![DFM](https://sunjc911.github.io/assets/images/DeepRec/DFM.png)

![DFM1](https://sunjc911.github.io/assets/images/DeepRec/DFM.png)

#### NFM——FM的神经网络化尝试

FM和FFM最多到二阶特征交叉，再高就组合爆炸，限制表达能力。能不能用NN来改进FM。

NFM用一个表达能力更强的函数替代原FM中二阶隐向量内积的部分。

![NFM](https://sunjc911.github.io/assets/images/DeepRec/NFM.png)

用下面的网络结构作为f（x）函数替代二阶

![NFM1](https://sunjc911.github.io/assets/images/DeepRec/NFM1.png)

![NFM2](https://sunjc911.github.io/assets/images/DeepRec/NFM2.png)

肚脐眼为element-wise product元素积，即对应元素相乘。

![NFM3](https://sunjc911.github.io/assets/images/DeepRec/NFM3.png)

#### 基于FM的深度学习模型的优缺点

优点：FNN、DeepFM、NFM都在经典多层NN的基础上加入了针对性的特征交叉操作，让模型具备更强的非线性表达能力。

缺点：特征工程的思路几乎穷尽，模型提升空间小。

### 注意力机制的应用

#### AFM——引入注意力机制的FM

NFM模型的延续。在NFM模型中，对特征交叉池化层后的特征向量进行”加和池化“，会“一视同仁”地对待所有交叉特征，不考虑不同特征对结果的影响程度，消解了有价值的信息。

AFM模型引入注意力机制是通过在特征交叉层和最终的输出层之间加入注意力网络实现。注意力网络的作用是为每一个交叉特征提供权重，也就是注意力得分。

![AFM](https://sunjc911.github.io/assets/images/DeepRec/AFM.png)

![AFM1](https://sunjc911.github.io/assets/images/DeepRec/AFM1.png)

![AFM2](https://sunjc911.github.io/assets/images/DeepRec/AFM1.png)

#### DIN——引入注意力机制的深度学习网络

更具有业务气息。应用于阿里巴巴的电商广告推荐。

![DIN](https://sunjc911.github.io/assets/images/DeepRec/DIN.png)

![DIN1](https://sunjc911.github.io/assets/images/DeepRec/DIN1.png)

![DIN2](https://sunjc911.github.io/assets/images/DeepRec/DIN2.png)

如果留意图3-24中的红线，可以发现商铺id只跟用户历史行为中的商铺 id序列发生作用，商品 id只跟用户的商品 id序列发生作用，因为注意力的轻重更应该由同类信息的相关性决定。
DIN模型与基于 FM的 AFM模型相比，是一次更典型的改进深度学习网络的尝试，而且由于出发点是具体的业务场景，也给了推荐工程师更多实质性的启发。

### DIEN——序列模型与推荐系统的结合

DIN的进化版本。创新在于用序列模型模拟了用户兴趣的进化过程。

#### DIEN的进化动机

历史行为都是一个随时间排序的序列。一定存在强或弱的前后依赖关系。AFM和DIN获得的注意力得分与时间无关，即序列无关。

序列信息的重要性：（1）加强最近行为对下次行为预测的影响。（2）序列模型能够学习到购买趋势的信息。

#### DIEN模型的架构

![DIEN](https://sunjc911.github.io/assets/images/DeepRec/DIEN.png)

![DIEN1](https://sunjc911.github.io/assets/images/DeepRec/DIEN1.png)

![DIEN2](https://sunjc911.github.io/assets/images/DeepRec/DIEN2.png)

#### 兴趣抽取层的结构

基本结构GRU门循环单元。相比于传统的RNN循环神经网络和LSTM长短期记忆网络。GRU解决了RNN的梯度消失问题。与LSTM相比，GRU的参数量更少，训练收敛速度更快。

![DIEN3](https://sunjc911.github.io/assets/images/DeepRec/DIEN3.png)

![DIEN4](https://sunjc911.github.io/assets/images/DeepRec/DIEN4.png)

#### 兴趣进化层的结构

最大特点：加入注意力机制。

![DIEN5](https://sunjc911.github.io/assets/images/DeepRec/DIEN5.png)

#### 序列模型对推荐系统的启发

具备强大的序列表达能力，非常适合预估用户经过一系列行为后的下一次动作。

模型复杂度较高，训练复杂度较高，服务过程中延迟大，增大其上线的难度，需要在工程上着重优化。

### 强化学习与推荐系统的结合

### 总结

![3o1](https://sunjc911.github.io/assets/images/DeepRec/3o1.png)

![3o2](https://sunjc911.github.io/assets/images/DeepRec/3o2.png)

![3o3](https://sunjc911.github.io/assets/images/DeepRec/3o3.png)

## 第四章 Embedding技术在推荐系统中的应用

### 什么是Embedding

用一个低维稠密的向量“表示”一个对象。“表示”意味着 Embedding向量能够表达相应对象的某些特征，同时向量之间的距离反映了对象之间的相似性。

#### Embedding的重要性

1.推荐中大量使用独热编码、id编码，导致极度稀疏，深度学习的结构特点不利于稀疏特征向量的处理。用Embedding层将高维稀疏转为低维稠密。所以为DL的基础操作。

2.本身就是重要的特征向量。表达能力更强，尤其是Graph Embedding技术提出后。

3.基于Embedding的相似度内积更适用于召回。

### Word2Vec——经典的Embedding方法

谷歌，使得词向量从NLP推广到搜广推领域。

#### 什么是Word2Vec

![WV](https://sunjc911.github.io/assets/images/DeepRec/WV.png)

T为句子长度，选择2c+1的滑动窗口。

![WV1](https://sunjc911.github.io/assets/images/DeepRec/WV1.png)

什么是输出向量表达和输入向量表达？

![WV2](https://sunjc911.github.io/assets/images/DeepRec/WV2.png)

![WV3](https://sunjc911.github.io/assets/images/DeepRec/WV3.png)

![WV4](https://sunjc911.github.io/assets/images/DeepRec/WV4.png)

#### Word2Vec的“负采样”训练方法

![WV5](https://sunjc911.github.io/assets/images/DeepRec/WV5.png)

![WV6](https://sunjc911.github.io/assets/images/DeepRec/WV6.png)

#### Word2Vec对Embedding技术的意义

牛逼。从另一个角度看，在 Word2vec 的研究中提出的模型结构、目标函数、负采样方法及负采样中的目标函数，在后续的研究中被重复使用并被屡次优化。掌握Word2vec 中的每个细节成了研究 Embedding 的基础。从这个意义上讲，熟练掌握本节内容非常重要。

### Item2vec——Word2vec在推荐系统领域的推广

Word2vec对词序列进行embedding，那么rec中可以对用户购买序列进行embedding。

#### 基本原理

利用用户向量和物品向量的相似性，可以直接在推荐系统的召回层快速得到候选集合，或在排序层直接用于最终推荐列表的排序。

![IV](https://sunjc911.github.io/assets/images/DeepRec/IV.png)

#### “广义”Item2vec

任何生成物品向量的方法都可以成为Item2vec。如双塔模型。

![IV1](https://sunjc911.github.io/assets/images/DeepRec/IV1.png)

![IV2](https://sunjc911.github.io/assets/images/DeepRec/IV2.png)

#### 优缺点

优点：推广Word2vec，大大拓展应用场景。广义上的Item2vec模型其实是物品向量化方法的统称。

缺点：只能利用序列数据。

### Graph Embedding——引入更多结构信息的图嵌入技术

![GE](https://sunjc911.github.io/assets/images/DeepRec/GE.png)

Graph Embedding是一种对图结构中的节点进行Embedding编码的方法。最终生成的节点 Embedding 向量一般包含图的结构信息及附近节点的局部相似性信息。

#### Deep Walk——基础的Graph Embedding方法

在由**物品组成的图结构**上进行随机游走，然后产生大量物品序列，然后作为样本输入到Word2vec进行训练，得到物品的Embedding。

![GE1](https://sunjc911.github.io/assets/images/DeepRec/GE1.png)

![GE2](https://sunjc911.github.io/assets/images/DeepRec/GE2.png)

#### Node2vec——同质性和结构性的权衡

基于Deep Walk，它通过调整随机游走权重的方法使Graph Embedding的结果更倾向于体现网络的司质性 (homophily) 或结构性 (structural equivalence) 。

具体地讲，网络的“同质性”指的是距离相近节点的Embedding应尽量近似，如图 4-8所示，节点u 与其相连的节点 s1、S2、S3、S4的 Embedding 表达应该是接近的，这就是网络“同质性”的体现。

“结构性”指的是结构上相似的节点的 Embedding 应尽量近似，图 4-8 中节点 U 和节点 s6都是各自局域网络的中心节点，结构上相似，其 Embedding 的表达也应该近似，这是“结构性”的体现。

![GE3](https://sunjc911.github.io/assets/images/DeepRec/GE3.png)

![GE4](https://sunjc911.github.io/assets/images/DeepRec/GE4.png)

![GE5](https://sunjc911.github.io/assets/images/DeepRec/GE5.png)

![GE6](https://sunjc911.github.io/assets/images/DeepRec/GE6.png)

Node2vec 所体现的网络的同质性和结构性在推荐系统中可以被很直观的解释。同质性相同的物品很可能是同品类、同属性，或者经常被一同购买的商品，而结构性相同的物品则是各品类的爆款、各品类的最佳凑单商品等拥有类似趋势或者结构性属性的商品。毫无疑问，二者在推荐系统中都是非常重要的特征表达。由于 Node2vec 的这种灵活性，以及发掘不同图特征的能力，甚至可以把不同Node2vec生成的偏向“结构性”的Embedding结果和偏向“同质性”的Embedding结果共同输入后续的深度学习网络，以保留物品的不同图特征信息。

#### EGES——阿里巴巴的综合性Graph Embedding方法

在Deep Walk生成的Graph Embedding基础上引入补充信息。

为了使冷启动的商品获得合理的初始Embedding，引入补充信息side information来丰富Embedding信息的来源。

生成Graph Embedding的第一步是生成物品关系图，通过用户行为序列可以生成物品关系图，也可以利用“相同属性”“相同类别”等信息建立物品之间的边，生成基于内容的知识图谱。而基于知识图谱生成的物品向量可以被称为补充信息 Embedding向量。当然，根据补充信息类别的不同，可以有多个补充信息Embedding向量。

![GE7](https://sunjc911.github.io/assets/images/DeepRec/GE7.png)

![GE8](https://sunjc911.github.io/assets/images/DeepRec/GE8.png)

### Embedding与深度学习推荐系统的结合

作为深度学习推荐系统不可分割的一部分，Embedding技术主要应用在如下三个方向。
(1) 在深度学习网络中作为Embedding层，完成从**高维稀疏特征向量到低维稠密**特征向量的转换。
(2)作为预训练的Embedding特征向量，与其他特征向量连接后，一同输入深度学习网络进行训练。
(3) 通过计算用户和物品的Embedding相似度，Embedding可以直接作为推荐系统的召回层或者召回策略之一。

#### 深度学习网络中的Embedding层

![GE9](https://sunjc911.github.io/assets/images/DeepRec/GE9.png)

![GE10](https://sunjc911.github.io/assets/images/DeepRec/GE10.png)

#### Embedding预训练方法

为解决Embedding层训练开销大的问题。

FNN模型就是采用的预训练，利用FM模型的各特征隐向量作为初始化Embedding权重，从而加快网络收敛速度。

若想更快收敛，可以固定Embedding权重，仅更新上层网络的权重，这是更彻底的预训练方法。

再延伸一下，Embedding的本质是建立高维向量到低维向量的映射，而“映射”的方法并不局限于神经网络，可以是任何异构模型。例如，2.6节介绍的GBDT+LR组合模型，其中GBDT部分在本质上就是进行了一次Embedding操作，利用GBDT模型完成Embedding预训练，再将Embedding输入单层神经网络(即逻辑回归) 进行CTR预估

通常，Graph Embedding的训练只能独立于推荐模型进行，所以预训练受青睐。

诚然，将Embedding过程与深度神经网络的训练过程割裂会损失一定的信息，但训练过程的独立也带来了训练灵活性的提升。举例来说，物品或用户的Embedding是比较稳定的(因为用户的兴趣、物品的属性不可能在几天内发生巨大的变化)，Embedding的训练频率其实不需要很高，甚至可以降低到周的级别，但上层神经网络为了尽快抓住最新的数据整体趋势信息，往往需要高频训练甚至实时训练。使用不同的训练频率更新Embedding模型和神经网络模型，是训练开销和模型效果二者之间权衡后的最优方案。

#### Embedding作为推荐系统召回层的方法

Embedding自身表达能力的增强使得直接利用Embedding生成推荐列表成了可行的选择。因此，利用Embedding向量的相似性，将Embedding作为推荐系统召回层的方案逐渐被推广开来。其中，YouTube推荐系统召回层(如图4-14所示) 的解决方案是典型的利用Embedding进行候选物品召回的做法。

![GE11](https://sunjc911.github.io/assets/images/DeepRec/GE11.png)

![GE12](https://sunjc911.github.io/assets/images/DeepRec/GE12.png)

![GE13](https://sunjc911.github.io/assets/images/DeepRec/GE13.png)

### 局部敏感哈希——让Embedding插上翅膀的快速搜索方法

Embedding最重要的用法之一是作为推荐系统的召回层，解决相似物品的召回问题。推荐系统召回层的主要功能是快速地将待推荐物品的候选集从十万、百万量级的规模减小到几千甚至几百量级的规模，避免将全部候选物品直接输入深度学习模型造成的计算资源浪费和预测延迟问题。
Embedding技术凭借其能够综合多种信息和特征的能力，相比传统的基于规则的召回方法，更适于解决推荐系统的召回问题。在实际工程中，能否应用Embedding的关键就在于能否使用Embedding技术“快速”处理几十万甚至上百万候选集，避免增大整个推荐系统的响应延迟。

#### “快速”Embedding最近邻搜索

基于内积需要对候选集合中的所有物品进行遍历。

由于用户和物品的Embedding同处于一个向量空间内，所以召回与用户向量最相似的物品Embedding向量的过程其实是一个在向量空间内搜索最近邻的过程。如果能够找到高维空间快速搜索最近邻点的方法，那么相似Embedding的快速搜索问题就迎刃而解了。

需要建立kd树。但其结构较为复杂，且往往需要回溯保证效果。

#### 局部敏感哈希（Locality Sensitive Hashing，LSH）的基本原理

主流的快速Embedding向量最近邻搜索方法。

让相邻的点落入同一个桶，这样在最近邻搜索时，仅需要在一个桶或者相邻的几个桶内的元素中进行搜。如果每个桶的元素在一个常数附近，可以将时间复杂度降为常数级别。如何构建桶？以基于欧氏距离的最近邻搜索为例。

在欧式空间中，将高维空间的点映射到低维空间，原本相近的点在低维空间中肯定依然相近，但原本远离的点则有一定概率变成相近的点。利用低维空间可以保留高维空间相近距离关系的性质，就可以构造局部敏感哈希“桶。

![GE14](https://sunjc911.github.io/assets/images/DeepRec/GE14.png)

#### 局部敏感哈希多桶策略

采用多个哈希函数进行分桶，存在一个待解决的问题: 到底是通过“与”(And) 操作还是“或”(Or) 操作生成最终的候选集。如果通过“与”操作 (“点A和点B在哈希函数1的同一桶中”并且“点A和点B在哈希函数2的同一桶中”) 生成候选集，那么候选集中近邻点的准确率将提高，候选集的规模减小使需要遍历计算的量降低，减少了整体的计算开销，但有可能会漏掉一些近邻点(比如分桶边界附近的点) :如果通过“或”操作 (“点A和点B在哈希函数1的同一桶中”或者“点A和点B在哈希函数2的同一桶中”) 生成候选集，那么候选集中近邻点的召回率提高，但候选集的规模变大，计算开销升高。到底使用几个哈希函数，是用“与”操作还是“或”操作来生成近邻点的候选集，需要在准确率和召回率之间权衡才能得出结论。

如果使用余弦相似度作为距离标准，如何分桶？

余弦相似度衡量的是两个向量间夹角的大小，夹角小的向量即为“近邻”，因此可以使用固定间隔的超平面将向量空间分割成不同哈希桶。同样，可以通过选择不同组的超平面提高局部敏感哈希方法的准确率或召回率。当然，距离的定义方法远不止“欧氏距离”和“余弦相似度”两种，还包括“曼哈顿距离”“切比雪夫距离”“汉明距离”等，局部敏感哈希的方法也随距离定义的不同有所不同。但局部敏感哈希通过分桶方式保留部分距离信息，大规模降低近邻点候选集的本质思想是通用的。

### 总结

![GE15](https://sunjc911.github.io/assets/images/DeepRec/GE15.png)

推荐模型是驱动推荐系统达成推荐效果的引擎，也是所有推荐系统团队投入精力最多的部分。读者也一定能够在之前的学习中感受到推荐模型在学术界和业界的发展进化速度之快。我们要清楚的是，对于一个成熟的推荐系统，除了推荐模型，还要考虑召回策略、冷启动、探索与利用、模型评估、线上服务等诸多方面的问题。

## 第五章——多角度审视推荐系统

(1) 推荐系统如何选取和处理特征?
(2)推荐系统召回层的主要策略有哪些?
(3))推荐系统实时性的重要性体现在哪儿?有哪些提高实时性的方法?
(4)如何根据具体场景构建推荐模型的优化目标?
(5)如何基于用户动机改进模型结构?
(6) 推荐系统冷启动问题的解决方法有哪些?
(7) 什么是“探索与利用”问题? 有哪些主流的解决方法?

### 推荐系统的特征工程

Garbage in garbage out

机器学习模型的能力边界**在于对数据的拟合和泛化，那么数据及表达数据的特征本身就决定了机器学习模型效果的上限。**

因此，特征工程对推荐系统效果提升的作用是无法替代的。为了构建一个“好”的特征工程，需要依次解决三个问题:
(1) 构建特征工程应该遵循的基本原则是什么?
(2) 有哪些常用的特征类别?
(3) 如何在原始特征的基础上进行特征处理，生成可供推荐系统训练和推断用的特征向量?

#### 构建推荐系统特征工程的原则

特征的本质是对某个行为过程相关信息的抽象表达。

从具体行为转化为抽象特征，必然涉及信息的损失。因为原始行为需要的存储空间过大，且有冗余无用的信息影响模型泛化。

**尽可能让特征工程抽取出的一组特征能够保留推荐环境及用户行为过程中的所有有用信息，尽量摒弃冗余信息。**

如何抽取特征代表”用户点击某个电影“这一行为。

![FE](https://sunjc911.github.io/assets/images/DeepRec/FE.png)

心情无法抽取所以舍弃。

#### 推荐系统中的常用特征

1.用户行为数据

**常用且最关键**

![FE1](https://sunjc911.github.io/assets/images/DeepRec/FE1.png)

隐性反馈越发重要，因为显性反馈收集难度大且数据量小。仅用显性不足以支撑模型训练到收敛。所以**挖掘隐性反馈是目前特征挖掘的重点。**

具体用户行为特征处理上，1是将id序列转换为multi-hot向量将其作为特征向量；另一种是用预训练的Embedding，然后通过mean或者DIN的注意力机制生成历史行为Embedding，将其作为特征向量。

2.用户关系数据

物以类聚，人以群分。显性和隐性关系，或者叫强弱关系。用户与用户之间可以通过“关注”“好友关系”等连接建立“强关系”，也可以通过“互相点赞”“同处一个社区”，甚至“同看一部电影”建立“弱关系。

在推荐系统中，利用用户关系数据的方式不尽相同，可以将用户关系作为召回层的一种物品召回方式;也可以通过用户关系建立关系图，使用 Graph Embedding的方法生成用户和物品的 Embedding; 还可以直接利用关系数据，通过“好友”的特征为用户添加新的属性特征:甚至可以利用用户关系数据直接建立社会化推荐系统。

3.属性、标签类数据

![FE2](https://sunjc911.github.io/assets/images/DeepRec/FE2.png)

![FE3](https://sunjc911.github.io/assets/images/DeepRec/FE3.png)

**用户属性、物品属性、标签类数据最重要。**

4.内容类数据

内容需要通过NLP、CV等手段提取内容信息再输入推荐系统。如CV目标检测提取狗标签。

5.上下文信息

推荐行为产生的场景的信息。时间地点等。如傍晚看浪漫电影，深夜看恐怖电影。

6.统计类特征

通过统计方法计算出，如历史CVR、CTR、流行度等。连续特征归一化后即可输入。本质是粗粒度的预测指标。与预测目标有较强相关性。

7.组合类特征

通过特征组合生成的新特征，如年龄加性别组成的人口属性分段特征。

#### 常用的特征处理方法

模型输入往往是数字组成的特征向量。

1.连续性特征处理

归一化、离散化、加非线性函数等方法

![FE4](https://sunjc911.github.io/assets/images/DeepRec/FE4.png)

2.类别特征处理

one-hot和multi-hot

##### 什么是multi-hot

与多个物品的交互行为、一个东西被打上多个同类别标签等。一个用户买了10个东西，一共1000个，则10个东西打上1，其他为0。

问题：特征维度过大，过于稀疏导致欠拟合，权重参数过多导致收敛慢。所以后续用Embedding技术将其转化为稠密向量。

#### 特征工程与业务理解

从这个意义上讲，传统的人工特征组合、过滤的工作已经不存在了，取而代之的是将特征工程与模型结构统一思考、整体建模的深度学习模式。不变的是，只有深入了解业务的运行模式，了解用户在业务场景下的思考方式和行为动机，才能精确地抽取出最有价值的特征，构建成功的深度学习模型。

### 推荐系统召回层的主要策略

召回负责海量缩小到几百几千个，排序负责精准排序。前面的模型主要用于排序。

#### 召回层和排序层的功能特点

![R](https://sunjc911.github.io/assets/images/DeepRec/R.png)

**召回层**:待计算的候选集合大、速度快、模型简单、特征较少，尽量让用户感兴趣的物品在这个阶段能够被快速召回，即保证相关物品的召回率。
**排序层**:首要目标是得到精准的排序结果。需处理的物品数量少，可利用较多特征使用比较复杂的模型。

召回层如何平衡计算速度和召回率？多路召回

#### 多路召回策略

所谓“多路召回策略”，就是指采用不同的策略、特征或简单模型，分别召回一部分候选集，然后把候选集混合在一起供后续排序模型使用的策略。
可以明显地看出，“多路召回策略”是在“计算速度”和“召回率”之间进行权衡的结果其中，各简单策略保证候选集的快速召回，从不同角度设计的策略保证召回率接近理想的状态，不至于损害排序效果。

![R1](https://sunjc911.github.io/assets/images/DeepRec/R1.png)

**召回策略的选择与业务强相关。**K通过线上A/B测试确定合理的取值范围。

虽然多路召回是实用的工程方法，但从策略选择到候选集大小参数的调整**都需要人工参与**，**策略之间的信息也是割裂**的，无法综合考虑不同策略对一个物品的影响。那么，是否存在一个综合性强且计算速度也能满足需求的召回方法呢? 基于Embedding的召回方法
给出了可行的方案。

#### 基于Embedding的召回方法

深度学习得到Embedding后局部敏感哈希进行快速的Embedding最近邻计算。

多路召回中使用的信息都可以作为Embedding 的side information融进Embedding向量如EGES。相当于在利用Embedding召回的过程中，考虑到了多路召回的多种策略。

Embedding召回的另一个优势在于**评分的连续性**。多路召回中不同召回策略产生的相似度、热度等分值不具备可比性，无法据此决定每个召回策略放回候选集的大小。Embedding召回可以把Embedding间的**相似度作为唯一的判断标准**，因此可以随意限定召回的候选集大小。
生成Embedding的方法也绝不是唯一的，除了第4章介绍的Item2vec、Graph Embedding等方法，矩阵分解、因子分解机等简单模型也完全可以得出用户和物品的Embedding向量。在实际应用中可以根据效果确定最优的召回层Embedding的生成方法。

### 推荐系统的实时性

#### 为什么重要

模型更新的间隔时间越长，推荐系统的效果越差:反过来说，模型更新得越频繁，实时性越好，损失越小，效果越好。

用户角度当然希望快速刷到自己感兴趣的。只要推荐系统能感知用户反馈、实时地满足用户的期望目标，就能提高推荐的效果，这就是推荐系统“实时性”作用的直观体现。

从机器学习的角度讲，推荐系统实时性的重要之处体现在以下两个方面:
(1) 推荐系统的更新速度越快，代表用户最近习惯和爱好的特征更新越快，越能为用户进行更有时效性的推荐
(2) 推荐系统更新得越快，模型越容易发现最新流行的数据模式 (data pattern)越能让模型快速抓住最新的流行趋势。
这两方面的原因直接对应着推荐系统实时性的两大要素:一是推荐系统“特征”的实时性:二是推荐系统“模型”的实时性。

#### 推荐系统”特征“的实时性

实时收集和更新输入特征，使推荐系统总使用最新的特征进行预测和推荐。实时性差会丧失最可能增加用户粘性和留存度的时机。

![T](https://sunjc911.github.io/assets/images/DeepRec/T.png)

1.客户端实时特征

在一次session中用户点击三个物品。很显然是即时兴趣，如果及时改变推荐结果，用户体验增加。

如果采用传统的流计算平台 (图5-7中的Flink) ，甚至批处理计算平台 (图5-7中的Spark) ，则由于延迟问题，;系统可能无法在3分钟之内就把session内部的行为历史存储到特征数据库(如Redis)中，这就导致用户的推荐结果不会马上受到session内部行为的影响无法做到推荐结果的实时更新。
如果客户端能够缓存 session 内部的行为，将其作为与上下文特征同样的实时特征传给推荐服务器，那么推荐模型就能够实时地得到 session 内部的行为特征，进行实时的推荐。这就是利用客户端实时特征进行实时推荐的优势所在。

2.流计算平台的准实时特征处理

Storm、Spark、Flink进行准实时特征处理是推荐系统的标配。

所谓流计算平台，是**将日志以流的形式进行微批处理** (mini batch) 。由于每次需要等待并处理一小批日志，流计算平台**并非完全实时**的平台，但它的优势是能够进行一些简单的统计类特征的计算，比如一个物品在该时间窗口内的曝光次数，点击次数、一个用户在该时间窗口内的点击话题分布，等等。
流计算平台计算出的特征**可以立刻存入特征数据库供推荐模型使用**。虽然无法实时地根据用户行为改变用户结果，但**分钟级别的延迟**基本可以保证推荐系统能够准实时地引入用户的近期行为。

3.分布式批处理平台的全量特征处理

HDFS为主的分布式存储系统，Spark等分布式批处理计算平台，进行全量特征的计算和提取。

用途：模型训练和离线评估；特征保存入特征数据库，供之后的线上模型使用。

无法满足实施推荐，但用户下次登录时进行更准确的推荐。

#### 推荐系统”模型“的实时性

从更全局的角度考虑问题。

特征的实时性力图用更准确的特征描述用户、物品和相关场景，从而让推荐系统给出更符合当时场景的推荐结果。而模型的实时性则是希望更快地抓住全局层面的新数据模式，发现新的趋势和相关性。

以某电商网站“双11”的大量促销活动为例，特征的实时性会根据用户最近的行为更快地发现用户可能感兴趣的商品，但绝对不会发现一个刚刚流行起来的爆款商品、一个刚刚开始的促销活动，以及与该用户相似的人群最新的偏好。要发现这类全局性的数据变化，需要实时地更新推荐模型。

![T1](https://sunjc911.github.io/assets/images/DeepRec/T1.png)

1.全量更新

“全量更新”是指模型利用某时间段内的所有训练样本进行训练。全量更新是最常用的模型训练方式，但它需要等待所有训练数据都“落盘”(记录在HDFS等大数据存储系统中)才可进行，并且训练全量样本的时间往往较长，因此全量更新也是实时性最差的模型更新方式。与之相比，“增量更新”的训练方式可以有效提高训练效率。

2.增量更新

增量更新仅将新加入的样本“喂”给模型进行增量训练。从技术上讲，深度学习模型往往采用随机梯度下降(SGD) 法及其变种进行学习，模型对增量样本的学习相当于在原有样本的基础上继续输入增量样本进行梯度下降。增量更新的缺点是:增量更新的模型往往无法找到全局最优点，因此在实际的推荐系统中，经常采用增量更新与全局更新相结合的方式，在进行了几轮增量更新后，在业务量较小的时间窗口进行全局更新，纠正模型在增量更新过程中积累的误差。

3.在线学习

在线学习是进行模型实时更新的主要方法，也就是在获得一个新的样本的同时更新模型。与增量更新一样，在线学习在技术上也通过SGD的训练方式实现，但由于需要在线上环境进行模型的训练和大量模型相关参数的更新和存储，工程上的要求相对比较高。

在线学习的另一个附带问题是模型的稀疏性不强，例如，在一个输入特征向量达到几百万维的模型中，如果模型的稀疏性好，就可以在模型效果不受影响的前提下，仅让极小部分特征对应的权重非零，从而让上线的模型体积很小(因为可以摒弃所有权重为 0的特征)，这有利于加快整个模型服务的过程。但如果使用SGD的方式进行模型更新，相比batch的方式，容易产生大量小权重的特征，这就增大了模型体积，从而增大模型部署和更新的难度。为了在在线学习过程中兼顾训练效果和模型稀疏性，有大量相关的研究，最著名的包括微软的FOBOS[1]、谷歌的FTRL[2]等，
在线学习的另一个方向是将强化学习与推荐系统结合，在3.10节介绍的强化学习推荐模型 DRN 中，应用了一种竞争梯度下降算法，它通过“随机探索新的深度学习模型参数并根据实时效果反馈进行参数调整”的方法进行在线学习，这是在强化学习框架下提高模型实时性的有效尝试。

4.局部更新

提高模型实时性的另一个改进方向是进行模型的局部更新，大致的思路是降低训练效率低的部分的更新频率，提高训练效率高的部分的更新频率。这种方式的代表是Facebook的“GBDT+LR”模型。
2.6节已经介绍过“GBDT+LR”的模型结构，模型利用GBDT进行自动化的特征工程利用 LR拟合优化目标。GBDT是串行的，需要依次训练每一棵树，因此训练效率低，更新的周期长，如果每次都同时训练“GBDT+LR”整个模型，那么GBDT的低效问题将拖慢IR的更新速度。为了兼顾GBDT的特征处理能力和 LR 快速拟合优化目标的能力，Facebook采取的部署方法是每天训练一次GBDT模型，固定GBDT模型后，实时训练LR模型以快速捕捉数据整体的变化。通过模型的局部更新，做到GBDT和LR能力的权衡。
“模型局部更新”的做法较多应用在“Embedding层+神经网络”的深度学习模型中，Embedding层参数由于占据了深度学习模型参数的大部分，其训练过程会拖慢模型整体的收敛速度，因此业界往往采用 **Embedding 层单独预训练，Embedding层以上的模型部分高频更新的混合策略，这也是“模型局部更新”思想的又一次应用。**

5.客户端模型实时更新

在本节介绍“特征”实时性的部分，提到了客户端“实时特征”的方法。既然客户端是最接近用户的部分，实时性最强，那么能否在客户端就根据当前用户的行为历史更新模型呢？

客户端模型实时更新在推荐系统业界仍处于探索阶段。对于一些计算机视觉类的模型可以通过模型压缩的方式生成轻量级模型，部署于客户端，但对于推荐模型这类“重量级”的模型，往往需要依赖服务器端较强大的计算资源和丰富的特征数据进行模型服务。但客户端往往可以保存和更新模型一部分的参数和特征，比如当前用户的Embedding向量。

这里的逻辑和动机是，在深度学习推荐系统中，模型往往要接受用户Embedding和物品Embedding两个关键的特征向量。对于物品Embedding的更新，一般需要全局的数据,因此只能在服务器端进行更新;而对用户Embedding来说，则更多依赖用户自身的数据那么把用户Embedding的更新过程移植到客户端来做，能实时地把用户最近的行为数据反映到用户的Embedding中来，从而可以在客户端通过实时改变用户Embedding的方式完成推荐结果的实时更新。
这里用一个最简单的例子来说明该过程。如果用户Embedding是由用户点击过的物品Embedding进行平均得到的，那么最先得到用户最新点击物品信息的客户端，就可以根据用户点击物品的Embedding实时更新用户Embedding，并保存该Embedding。在下次推荐时将更新后的用户Embedding传给服务器，服务器端可根据最新的用户Embedding返回实
时推荐内容。

#### ”木桶理论“看待推荐系统的迭代升级

”抓住一点，重点提升“是工程师应该采取的策略。这一点是木桶理论里最短的木板。替换或者改进它。

从更高的角度看待整个推荐系统的迭代升级问题，“木桶理论”也同样适用。推荐系统的模**型**部分和工程部分总是**迭代进行、交替优化**的。当通过改进模型增加推荐效果的尝试受阻或者成本较高时，可以将优化的方向聚焦在工程部分，从而达到花较少的精力，达成更显著效果的目的。

### 如何合理设定推荐系统中的优化目标

某知名互联网人物说过:“不要用战术上的勤奋掩盖战略上的懒惰”。这句话同样适用于技术的创新和应用。如果一项技术本身是新颖的、先进的，但应用的方向与实际需求的方向有偏差，那这项技术的成果不可能是显著的。**在推荐系统中，如果你的推荐模型的优化目标是不准确的，即使模型的评估指标做得再好，也肯定与实际所希望达到的目标南辕北辙**。所以，不要犯战略性的失误、合理设定推荐系统的优化目标是每位推荐工程师在构建推荐系统之前应该着重思考的问题。
设定一个“合理”的推荐系统优化目标，首先需要确立一个“合理”的原则。对一家商业公司而言，在绝大多数情况下，推荐系统的目标都是完成某个商业目标，所以根据公司的商业目标来制定推荐系统的优化目标理应作为“合理”的战略性目标。下面通过YouTube和阿里巴巴推荐系统的例子进一步说明这一点。

#### YouTube以观看时长为优化目标的合理性

YouTube的主要商业模式是免费视频带来的广告收入，它的视频广告会阶段性地出现在视频播放之前和视频播放的过程中，因此YouTube的广告收入是与用户观看时长成正比的。为了完成公司的商业目标，YouTube推荐系统的优化目标并不是点击率、播放率等通常意义上的 CTR 预估类的优化目标，而是用户的播放时长。
不可否认的是，点击率等指标与用户播放时长有相关性，但二者之间仍存在一些“优化动机”上的差异。如果以点击率为优化目标，那么推荐系统会倾向于推荐“标题党”“预览图劲爆”的短视频，而如果以播放时长为优化目标，那么推荐系统应将视频的长短、视频的质量等特征考虑进来，此时推荐一个高质量的“电影”或“连续剧”就是更好的选择。推荐目标的差异会导致推荐系统倾向性的不同，进而影响到能否完成“增加用户播放时长”这商业目标。
在YouTube的推荐系统排序模型(如图5-9所示) 中，引入播放时长作为优化目标的方式非常巧妙。YouTube排序模型原本是把推荐问题当作分类问题对待的，即预测用户是
否点击某个视频。既然是分类问题，理论上应很难预测播放时长(预测播放时长应该是回归模型做的事情)。但 YouTube 巧妙地把播放时长转换成正样本的权重，输出层利用加权逻辑回归(Weighted Logistic) 进行训练，预测过程中利用e^{Wx+b}算式计算样本的概率 (Odds) ，这概率就是模型对播放时长的预测(这里的论证并不严谨，在8.3节中还会进一步讨论YouTube排序模型的推断过程) 。

YouTube对于播放时长的预测符合其广告赢利模式和商业利益，从中也可以看出制定个合理的优化目标对于实现推荐系统的商业目标是必要日关键的。

![T2](https://sunjc911.github.io/assets/images/DeepRec/T2.png)

相比视频类公司，对阿里巴巴等电商类公司来说，自然不存在播放时长这样的指标，那么阿里巴巴在设计其推荐系统优化目标时，考虑的关键因素有哪些呢?

#### 模型优化和应用场景的统一性

优化目标的制定还应该考虑的要素是模型优化场景和应用场景的统一性，在这一点上阿里巴巴的多目标优化模型给出了一个很好的例子。
在天猫、淘宝等电商类网站上做推荐，用户从登录到购买的过程可以抽象成两步:(1) 产品曝光，用户浏览商品详情页。
(2) 用户产生购买行为。
与YouTube等视频网站不同，对电商类网站而言，公司的商业目标是通过推荐使用户产生更多的购买行为。按照“优化目标应与公司商业目标一致”的原则，电商类推荐模型应该是一个CVR预估模型。
由于购买转化行为是在第二步产生的，因此在训练 CVR 模型时，直观的做法是采用点击数据+转化数据(图 5-10 中灰色和深灰色区域数据) 练 CVR 模型。在使用CVR模型时，因为用户登录后直接看到的并不是具体的商品详情页，而是首页或者列表页，因此CVR模型需要在产品曝光的场景(图5-10中最外层圈内的数据) 下进行预估。这就导致了训练场景与预估场景不一致的问题。模型在不同的场景下肯定会产生有偏的预估结果，进而导致应用效果的损失

![T3](https://sunjc911.github.io/assets/images/DeepRec/T3.png)

为了达到同时优化CTR和CVR模型的目的，阿里巴巴提出了多目标优化模型ESMM(Entire Space Multi-task Model) [4]。ESMM可以被当作一个同时模拟“曝光到点击”和“点击
到转化”两个阶段的模型。从模型结构(如图5-11) 上看，底层的Embedding层是CVR部分和CTR部分共享的，共享 Embedding层的目的主要是解决 CVR任务正样本稀疏的问题，利用CTR的数据生成更准确的用户和物品的特征表达。
中间层是CVR部分和CTR部分各自利用完全隔离的神经网络拟合自己的优化目标一pCVR (post-click CVR，点击后转化率)和 pCTR(post-view Click-through Rate，曝光后点击率) 。最终，将pCVR和pCTR相乘得到pCTCVR。

![T4](https://sunjc911.github.io/assets/images/DeepRec/T4.png)

ESMM同时将pCVR、PCTR和pCTCVR融合进一个统一的模型，因此模型可以一次性得出所有三个优化目标的值，在模型应用的过程中，也可以根据合适的应用场景选择与之相对应的目标进行预测。正因如此，阿里巴巴通过构建ESMM这一多目标优化模型同时解决了“训练空间和预测空间不一致”及“同时利用点击和转化数据进行全局优化”两个关键的
问题。无论是YouTube，还是阿里巴巴，虽然他们的推荐系统的模型结构截然不同，但在设计推荐系统优化目标时，他们都充分考虑了真正的商业目标和应用场景，力图在训练模型的阶段“仿真”预测阶段的场景和目标，这是读者在设计自己的推荐系统时首先要遵循的原则。

#### 优化目标是和其他团队的接口性工作

需要协调一致，才能共同完成推荐系统的商业目标。

在协调的过程中，技术团队抱怨产品团队频繁修改需求，产品团队抱怨技术团队没有充分理解他们的设计意图，二者之间往往有结构性的矛盾。如果找一个最可能的切入点，最大限度地解耦产品团队和技术团队的工作，那么最合适的点就是推荐系统优化目标的设计。
只有设定好合适的优化目标，技术团队才能够专心于模型的改进和结构的调整，避免把过于复杂晦涩的推荐系统技术细节暴露给外界。而产品团队也只有设定好合理的优化目标，才能让推荐系统服务于公司的整体商业利益和产品整体的设计目标。诚然，这个过程少不了各团队之间的矛盾、妥协与权衡，但只有在动手解决问题之前协商好优化目标，才能在今后的工作中最大限度地避免战略性的错误和推诿返工，尽可能最大化公司的商业利益和各团队的工作效率。

### 推荐系统中比模型结构更重要的是什么

#### 有解决推荐问题的”银弹“吗？

到这里也基本可以给出题目中问题的答案了--在构建推荐模型的过程中，从应用场景出发，基于用户行为和数据的特点，提出合理的改进模型的动机才是最重要的。
换句话说，推荐模型的结构不是构建一个好的推荐系统的“银弹”，**真正的“银弹”是你对用户行为和应用场景的观察，基于这些观察，改进出最能表达这些观察的模型结构。**下面用三个例子对这句话做进一步的解释。

#### Netflix对用户行为的观察

发现除了影片的排序，海报也是影响点击率的重要元素。通过A/B测试后着手对预览图生成进行优化，以提高推荐结果整体的点击率。

使用简单的线性”探索和利用“模型验证哪种组合文字图片组合才是最适合用户的个性化海报。

**从用户和场景出发解决问题。**

#### 观察用户行为，在模型中加入有价值的用户信息

缺少点击和播放样本，怎么解决数据稀疏问题？

**从用户的角度理解问题，发现有价值的信号。**

广义上讲，引入新的有价值信息相当于为推荐系统增加新的“水源”，而改进模型结构则是对已有“水源”的进一步挖掘。通常，新水源带来的收益更高，开拓难度却小于对已有水源的持续挖掘。

#### DIN模型的改进动机

出发点同样是**用户行为特点。**

天猫、淘宝作为综合性的电商网站，**只有收集与候选物品相关的用户历史行为记录才是有价值的**。基于这个出发点，引入相关物品的开关和权重结构，最终发现注意力机制恰巧是能够解释这个动机的最合适的技术结构。反过来，如果单纯从技术角度出发，为了验证注意力机制是否有效而应用注意力机制，则有“本末倒置”的嫌疑，因为这不是业界解决问题的常规思路，而是试探性的技术验证过程，这种纯“猜测”型的验证无疑会大幅增加工作量。

#### 算法工程师不能只是”炼金术士“

从用户的角度思考问题，构建模型。

### 冷启动的解决办法

具体地讲，冷启动问题根据数据匮乏情况的不同，主要分为三类:

(1) 用户冷启动，新用户注册后，没有历史行为数据时的个性化推荐。
(2) 物品冷启动，系统加入新物品后(新的影片、新的商品等) ，在该商品还没有交互记录时，如何将该物品推荐给用户。
(3) 系统冷启动，在推荐系统运行之初，缺乏所有相关历史数据时的推荐。

针对不同应用场景，解决冷启动问题需要比较专业的洞察，根据领域专家意见制定合理的冷启动策略。总体上讲，可以把主流的冷启动策略归为以下三类:
(1) 基于规则的冷启动过程。
(2) 丰富冷启动过程中可获得的用户和物品特征。
(3) 利用主动学习、迁移学习和“探索与利用”机制。

#### 基于规则的冷启动过程

在冷启动过程中，由于数据的缺乏，个性化推荐引擎无法有效工作，自然可以让系统回退到“前推荐系统”时代，采用基于规则的推荐方法。例如，在用户冷启动场景下，可以使用“热门排行榜”“最近流行趋势”“最高评分”等**榜单作为默认的推荐列表**。事实上，大多数音乐、视频等应用都是采用这类方法作为冷启动的默认规则。
更进一步，可以参考专家意见建立一些个性化物品列表，根据用户有限的信息，例如注册时填写的年龄、性别、基于 IP 推断出的地址等信息做**粗粒度的规则推荐**。例如，利用点击率等目标构建一个用户属性的决策树，在每个决策树的叶节点建立冷启动榜单，在新用户完成注册后，根据用户有限的注册信息，寻找决策树上对应的叶节点榜单，完成用户冷启动过程。
在物品冷启动场景下，可以根据一些规则找到该物品的相似物品，利用相似物品的推荐逻辑完成物品的冷启动过程。当然，寻找相似物品的过程是与业务强相关的。本节以Airbnb为例说明该过程。通过价格、房屋属性、距离进行聚类得到新商品的Embedding。

依赖领域专家对业务的洞察。

#### 丰富冷启动过程中可获得的用户和物品特征

基于规则的冷启动与模型是割裂的。

该方法在模型中加入更多用户或者物品的属性特征，而非历史数据特征。

属性特征可以用于粗粒度推荐。包括：用户注册信息，第三方DMP，物品内容特征，引导用户输入的冷启动特征。

#### 利用主动学习、迁移学习和”探索与利用“机制

1.主动学习

主动学习不仅利用已有数据进行建模，还会主动发现哪些数据是急需的，发出询问，获得反馈，加速过程。

![T5](https://sunjc911.github.io/assets/images/DeepRec/T5.png)

与强化学习一脉相承。

2.迁移学习

迁移其他领域的知识。如ESSM模型，CTR模型生成的Embedding共享给CVR模型。

3."探索与利用"机制

“探索与利用”机制是解决冷启动问题的另一个有效思路。简单地讲，探索与利用是在**“探索新数据”和“利用旧数据”之间进行平衡**，使系统既能利用旧数据进行推荐，达到推荐系统的商业目标，又能高效地探索冷启动的物品是否是“优质”物品，使冷启动物品获得曝光的倾向，快速收集冷启动数据。
这里以最经典的探索与利用方法UCB (Upper Confidence Bound，置信区间上界)[7]讲解探索与利用的原理。
(式 5-2) 是用 UCB方法计算每个物品的得分的公式。其中 x_j为观测到的第j个物品的平均回报(这里的平均回报可以是点击率、转化率、播放率等) ，n_j为目前为止向用户曝光第j个物品的次数，n 为到目前为止曝光所有物品的次数之和。

![T6](https://sunjc911.github.io/assets/images/DeepRec/T6.png)

#### ”巧妇难为无米之炊“的困境

米：数据；巧妇：算法工程师

没米搞点粗粮先。即利用粗粒度的特征、属性进行冷启动先。

边吃边买米。利用冷启动的机制解决冷启动问题，一步一步使得Embedding准确。

### 探索与利用

不仅要捞鱼塘里的老鱼，还要往里加鱼苗。

这里的“捞鱼”行为指的就是推荐系统一味使用历史数据，根据用户历史进行推荐，不注重发掘用户新的兴趣、新的优质物品。那么，“投放鱼苗”的行为自然就是推荐系统主动试探用户新的兴趣点，主动推荐新的物品，发掘有潜力的优质物品。
给用户推荐的机会是有限的，推荐用户喜欢的内容和探索用户的新兴趣这两件事都会占用宝贵的推荐机会，在推荐系统中应该如何权衡这两件事呢?这就是“探索与利用”试图解决的问题。

三大类方法：

(1) 传统的探索与利用方法: 这类方法将问题简化成多臂老虎机问题。主要的算法有e-Greedy (e贪婪)、Thompson Sampling (汤普森采样)和 UCB。该类解决方法着重解决新物品的探索和利用，方法中并不考虑用户、上下文等因素，因此是非个性化的探索与
利用方法。

(2) 个性化的探索与利用方法: 该类方法有效地结合了个性化推荐特点和探索与利用的思想，在考虑用户、上下文等因素的基础上进行探索与利用的权衡，因此被称为个性化探索与利用方法。

(3) 基于模型的探索与利用方法: 该类方法将探索与利用的思想融入推荐模型之中将深度学习模型和探索与利用的思想有效结合，是近年来的热点方向。

#### 传统的探索与利用方法

主要是解决多臂老虎机问题（Multi-Armed Bandit problem，MAB）

##### 基础知识——多臂老虎机

一个人看到一排老虎机(一种有一个摇臂的机器，投入一定金额，摇动摇臂，随机获得一定收益)，它们的外表一模一样，但每个老虎机获得回报的期望不同，刚开始这个人不知道这些老虎机获得回报的期望和概率分布，如果有N次机会，按什么顺序选择老虎机可以收益最大化呢? 这就是多臂老虎机问题(如图5-17所示)。

![T7](https://sunjc911.github.io/assets/images/DeepRec/T7.png)

###### 1.ε-Greedy算法

ε-Greedy算法的主要流程是: 选一个[0，1]的数ε，每次以ε的概率在所有老虎机中进行随机选择，以(1-ε)的概率选择截至当前平均收益最大的老虎机，在摇臂后，根据回报值对老虎机的回报期望进行更新。
这里ε的值代表对“探索”的偏好程度，每次以概率ε去“探索”，以 (1-ε) 的概率来“利用”，基于被选择的物品的回报更新该物品的回报期望。本质上讲，“探索”的过程其实是一个收集未知信息的过程，而“利用”的过程则是对已知信息的“贪心”利用过程，ε这一概率值正是“探索”和“利用”的权衡点。

ε-Greedy算法是非常简单实用的探索与利用算法，但其对探索部分和利用部分的划分还略显粗暴和生硬。例如，在进行了一段时间的探索后，再进行探索的收益已经没有之前大了，这时应该逐渐减小e的值，增加利用部分的占比:另外，对每个老虎机进行完全“随机”的探索也不是高效的探索策略，例如有的老虎机已经积累了丰富的信息，不用再进行探索来收集信息了，这时就应该让探索的机会更倾向于那不常被选择的老虎机。为了改进ε-Greedy算法的这些缺陷，启发式探索与利用算法被提出。

###### 2.汤普森采样算法

Thompson Sampling[8]是一种经典的启发式探索与利用算法。该算法假设每个老虎机能够赢钱(这里假设赢钱的数额一致)的概率是p，同时概率p的分布符合beta (win，lose)分布，每个老虎机都维护一组beta分布的参数，即win，lose。每次试验后，选中一个老虎机，摇臂后，有收益(这里假设收益是二值的，0或1) 则该老虎机的win参数增加1，否则该老虎机的lose参数增加1。
每次选择老虎机的方式是:利用每个老虎机现有的beta分布产生一个随机数b，逐一生成每个老虎机的随机数，选择随机数中最大的那个老虎机进行尝试。综上，Thompson Sampling算法流程的伪代码如代码5-2所示。

![T8](https://sunjc911.github.io/assets/images/DeepRec/T8.png)

![T9](https://sunjc911.github.io/assets/images/DeepRec/T9.png)

通过Thompson Sampling选择下一次行动时，action 3的收益期望是三者中最低的，如果按照纯“利用”的思路，是不应该选择action 3这个“老虎机”的; 但基于 action 3 的 beta 分布图形，可以很明显地看出其概率分布有一部分落在action 1和action 2概率分布右侧，而
且概率并不小 (10%~20%)。也就是说，通过Thompson Sampling选择action 3这一“老虎机”的机会并不小。这就利用了Thompson Sampling对新物品的倾向性。

###### 3.UCB算法

![T10](https://sunjc911.github.io/assets/images/DeepRec/T10.png)

对于 UCB 的一系列严格证明涉及更多的理论知识，在此不再过多扩展。只需要定性地清楚 UCB 的上界形式相当于老虎机收益期望的严格的置信区间即可。
UCB和Thompson Sampling都是工程中常用的探索与利用方法，但这类传统的探索与利用方法无法解决引入个性化特征的问题。这严重限制了探索与利用方法在个性化推荐场景下的使用，为此，个性化的探索与利用方法被提出。

#### 个性化的探索与利用方法

传统的探索与利用方法的弊端是无法引入用户的上下文和个性化信息，只能进行全局性的探索。事实上，在用户冷启动场景下，即使是已经被探索充分的商品，对于新用户仍是陌生的，用户对于这个商品的态度是未知的:另外，一个商品在不同上下文中的表现也不尽相同，比如一个商品在首页的表现和在品类页的表现很可能由于页面上下文环境的变化而截然不同。因此，在传统的探索与利用方法的基础上，引入个性化信息是非常重要的这类方法通常被称为基于上下文的多臂老虎机算法(Contextual-Bandit Algorithm)，其中最具代表性的算法是2010年由雅虎实验室提出的LiUCB算法[9]。俺不懂。

#### 基于模型的探索与利用方法

无论是传统的探索与利用方法，还是以LinUCB为代表的个性化的探索与利用方法，都存在一个显著的问题一-无法与深度学习模型进行有效的整合。例如，对LinUCB来说应用的前提就是假设推荐模型是一个线性模型，如果把预测模型改为一个深度学习模型
那么LinUCB的理论框架就不再自洽了。如果 CTR 预测模型或者推荐模型是一个深度学习模型，那么如何将探索与利用的思想与模型进行有效整合呢? 这里要再次回顾 3.10 节介绍的强化学习模型DRN。在DRN中，对于已经训练好的当前网络Q，通过对其模型参数W添加一个较小的随机扰动AW，得到新的模型参数，这里称W对应的网络为探索网络O。再通过系统的实时效果反馈决定是保留探索网络O还是沿用当前网络Q。
可以看出，DRN 对于深度学习模型的探索过程是非启发式的，但这种与模型结构无关的方法也使 DRN 中的模型探索方式适用于任何深度学习模型。它有效地把探索与利用的思想与深度学习模型结合起来，通过对模型参数随机扰动的方法探索式地优化模型。与此同时，模型参数的随机扰动也带来了推荐结果的变化和更新，自然实现了对不同内容的探索，这是“探索与利用”的思想在DRN模型中的直接体现。

#### ”探索与利用“机制在推荐系统中的应用

(1)物品冷启动。对新加入的物品或者长久没有互动信息的长尾物品来说，探索与利用算法对**新物品和长尾物品有天然的倾向性**，因此可以帮助这类物品快速收集用户反馈，快速度过冷启动期，并在较少伤害系统整体收益的前提下，快速找到有潜力的物品，丰
富优质的物品候选集。

(2) 发掘用户新兴趣。本节开头已经介绍过，如果推荐系统总是利用现有数据为用户推荐物品，相当于对用户的已发掘兴趣进行“涸泽而渔”的利用，短期内用户可能满足于当前的推荐结果，但很可能快速疲倦并离开。为了发掘用户新兴趣，推荐系统有必要进行一定程度的探索，维持用户的长期兴趣。另外，用户兴趣本身也在不断的改变和进化，需要通过探索不断抓住用户兴趣改变的趋势。

(3) 增加结果多样性。探索与利用也是增加推荐结果多样性的手段。增加结果多样性对于推荐系统的好处主要有两方面，一方面是让用户能明显感觉到结果的丰富性:另一方面是减少大量同质化内容同时出现时用户的厌倦情绪。

总的来说，探索与利用思想是所有推荐系统不可或缺的补充。相比推荐模型的优化目标--利用已有数据做到现有条件下的利益最大化，探索与利用的思想实际上是着眼于未来的，着眼于用户的长期兴趣和公司的长期利益，算法工程师不仅需要充分理解这一点，更需要制定算法目标的决策者有更深的理解，做出更有利于公司长远发展的决策。

## 第六章 深度学习推荐系统的工程实现

从工程的角度来看推荐系统，可以将其分为两大部分: 数据部分和模型部分。数据部分主要指推荐系统所需数据流的相关工程实现;模型部分指的是推荐模型的相关工程实现根据模型应用阶段的不同，可进一步分为离线训练部分和线上服务部分。根据推荐系统整体的工程架构，本章的主要内容可以分为以下三大部分:
(1) 推荐系统的数据流::主要介绍与推荐系统数据流相关的大数据平台的主要框架和实现大数据平台的主流技术

(2) 深度学习推荐模型的离线训练: 主要介绍训练深度学习推荐模型的主流平台,如 Spark MLlib、Parameter Server (参数服务器)、TensorFlow、PyTorch的主要原理。

(3) 深度学习推荐模型的上线部署:主要个绍部署深度学习推荐模型的技术途径和模型线上服务的过程。
在此工程架构基础上，介绍工程和理论之间的权衡方法，探讨推荐算法工程师如何进行取舍才能达到工程和理论之间的平衡和统一。

### 推荐系统的数据流

本节要介绍的“推荐系统的数据流”指的是训练、服务推荐模型所需数据的处理流程。自2003年谷歌陆续发表了Big Table [1]、Google File System[2]和Map Reduce [3]三大大数据领域奠基性论文以来，推荐系统也全面进入了大数据时代。动辄 TB 乃至 PB 级别的训练数据，让推荐系统的数据流必须和大数据处理与存储的基础设施紧密结合，才能完成推荐系统的高效训练和在线预估。
大数据平台的发展经历了从批处理到流计算再到全面融合进化的阶段。架构模式的不断发展带来的是数据处理实时性和灵活性的大幅提升。按照发展的先后顺序，大数据平台主要有批处理、流计算、Lambda、Kappa 4种架构模式。

#### 批处理大数据架构

在大数据平台诞生之前，传统数据库很难处理海量数据的存储和计算问题。针对这一难题，以Google GFS和Apache HDFS为代表的分布式存储系统诞生，解决了海量数据的存储问题;为了进一步解决数据的计算问题，Map Reduce 框架被提出，采用分布式数据处理再逐步Reduce的方法并行处理海量数据。“分布式存储+Map Reduce”的架构只能批量处理已经落盘的静态数据，无法在数据采集、传输等数据流动的过程中处理数据，因此被称为批处理大数据架构。
相比之前以数据库为核心的数据处理过程，批处理大数据架构用分布式文件系统和MReduce替换了原来的依托传统文件系统和数据库的数据存储和处理方法，批处理大数ap据架构示意图如图6-1所示。

![D](https://sunjc911.github.io/assets/images/DeepRec/D.png)

#### 流计算大数据架构

流计算大数据架构在数据流产生及传递的过程中流式地消费并处理数据(如图 6-2 所示)。流计算架构中“滑动窗口”的概念非常重要，在每个“窗口”内部，数据被短暂缓存并消费，在完成一个窗口的数据处理后，流计算平台滑动到下一时间窗口进行新一轮的数据处理。因此理论上，流计算平台的延迟仅与滑动窗口的大小有关。在实际应用中，滑动窗口的大小基本以分钟级别居多，这大大提升了原“批处理”架构下动辄几小时的数据延迟。

![D1](https://sunjc911.github.io/assets/images/DeepRec/D1.png)

知名开源流计算平台包括Storm、Spark Streaming、Flink等，特别是近年来崛起的Flink，它将所有数据均看作“流”，把批处理当作流计算的一种特殊情况，可以说是“原生”的流处理平台。
在流计算的过程中，流计算平台不仅可以进行单个数据流的处理，还可以对多个不同数据流进行ioin操作，并在同一个时间窗口内做整合处理。除此之外，一个流计算环节的输出还可以成为下游应用的输入，整个流计算架构是灵活可重构的。因此，流计算大数据架构的优点非常明显，就是数据处理的延迟小，数据流的灵活性非常强。这对于数据监控推荐系统特征实时更新，以及推荐模型实时训练有很大的帮助。
另外，纯流计算的大数据架构摒弃了批处理的过程，这使得平台在数据合法性检查数据回放、全量数据分析等应用场景下显得捉襟见肘:特别是在时间窗口较短的情况下.日志乱序、ioin操作造成的数据遗漏会使数据的误差累计，纯流计算的架构并不是完美的这就要求新的大数据架构能对流计算和批处理架构做一定程度的融合，取长补短。

#### Lambda架构

Lambda 架构是大数据领域内举足轻重的架构，大多数一线互联网公司的数据平台基
本都是基于Lambda架构或其后续变种架构构建的。Lambda 架构的数据通道从最开始的数据收集阶段裂变为两条分支: 实时流和离线处理。实时流部分保持了流计算架构，保障了数据的实时性，而离线处理部分则以批处理的方式为主，保障了数据的最终一致性，为系统提供了更多数据处理的选择。Lambda架构示意图如图6-3所示。
流计算部分为保障数据实时性更多是以增量计算为主，而批处理部分则对数据进行全量运算，保障其最终的一致性及最终推荐系统特征的丰富性。在将统计数据存入最终的数据库之前，Lambda 架构往往会对实时流数据和离线层数据进行合并，并会利用离线层数据对实时流数据进行校检和纠错，这是 Lambda架构的重要步骤。

![D2](https://sunjc911.github.io/assets/images/DeepRec/D2.png)

#### Kappa架构

Kappa 架构是为了解决 Lambda 架构的代码冗余问题而产生的。Kappa 架构秉持着-“Everything is streaming (一切皆是流)”的原则，在这个原则之下，无论是真正的实时流，还是离线批处理，都被以流计算的形式执行。也就是说，离线批处理仅是“流处理”的一种特殊形式。从某种意义讲，Kappa架构也可以看作流计算架构的“升级”版本。那么具体来讲，Kappa架构是如何通过同样的流计算框架实现批处理的呢?事实上“批处理”处理的也是一个时间窗口的数据，只不过与流处理相比，这个时间窗口比较大,流处理的时间窗口可能是5分钟，而批处理可能需要1天。除此之外，批处理完全可以共享流处理的计算逻辑。
由于批处理的时间窗口过长，不可能在在线环境下通过流处理的方式实现，那么问题的关键就在于如何在离线环境下利用同样的流处理框架进行数据批处理。
为了解决这个问题，需要在原有流处理的框架上加上两个新的通路“原始数据存储”和“数据重播”。“原始数据存储”将未经流处理的数据或者日志原封不动地保存到分布式文件系统中，“数据重播”将这些原始数据按时间顺序进行重播，并用同样的流处理框架进行处理，从而完成离线状态下的数据批处理。这就是Kappa架构的主要思路(如图6-4所示)。

![D3](https://sunjc911.github.io/assets/images/DeepRec/D3.png)

#### 大数据平台与推荐系统的整合

大数据平台与推荐系统的关系是非常紧密的，5.3节曾详细介绍了推荐系统实时性的重要性，无论是推荐系统特征的实时性还是模型训练的实时性都依赖于大数据平台对数据的处理速度。具体来讲，大数据平台与推荐系统的整合主要体现在两个方面:
(1) 训练数据的处理。
(2) 特征的预计算
如图6-5所示，无论采用哪种大数据架构，大数据平台在推荐系统中的主要任务都是对特征和训练样本的处理。根据业务场景的不同，完成特征处理之后，样本和特征数据最终流向两个方向;
(1) 以HDFS为代表的离线海量数据存储平台，主要负责存储离线训练用的训练样
本。
征。
(2) 以Redis为代表的在线实时特征数据库，主要负责为模型的在线服务提供实时特

![D4](https://sunjc911.github.io/assets/images/DeepRec/D4.png)

大数据架构的选择与推荐模型的训练方式是密切相关的。如果推荐模型希望进行准实时甚至实时的训练更新，那么对大数据平台数据处理能力的要求会非常高。利用流计算平台实时地对数据进行特征工程的计算，不同数据流的 ioin操作是必须要进行的，甚至可以将模型的更新过程整合进流计算平台之中。
加入了机器学习层的架构也被称为新一代的 Unified 大数据架构，其在Lambda 或 Kappa 架构上的流处理层新增了机器学习层，将机器学习和数据处理融为一体，被看作推荐系统和大数据平台的深度整合。
总而言之，互联网海量数据场景下的推荐系统与大数据平台的关系是密不可分的。业界所有前沿的推荐系统只有与大数据平台进行深度整合，才能完成推荐系统的训练、更新在线服务的全部过程。

### 推荐模型离线训练之Spark MLib

##### Spark的分布式计算原理

Spark 是一个**分布式计算平台。所谓分布式，指的是计算节点之间不共享内存，需要通过网络通信的方式交换数据**。要强调的是，Spark 最典型的应用方式是建立在大量廉价计算节点上的，这些节点可以是廉价主机，也可以是虚拟的Docker Container (Docker容器):但这种方式区别于CPU+GPU的架构，以及共享内存多处理器的高性能服务器架构
搞清楚这一点，对于理解后续的Spark的计算原理是重要的。从图6-6的Spark架构图中可以看出，Spark程序由Cluster Manager (集群管理节点)进行调度组织，由Worker Node (工作节点) 进行具体的计算任务执行，最终将结果返回Drive Program (驱动程序)。在物理的Worker Node上，数据还可能分为不同的Partition (数据分片)，可以说**partition是Spark的基础处理单元**。

![D5](https://sunjc911.github.io/assets/images/DeepRec/D5.png)

在执行具体的程序时，Spark 会将程序拆解成一个任务 DAG (Directed Acyclic Graph有向无环图)，再根据DAG决定程序各步骤执行的方法。图6-7所示为某示例程序的 DAG图，该程序分别从 textFile 和 HadoopFile 读取文件，经过一系列操作后进行join，最终得到处理结果。
在 Spark 平台上并行处理图 6-7 所示的 DAG 时，最关键的过程是找到哪些是可以并行处理的部分，哪些是必须shuffle (混洗) 和reduce的部分。

![D6](https://sunjc911.github.io/assets/images/DeepRec/D6.png)

这里的 shuffle 指的是所有 Partition 的数据必须进行洗牌后才能得到下一步的数据,最典型的操作就是groupByKey操作和join操作。以ioin操作为例，必须对 textFile 数据和 hadoopFile 数据做全量的匹配才能得到 ioin 操作后的dataframe (Spark保存数据的结构)而groupByKey操作需要对数据中所有相同的key进行合并，也需要全局的shuffle才能完成
与之相比，map、filter等操作仅需逐条地进行数据处理和转换，不需要进行数据间的操作，因此各Partition之间可以并行处理。
除此之外，在得到最终的计算结果之前，程序需要进行 reduce 操作，从各Partition上汇总统计结果。随着Partition的数量逐渐减小，reduce操作的并行程度逐渐降低，直到将最终的计算结果汇总到master节点(主节点) 上。
可以说，shuffle 和 reduce 操作的发生决定了纯并行处理阶段的边界。如图 6-8所示Spark的DAG被分割成了**不同的并行处理阶段 (stage)**

![D7](https://sunjc911.github.io/assets/images/DeepRec/D7.png)

需要强调的是，shuffle操作需要在不同计算节点之间进行数据交换，非常消耗计算、通信及存储资源，因此shuffle操作是spark程序应该尽量避免的。一句话总结Spark的计算过程: **Stage内部数据高效并行计算，Stage边界处进行消耗资源的shuffle操作或者最终的reduce操作。**

##### Spark MLlib的模型并行训练原理

将重点放在梯度下降类方法的实现上，因为梯度下降的并行程度决定了以逻辑回归为基础，MLP为代表的深度学习模型的训练速度。

经过精简的代码非常简单，Spark的mini batch过程只做了三件事:

(1) 把当前的模型参数广播到各个数据Partition (可当作虚拟的计算节点)。

(2)各计算节点进行数据抽样得到mini batch的数据，分别计算梯度，再通过treeAggregate操作汇总梯度，得到最终梯度gradientSum。

(3)利用gradientSum更新模型权重。

这样一来，每次迭代的Stage和Stage的边界就非常清楚了，Stage内部的并行部分是各节点分别采样并计算梯度的过程，Stage 的边界是汇总加和各节点梯度的过程。这里再强调一下汇总梯度的操作treeAggregate，该操作是进行类似树结构的逐层汇总，整个过程是一个 reduce 过程，并不句含 shuffle 操作，再加上采用分层的树形操作，每层内部的树节
点操作并行执行，因此整个过程非常高效。在迭代次数达到上限或者模型已经充分收敛后，模型停止训练。这就是Spark MLlib进行mini batch梯度下降的全过程，也是Spark MLlib实现分布式机器学习的最典型代表。总结来说，Spark MLlib 的并行训练过程其实是“数据并行”的过程，并不涉及过于复杂的梯度更新策略，也没有通过“参数并行”的方式实现并行训练。这样的方式简单、直观易于实现，但也存在一些局限性。

##### Spark Mlib并行训练的局限性

全局广播，在每轮迭代前广播全部参数，非常消耗带宽资源。

阻断式梯度下降的方式，每轮梯度下降由最慢的节点决定。

不支持复杂深度学习网络结构和大量可调超参。只支持MLP训练。

### 推荐模型离线训练之Parameter Server

#### Parameter Server 的分布式训练原理

![D8](https://sunjc911.github.io/assets/images/DeepRec/D8.png)

server节点的主要功能是保存模型参数、接受worker节点计算出的局部梯度、汇总计算全局梯度，并更新模型参数。
worker节点的主要功能是保存部分训练数据，从server节点拉取最新的模型参数，根据训练数据计算局部梯度，上传给server节点。

![D9](https://sunjc911.github.io/assets/images/DeepRec/D9.png)

可以看到，Parameter Server分为两大部分: 服务器节点组 (server group) 和多个工作节点组 (worker group) 。资源管理中心 (resource manager) 负责总体的资源分配调度服务器节点组内部包含多个服务器节点(server node) ，每个服务器节点负责维护一部分参数，服务器管理中心 (server manager) 负责维护和分配server资源。每个工作节点组对应一个 Application (即一个模型训练任务) ，工作节点组之间，以及工作节点组内部的任务节点之间并不通信，任务节点只与server通信。

![D10](https://sunjc911.github.io/assets/images/DeepRec/D10.png)

Parameter Server的并行梯度下降流程中最关键的两个操作是push和pull。

push 操作: worker 节点利用本节点上的训练数据，计算好局部梯度，上传给server
节点。

pull操作:为了进行下一轮的梯度计算，worker节点从server节点拉取最新的模型参数到本地。

在图6-11的基础上，概括整个Parameter Server的分布式训练流程如下:
(1) 每个worker载入一部分训练数据。
(2) worker节点从server节点拉取 (pull) 最新的相关模型参数
(3) worker节点利用本节点数据计算梯度。
(4) worker节点将梯度推送到server节点。
(5) server节点汇总梯度更新模型。
(6) 跳转到第2步，直到迭代次数达到上限或模型收敛

#### 一致性和并行效率间的取舍

Spark的阻断式梯度下降导致并行效率低，但是一致性高。

Parameter Server用“异步非阻断式”的梯度下降替代原来的“同步阻断式”方法。图6-11所示为一个 worker节点多次迭代计算梯度的过程。可以看到节点在做第 11次选代(iter 11) 计算时，第 10次选代后的 push&pull过程并没有结束，也就是说，最新的模型权重参数还没有被拉取到本地，该节点仍在使用iter 10的权重参数计算iter 11的梯度。这就是所谓的异步非阻断式梯度下降法，其他节点计算梯度的进度不会影响本节点的梯度计算。所有节点始终都在并行工作，不会被其他节点阻断。

当然，任何技术方案都有“取”也有“舍”，异步梯度更新的方式虽然大幅加快了训练速度，但带来的是模型一致性的损失。也就是说，并行训练的结果与原来的单点串行训练的结果是不一致的，这样的不一致会对模型收敛的速度造成一定影响。所以最终选取同步更新还是异步更新取决于不同模型对一致性的敏感程度。这类似于一个模型超参数选取的问题，需要针对具体问题进行具体的验证。
除此之外，在同步和异步之间，还可以通过设置“最大延迟”等参数限制异步计算的程度。例如，可以限定在三轮迭代之内，模型参数必须更新一次。如果某 worker 节点计算了三轮梯度，还未完成一次从 server 节点拉取最新模型参数的过程，那么该 worker 节点就必须停下等待 pull 操作的完成。这是同步和异步之间的折中方法。
本节介绍了并行梯度下降方法中“同步”更新和“异步”更新之间的区别。在效果上，读者肯定关心下面两个指标:

(1)“异步”更新到底能够节省多少阻断时间 (waiting time)

(2)“异步”更新会降低梯度更新的一致性，这是否会让模型的收敛时间变长。

针对上面两点疑问，Parameter Server论文的原文中提供了异步和同步更新的效率对比(基于Sparse logistic regression (稀疏逻辑回归) 模型训练) ，PS的计算时间占比远高于同步更新策略，计算效率明显提高。收敛速度也块，说明不一致性问题的影响没有想象中那么大。

#### 多server节点的协同和效率问题

Spark MLlib广播受到带宽影响。PS如何解决单点master效率低下的问题？

Parameter Server采用了服务器节点组内多server的架构，每个 server 主要负责部分模型参数。模型参数使用 key-value 的形式，因此每个server负责一个参数键范围(ke
y range) 内的参数更新就可以了。那么另一个问题来了，每个server是如何决定自己负责哪部分参数范围呢? 如果有新的server节点加入，那么如何在保证已有参数范围不发生大的变化的情况下加入新的节点呢?这两个问题的答案涉及一致性哈希 consistent hashing) 的原理。Parameter Server节点组成的一致性哈希环如图6-14所示。

![D11](https://sunjc911.github.io/assets/images/DeepRec/D11.png)

(1) 将模型参数的key映射到一个环形的哈希空间，比如有一个哈希函数可以将任意key映射到 0~(232) -1的哈希空间内，只要让(232) -1这个桶的下一个桶是0这个桶,这个空间就变成了一个环形哈希空间。

(2) 根据 server 节点的数量 n，将环形哈希空间等分成 nm 个范围，让每个server间隔地分配m个哈希范围。这样做的目的是保证一定的负载均衡性，避免哈希值过于集中带来的server负载不均。

(3) 在新加入一个server节点时，让新加入的server节点找到哈希环上的插入点，让新的server负责插入点到下一个插入点之间的哈希范围，这样做相当于把原来的某段哈希范围分成两份，新的节点负责后半段，原来的节点负责前半段。这样不会影响其他哈希范
围的哈希分配，自然不存在大量的重哈希带来的数据大混洗的问题。

(4) 删除一个server节点时，移除该节点相关的插入点，让临近节点负责该节点的哈希范围。

在 Parameter Server的服务器节点组中应用一致性哈希原理，可以非常有效地降低原来单 master 节点带来的瓶颈问题。在应用一致性哈希原理后，当某worker 节点希望拉取新的模型参数时，该节点将发送不同的“范围拉取请求”(range pull) 到不同的server节点之后各server节点可以并行地发送自己负责的权重参数到该worker节点。

此外，由于在处理梯度的过程中server节点之间也可以高效协同，某worker节点在计算好自己的梯度后，只需要利用范围推送 (range push) 操作把梯度发送给一部分相关的server节点。当然，这一过程也与模型结构相关，需要跟模型本身的实现结合。总的来说，Parameter Server基于一致性哈希提供了参数范围拉取和参数范围推送的能力，让模型并行训练的实现更加灵活。

#### Parameter Server技术要点总结

Parameter Server实现分布式机器学习模型训练的要点如下：

1用异步非阻断式的分布式梯度下降策略替代同步阻断式的梯度下降策略。

2实现多server节点的架构，避免单master节点带来的带宽瓶颈和内存瓶颈。

3使用一致性哈希、参数范围拉取、参数范围推送等工程手段实现信息的最小传递避免广播操作带来的全局性网络阻塞和带宽浪费。

Parameter Server仅仅是一个管理并行训练梯度的权重平台，并不涉及具体的模型实现因此Parameter Server往往作为MXNet、TensorFlow的一个组件，要想具体实现一个机器学习模型，还需要依赖通用的、综合性的机器学习平台。6.4节将介绍以TensorFlow为代表的机器学习平台的工作原理

### 推荐模型离线训练之TensorFlow

#### 基本原理

根据深度学习模型架构构建一个有向图，让数据以张量的形式在其中流动起来。

张量(tensor) 其实是矩阵的高维扩展，矩阵可以看作张量在二维空间上的特例。

![TF](https://sunjc911.github.io/assets/images/DeepRec/TF.png)

#### TF基于任务关系图的并行训练过程

构建了由各“操作”构成的任务关系图，TensorFlow就可以基于任务关系图进行灵活的任务调度，以最大限度地利用多 GPU 或者分布式计算节点的并行计算资源。利用任务关系图进行调度的总原则是，**存在依赖关系的任务节点或者子图(subgraph) 之间需要串行执行，不存在依赖关系的任务节点或者子图之间可以并行执行**。

![TF1](https://sunjc911.github.io/assets/images/DeepRec/TF1.png)

![TF2](https://sunjc911.github.io/assets/images/DeepRec/TF2.png)

#### 单机训练与分布式训练模式

对单机训练来说，虽然执行过程中也包括 CPU、GPU 的并行计算过程，但总体上处于共享内存的环境，不用过多考虑通信问题:而多机分布式训练指的是多台不共享内存的独立计算节点组成的集群环境下的训练方法。计算节点间需要依靠网络通信。

![TF3](https://sunjc911.github.io/assets/images/DeepRec/TF3.png)

#### TF技术总结

本节从训练原理的角度讲解了以 TensorFlow 为代表的深度学习平台的运行过程。希望读者能够掌握 TensorFlow 的基本运行模式和任务拆解过程，以及并行化训练的原理,其技术要点如下:
(1) TensorFlow 直译为“张量流动”，主要原理是将模型训练过程转换成任务关系图让数据以张量的形式在任务关系图中流动，完成整个训练。
(2) TensorFlow基于任务关系图进行任务调度和并行计算。
(3)对于分布式 TensorFlow 来说，其并行训练分为两层，一层是基于Parameter Server 架构的数据并行训练过程;另一层是每个 worker 节点内部，CPU+GPU任务级别的并行计算过程。

### 深度学习推荐模型的上线部署

如何将离线训练好的模型部署在线上的生产环境，进行线上实时推断，一直是业界的一个难点。

#### 预存推荐结果或Embedding结果

离线训练后结果存入Redis等线上数据库，线上直接取出。

优点：(1) 无须实现模型线上推断的过程，线下训练平台与线上服务平台**完全解耦**，可以灵活地选择任意离线机器学习工具进行模型训练。

(2) 线上服务过程没有复杂计算，推荐系统的**线上延迟极低**。

该方法的缺点如下。

(1) 由于需要存储用户x物品x应用场景的组合推荐结果，在用户数量、物品数量等规模过大后，容易发生**组合爆炸**的情况，线上数据库根本无力支撑如此大规模结果的存储

（2）**无法引入线上场景类特征**，推荐系统的灵活性和效果受限

这是种“以存代算”的方式。

而存Embedding大大减少存储量，线上只需内积或者余弦相似度得到推荐结果。但同样无法引入线上场景特征，且无法进行复杂模型结构的线上推荐，表达能力受限。因此对于复杂模型，从实时线上推断的角度入手。

#### 自研模型线上服务平台

通用平台代码冗余，难以修改和定制。自研灵活。或者是需求特殊，大部分通用框架无法支持。

#### 预训练Embedding+轻量级线上模型

业界的很多公司采用了“复杂网络离线训练、生成Embedding存入内存数据库、线上实现逻辑回归或浅层神经网络等轻量级模型拟合优化目标”的上线方式。4.3节曾介绍过的“双塔”模型是非常典型的例子(如图4-5所示)
**双塔模型**分别用复杂网络对“用户特征”和“物品特征”进行了Embedding化，在最后的交叉层之前，用户特征和物品特征之间没有任何交互，这就形成了两个独立的“塔”，因此称为双塔模型。
在完成双塔模型的训练后，可以把最终的用户Embedding和物品Embedding存入内存数据库。而在进行线上推断时，也不用复现复杂网络，只需要实现最后输出层的逻辑即可。这里的输出层大部分情况下就是逻辑回归或 softmax，也可以使用复杂一点的浅层神经网络。但无论选择哪种神经网络，线上实现的难度并不大。在从内存数据库中取出用户Embedding和物品Embedding之后，通过输出层的线上计算即可得到最终的预估结果。在这样的架构下，还可以在输出层之前把用户Embedding和物品Embedding，以及一些场景特征连接起来，使模型能够引入线上场景特征，丰富模型的特征来源。在Graph Embedding技术已经非常强大的今天，Embedding离线训练的方法已经可以融入大量用户和物品信息，输出层并不用设计得过于复杂，因此采用Embedding 预训练+轻量级线上模型的方法进行模型服务，不失为一种灵活简单且不过多影响模型效果的方法。

#### 利用PMML转换并部署模型

Embedding+轻量级模型的方法是实用且高效的，但无论如何还是割裂了模型。无法实现End2End训练+End2End部署这种最完美的方式。有没有在离线训练完模型之后，直接部署模型的方式呢?本节介绍一种脱离平台的通用的模型部署方式-PMML。
PMML的全称是“**预测模型标记语言**”(Predictive Model Markup Language，PMML是一种通用的以XML的形式表示不同模型结构参数的标记语言。在模型上线的过程中PMML经常作为中间媒介连接离线训练平台和线上预测平台。

![PMML](https://sunjc911.github.io/assets/images/DeepRec/PMML.png)

#### TF Serving

是TF推出的原生模型服务器。利用TF自带的模型序列化函数可将训练好的模型参数和结构保存到某文件路径。

#### 灵活选择模型服务方法

因此，作为一名算法工程师，除了应对主流的模型服务方式有所了解，还应对公司客观的工程环境进行综合权衡，给出最适合的解决方案。

### 工程与理论之间的权衡

#### 工程师职责的本质

应具备工程思维而不是学术思维，以技术落地为首要目标。

**在现有实际条件的制约下，以工程完成和技术落地为目标，寻找并实现最优的解决方案。**

#### Redis容量和模型上线方式之间的权衡

为保证模型参数和线上特征的实时性，采用内从数据库，Redis首当其冲，但要占用大量内存资源。

在此制约因素下，工程师需要从两方面考虑问题。

(1) 模型的**参数规模要尽量小**，特别是对深度学习推荐系统而言，模型的参数量极较传统模型有了几个量级的提升，更应该着重考虑模型的参数规模。
(2) 线上预估所需的**特征数量**不能无限制地增加，要根据重要性做一定程度的**取舍**。
在这样的制约因素下上线推荐系统，必然需要舍弃一些次要的要素，关注主要矛盾,名成熟的工程师的思路应该是这样的:

(1) 对于千万甚至更高量级的特征维度，理论上参数的数量级也在千万量级，线上服务是很难支持这种级别的数据量的，这就要求工程上**关注模型的稀疏性，关注主要特征舍弃大量次要特征，舍弃一定的模型预测准确度，提升线上预估的速度，减小工程资源消耗**。
(2) 增强模型的稀疏性的关键技术点有哪些? 加入**L1正则化项**，采用**FTRL等稀疏性强的训练方法**。
(3)实现目标的技术途径有多种，在无法确定哪种技术效果更佳的情况下，**实现所有备选方案，通过离线和在线的指标进行比较观察**。
(4) **根据数据确定**最终的技术途径，完善工程实现。

以上是正对模型侧的瘦身方法。、

针对特征首先PCA。针对不好取舍的进行离线评估和线上AB。

#### 研发周期限制和技术选型的权衡

在实际的工程环境中，研发周期的制约同样是不可忽视的因素。这就涉及工程师对项目整体的把控能力和对研发周期的预估能力。在产品迭代日益迅速的互联网领域，没人愿
意成为拖累其他团队的最慢一环。笔者曾经经历过多次产品和技术平台的大规模升级。在技术平台升级的过程中，要充分权衡产品新需求和技术平台整体升级的进度。例如，公司希望把机器学习平台从Spark整体迁移到TensorFlow，这是顺应深度学习浪潮的技术决策，但由于Spark平台自身的特性，编程语言、模型训练方式和TensorFlow有较大差别，整个迁移必然要经历一个较长的研发周期。在迁移的过程中，如果有新的产品需求，就需要工程师做出权衡，在进行技术升级的过程中兼顾日常的开发进度。
这里可能的技术途径有两个:
(1) 集中团队的力量完成Spark到TensorFlow的迁移，在新平台上进行新模型和新功能的研发。
(2)团队一部分成员利用成熟稳定的 Spark 平台快速满足产品需求，为TensorFlow的迁移、调试、试运行留足充分的时间。与此同时，另一部分成员则全力完成TensorFlow的相关工作，力保在大规模迁移之前新平台的成熟度。
单纯从技术角度考虑，既然已经决定升级到 TensorFlow 平台，理论上没必要再花时间利用Spark平台研发新模型。这里需要搞清楚的问题有两个。
(1) 再成熟的平台也需要整个团队磨合调试较长时间，绝不可能刚迁移至TensorFlow就让它支持重要的业务逻辑。
(2) 技术平台的升级换代应作为技术团队的内部项目，最好对其他团队透明，不应成为减缓对业务支持的直接理由。
因此，从工程进度和风险角度考虑，第2个技术途径应成为更符合工程实际和公司实际的选择。

#### 硬件平台环境和模型结构间的平衡

这里的“优化”实际上包括两个方面:

一方面是**程序本身的优化**。笔者在带实习生时，经常遇到一些实习生抱怨Spark跑得太慢，究其原因，是因为他们对Spark的shuffle机制**没有深入了解**，写的程序包含大量触发 shuffle 的操作，容易导致大量的数据倾斜问题。这样的问题本身并不涉及技术上的“权衡”，而是应该夯实自己的技术功底，尽量通过技术上的“优化”提升模型的训练效率和实时性。

另一方面的优化就需要一些**技术上的取舍**了。能否通过优化或者简化模型的结构大幅提升模型训练的速度，降低模型训练的消耗，提升推荐模型的实时性呢?典型的案例在53节中已经提到。在深度学习模型中，模型的整体训练收敛速度和模型的参数数量有很强的相关性，而模型的参数数量中输入层到Embedding层的数量占绝大部分。因此，为了大幅加快模型的训练速度，可以将Embedding部分单独抽取出来做预训练，这样可以做到上层模型的快速收敛。当然，这样的做法舍弃了End2End训练的一致性，但在硬件条件制约的情况下，增强模型实时性的收益可能远大于End2End训练带来的模型一致性收益。

其他类似的例子还包括简化模型结构的问题。如果通过增加模型复杂性(例如增加神经网络层级，增加每层神经元的数量) 带来的收益已经趋于平缓，就没有必要浪费过多硬件资源做微乎其微的效果提升，而是应该把优化方向转换到提升系统实时性，挖掘其他有效信息，为模型引入更有效的网络结构等方面。

#### 处理好局部与整体的关系

## 第七章 推荐系统的评估

推荐系统评估相关的知识比重在整个推荐系统的知识框架中并不大，但其重要性却应摆在与推荐系统构建同样重要的位置，它的重要性主要有以下3点:
(1) 推荐系统评估所采用的指标直接决定了推荐系统的优化方向是否客观合理。
(2)推荐系统评估是机器学习团队与其他团队沟通合作的接口性工作。

(3) 推荐系统评估指标的选取直接决定了推荐系统是否符合公司的商业目标和发展
愿景。

以上3点都是方向性问题，是决定一个推荐系统是否成功的关键。本章聚焦推荐系统的评估问题，从离线评估到线上测试，从多个层级探讨推荐系统评估的方法和指标，具体包括下面内容:
(1) 离线评估的方法和指标
(2) 离线仿真评估方法Replay (重播评估法)
(3) 线上A/B测试方法和线上评估指标。

(4) 快速线上评估测试方法-Interleaving(间隔插值测试法)

上述几种评估方法并不是独立的，本章的最后将探讨如何将不同层级的评估方法结合形成科学且高效的多层推荐系统评估体系。

### 离线评估方法与基本评价指标

在推荐系统的评估过程中，离线评估往往被当作最常用也是最基本的评估方法。顾名思义，离线评估是指在将模型部署于线上环境之前，在离线环境中进行的评估。由于不用部署到生产环境，离线评估没有线上部署的工程风险，也**无须浪费宝贵的线上流量资源**，而且具有**测试时间短**、同时进行多组并行测试、能够**利用丰富的线下计算资源**等诸多优点
因此，在模型上线之前，进行大量的离线评估是验证模型效果最高效的手段。为充分掌握离线评估的技术要点，需要掌握两方面的知识:一是离线评估的方法有哪些;二是离线评估的指标有哪些。

#### 离线评估的主要方法

划分训练集测试集。根据划分方法不同，离线评估可分为三种。

##### 1.Holdout检验

Holdout 检验是基础的离线评估方法，它将原始的样本集合随机划分为训练集和验证集两部分。举例来说，对于一个推荐模型，可以把样本按照 70%-30%的比例随机分成两部分，70%的样本用于模型的训练;30%的样本用于模型的评估。
Holdout 检验的缺点很明显，即**在验证集上计算出来的评估指标与训练集和验证集的划分有直接关系，如果仅进行少量Holdout检验，则得到的结论存在较大的随机性**。为了消除这种随机性，“交叉检验”的思想被提出。

##### 2.交叉检验

k-fold交叉验证:先将全部样本划分成 **k个大小相等的样本子集**;**依次遍历这k个子集每次都把当前子集作为验证集，其余所有子集作为训练集，进行模型的训练和评估;最后将所有k次的评估指标的平均值作为最终的评估指标。**在实际实验中，k经常取10。留一验证:每次留下1个样本作为验证集，其余所有样本作为测试集。样本总数为n依次遍历所有n个样本，进行n次验证，再将评估指标求平均得到最终指标。在样本总数较多的情况下，留一验证法的时间开销极大。事实上，留一验证是留p验证的特例。留p验证是指每次留下p个样本作为验证集，而从n个元素中选择 p 个元素有C^p_n种可能，因此它的时间开销远远高于留一验证，故很少在实际工程中应用。

##### 3.自助法

上两种都是基于训练集和测试集。当样本规模小。适用自助法。

基于自助采样法的检验方法：对于总数为n的样本集合，进行n次有放回的随机抽样，得到大小为n的训练集。将没有被抽出的样本作为验证集进行模型验证。

#### 离线评估的指标

##### 1.准确率（Accuracy）

分类准确率（Accuracy）指分类正确的样本占总样本个数的比例。

![ACC](https://sunjc911.github.io/assets/images/DeepRec/ACC.png)

具有较强可解释性且直观，但缺陷：当不同类别的样本比例非常不均衡时，占比较大的类别往往成为影响准确率的最主要原因。例如，如果负样本占99%，那么分类器把所有样本都预测为负样本也可以获得99%的准确率。
如果将推荐问题看作一个点击率预估式的分类问题，那么在选定一个闽值划分正负样本的前提下，可以用准确率评估推荐模型。而在实际的推荐场景中，更多是利用推荐模型得到一个推荐序列，因此更多是使用精确率和召回率这一对指标来衡量一个推荐序列的好坏。

##### 2.精确率Precision与召回率Recall

精确率(Precision) 是分类正确的正样本个数占分类器判定为正样本的样本个数的比例，召回率(Recall) 是分类正确的正样本个数占真正的正样本个数的比例。

在排序模型中，通常没有一个确定的闯值把预测结果直接判定为正样本或负样本，而是采用Top N排序结果的精确率 (Precision@N) 和回率(Recall@N) 来衡量排序模型的性能，即认为模型排序的To p N的结果就是模型判定的正样本，然后计算Precision@N和Recall@N。
精确率和召回率是**矛盾统一**的两个指标:为了提高精确率，分类器需要尽量在“更有把握时”才把样本预测为正样本，但往往会因过于保守而漏掉很多“没有把握”的正样本，导致召回率降低。
为了综合地反映Precision和Recall的结果，可以使用F1-score，F1-score是精确率和召回率的调和平均值，其定义如下:

![F1](https://sunjc911.github.io/assets/images/DeepRec/F1.png)

##### 3.均方根误差（RMSE）

衡量回归模型的好和坏。使用点击率预估模型构建推荐系统时，预测的其实是样本为正样本的概率，那么就可以用RMSE评估

![RMSE](https://sunjc911.github.io/assets/images/DeepRec/RMSE.png)

yi是滴i个样本的真实值，yi帽是预测值，n为样本个数。

一般情况下，RMSE能够很好地反映**回归模型预测值与真实值的偏离程度，但受到极端噪声的影响。**但在实际应用时，如果存在个别偏离程度非常大的离群点，那么即使离群点数量非常少，也会让RMSE指标变得很差。为解决这个问题，可以使用**鲁棒性更强的平均绝对百分比误差**(Mean Absolute Percent Error，MAPE) 进行类似的评估，MAPE的定义如下:

![MAPE](https://sunjc911.github.io/assets/images/DeepRec/MAPE.png)

把每个点的误差归一化，降低离群点的影响。

##### 4.对数损失函数

LogLoss为尝使用的指数，在一个二分类问题中，LogLoss的定义

![LogLoss](https://sunjc911.github.io/assets/images/DeepRec/LogLoss.png)

细心的读者会发现，LogLoss就是逻辑回归的损失函数，而大量深度学习模型的输出层正是逻辑回归或 softmax，因此采用 LogLoss 作为评估指标能够非常直观地反映模型损失函数的变化。如果仅站在模型的角度来说，LogLoss是非常适于观察模型收敛情况的评估指标。

### 直接评估推荐序列的离线指标

7.1 节介绍了推荐系统主要的离线评测方法和常用的评估指标，但无论是准确率、RMSE、还是 LogLoss，都更多地将推荐模型视作类似于点击率预估的预测模型，而不是一个排序模型。这其实是有弊端的，因为预测模型的要求是预测的概率应具有物理意义，也就是说，预测出的点击率应该接近经验点击率。而事实上，推荐系统的最终结果是一个排序列表，以矩阵分解方法为例，其获得的用户和物品的相似度仅是排序的一个依据，并不具有类似点击率这样的物理意义。因此，使用直接评估推荐序列的指标来评估推荐模型，就成了更加合适的评估方法。本节将依次介绍直接评估推荐序列的离线指标--P-R曲线、ROC曲线和平均精度均值。

#### P-R曲线

7.1节中介绍了评估排序序列的两个重要指标Precision@N和Recall@N。为了综合评价一个排序模型的好坏，不仅要看模型在不同Top N下的Precision@N和Recall@N，而且最好能够绘制出模型的Precision-Recall曲线(精确率-召回率曲线，简称P-R曲线)。本节简
单介绍P-R曲线的绘制方法。
P-R 曲线的**横轴是召回率，纵轴是精确率**。对于一个排序模型来说，其 P-R曲线上的一个点代表“**在某一闽值下，模型将大于该闯值的结果判定为正样本，将小于该阙值的结果判定为负样本时，排序结果对应的召回率和精确率**”。
整条P-R曲线是通过**从高到低移动正样本闯值生成**的。如图7-1所示，其中实线代表模型 A的 P-R曲线，虚线代表模型 B的 P-R曲线。横轴 0点附近代表值最大时模型的精确率和召回率。
由图7-1可见，在召回率接近0时，模型A的精确率是0.9，模型B的精确率是1，这说明模型B中得分前几位的样本全部是真正的正样本，而模型A中即使是得分最高的几个样本也存在预测错误的情况。然而，随着召回率的增加，精确率整体上有所下降:特别地，在召回率为1时，模型A的精确率反而超过了模型B。这充分说明，只用一个点的精确率和召回率是不能全面衡量模型性能的，只有通过P-R曲线的整体表现，才能对模型进行更全面的评估。

![PR](https://sunjc911.github.io/assets/images/DeepRec/PR.png)

计算曲线下面积（AUC）能够量化PR曲线的优劣。沿横轴做积分。越大越好。

#### ROC曲线

the Receiver Operating Characteristic曲线，翻译为受试者工作特征曲线。

ROC曲线的横坐标为False Positive Rate (FPR，假阳性率) : 纵标为True Positive Rate (TPR，真阳性率) 。FPR和TPR的计算方法如下:

![ROC](https://sunjc911.github.io/assets/images/DeepRec/ROC.png)

在(式7-6)中，P是真实的正样本数量，N是真实的负样本数量:TP指的是 P个正样本中被分类器预测为正样本的个数，FP指的是N个负样本中被分类器预测为负样本的个数
ROC曲线的定义较复杂，但绘制ROC曲线的过程并不困难。通过绘制ROC曲线，读者能够清楚ROC曲线是如何衡量一个推荐序列的效果的。
同 P-R 曲线一样，ROC 曲线也是通过不断移动模型正样本闽值生成的。这里举例解释该过程。

假设测试集中一共有 20 个样本，模型的输出如表 7-1 所示。表中第 1 列为样本序号第2列为样本的真实标签，第3列为模型输出的样本为正的概率。样本按照预测概率从高到低排序。在输出最终的正例、负例之前，需要指定一个闯值:预测概率大于该闯值的样本会被判为正例，小于该闯值的会被判为负例。假如指定0.9为闯值，那么只有第1个样本会被预测为正例，其他全部都是负例。这里的闯值也被称为“截断点”

![ROC1](https://sunjc911.github.io/assets/images/DeepRec/ROC1.png)

动态地调整截断点，从最高的得分开始(实际上是从正无穷开始，对应着ROC 曲线的零点)，逐渐调整到最低得分。每一个截断点都会对应一个 FPR 和TPR，在 ROC 图上绘制出每个截断点对应的位置，再连接每个点即可得到最终的ROC曲线。
就本例来说，当截断点选择为正无穷时，模型把全部样本预测为负例，那么FP和TP必然都为0，FPR和TPR也都为0，因此曲线的第一个点就是 (0，0) 。当把截断点调整为0.9时，模型预测1号样本为正样本，并且该样本确实是正样本，因此，TP=1。在20个样本中，所有正例数量为P=10，故TPR=TP/P=1/10。本例没有预测错的正样本，即FP=0，负样本总数N=10，故FPR=FP/N=0/10=0，对应着ROC图上的点 (0，0.1) 。依次调整截断点直到画出全部关键点，再连接关键点即得到最终的ROC曲线，如图7-2所示。

![ROC3](https://sunjc911.github.io/assets/images/DeepRec/ROC3.png)

其实，还有一种更直观的绘制 ROC 曲线的方法。首先，根据样本标签统计出正负样本的数量，假设正样本数量为P，负样本数量为N;接下来，把横轴的刻度间隔设置为 1/N纵轴的刻度间隔设置为 1/P: 再根据模型输出的预测概率对样本进行排序(从高到低)依次遍历样本，同时从零点开始绘制ROC曲线，每遇到一个正样本就沿纵轴方向绘制一个刻度间隔的曲线，每遇到一个负样本就沿横轴方向绘制一个刻度间隔的曲线，直到遍历完所有样本，曲线最终停在 (1，1) 这个点，整个ROC曲线绘制完成。
在绘制完 ROC曲线后，同 P-R曲线一样，可以计算出 ROC曲线的 AUC，并用AUC评估推荐系统排序模型的优劣。

#### 平均精度值

mean Average Precision ，mAP。是对平均精度（AP）的再次平均。

什么是平均精度。

![AP](https://sunjc911.github.io/assets/images/DeepRec/AP.png)

如果推荐系统对测试集中的每个用户都进行样本排序，那么**每个用户都会计算出一个AP值，再对所有用户的AP值进行平均，就得到了mAP**。也就是说，mAP是对精确度平均的平均。值得注意的是，mAP的计算方法和 P-R曲线、ROC曲线的计算方法完全不同，因为**mAP需要对每个用户的样本进行分用户排序**，而**P-R曲线和ROC曲线均是对全量测试样本进行排序**。这一点在实际操作中是需要注意的。

#### 合理选择评估指标

还包括归一化折扣累计收益NDCG、覆盖率coverage、多样性diversity等

离线评估的目的在于快速定位问题，快速排除不可行的思路，为线上评估找到“靠谱”的候选者。因此，根据业务场景选择2~4个有代表性的离线指标，进行高效率的离线实验才是离线评估正确的“打开方式”。

### 更接近线上环境的离线评估方法——Replay

#### 模型评估的逻辑闭环

如何评估模型才能确定其好坏

![Re](https://sunjc911.github.io/assets/images/DeepRec/Re.png)

**离线评估的重点是让离线评估的结果能够尽量接近线上结果**。要达到这个目标，就应该让离线评估过程尽量还原线上环境，线上环境不仅包括线上的数据环境，也包括模型的更新频率等应用环境。

#### 动态离线评估方法

传统离线评估方法的弊端是评估过程是“静态的”，即模型不会随着评估的进行而更新这显然不符合事实。假设用一个月的测试数据评估一个推荐系统，如果评估过程是“静态的”，就意味着当模型对月末的数据进行预测时，模型已经停止更新近 30 天了，这不仅不符合工程实践(因为没有一家一线互联网公司会30天才更新一次模型)，而且会导致模型效果评估的失真。为了解决这个问题，需要让整个评估过程“动”起来，使之更加接近真实的线上环境。
**动态离线评估方法先根据样本产生时间对测试样本由早到晚进行排序，再用模型根据样本时间依次进行预测。**在模型更新的时间点上，模型需要**增量学习**更新时间点前的测试样本，更新后继续进行后续的评估。传统离线评估方法和动态离线评估方法比对如图7-4所示。

![Re1](https://sunjc911.github.io/assets/images/DeepRec/Re1.png)

毫无疑问，动态评估的过程更接近真实的线上环境，评测结果也更接近客观情况。如果模型更新的频率持续加快，快到接收到样本后就更新。整个动态评估的过程也变成逐样本回放的精准线上仿真过程，这就是经典的仿真式离线评估方法一-Replay。事实上，Replay方法不仅适用于几乎所有推荐模型的离线评估，而且是强化学习类模型唯一的离线评估方法[1]。以 3.10节介绍的 DRN模型为例，由于模型需要在线上不断接收反馈并进行在线更新，这就意味着为了模拟线上环境，必须在线下使用 Replay 方法模拟反馈的产生过程和模型的实时更新过程，只有这样才能对强化学习模型进行合理的评估

#### Netflix的Replay评估方法实践

最关键的一点是: **既然是模拟在线数据流，就要求在每个样本产生时，样本中不能包含任何“未来信息”，要避免“数据穿越”的现象发生**

![Re2](https://sunjc911.github.io/assets/images/DeepRec/Re2.png)

从图中可以看出，时光机是以天为单位启动的 (Runs once a day) 。它的主任务Snapshot Jobs(数据快照)的主要功能是把当天的各类日志、特征、数据整合起来，形成当天的、供模型训练和评估使用的样本数据。以日期为目录名称，将样本数据保存在分布式文件系统 S3 中，并对外提供统一的 API，可以根据用户所需的时间获取这些数据快照。从Snapshot Jobs的输入来看，时光机整合的信息包括两大部分:
(1) 场景信息(Context) : 它包括存储在Hive中的不经常改变的场景信息，如用户的资料、设备信息、物品信息等。
(2) 系统日志流:指的是系统实时产生的日志，它包括用户的观看历史 (Viewing History) 、用户的推荐列表(My List) 和用户的评价 (Ratings) 。这些日志从各自的服务( Service) 中产生，由Netflix的统一数据接口Prana对外提供服务。
Snapshot Jobs通过 S3获取场景信息，通过 Prana获取日志信息，在经过整合处理、生成特征之后，保存当天的数据快照到S3。
在生成每天的数据快照后，使用 Replay 方法进行离线评估就不再是一件困难的事情了，因为没有必要在 Replay 过程中进行烦琐的特征计算，直接使用当天的数据快照信息即可。

不失灵活性的是，由于每种模型所需的特征不同，Snapshot Jobs不可能一次性生成所有模型需要的特征，如果需要某些特殊的特征，时光机也能在通用快照的基础上，单独为某模型生成数据快照。在时光机的架构之上，使用某个时间段的样本进行一次 Replay 评估，相当于进行了一次时光旅行 (time travel) 。希望读者能够在这“美妙”的时光旅行中找到自己理想中的模型。

#### A/B测试与线上评估指标

### 什么是A/B测试

A/B 测试又称为“分流测试”或“分桶测试”，是一个随机实验，通常被分为**实验组和对照组**。在利用**控制变量法保持单一变量**的前提下，将A、B两组数据进行**对比**，得出实验结论。具体到互联网场景下的算法测试中，可将用户随机分成实验组和对照组，**对实验组的用户施以新模型，对对照组的用户施以旧模型**，比较实验组和对照组在各线上评估指标
上的差异。相对离线评估而言，线上A/B测试无法被替代的原因主要有以下3点。

1.离线评估无法完全消除**数据有偏** (data bias) 现象的影响，因此得出的离线评估结果无法完全替代线上评估结果。
2.离线评估**无法完全还原线上的工程环境**。一般来讲，离线评估往往不考虑线上环境的延迟、数据丢失、标签数据缺失等情况。因此，离线评估环境只能说是理想状态下的工程环境，得出的评估结果存在**一定的失真**现象。
3.线上系统的**某些商业指标在离线评估中无法计算**。离线评估一般针对模型本身进行评估，无法直接获得与模型相关的其他指标，特别是商业指标。以新的推荐模型为例，离线评估关注的往往是ROC曲线、PR曲线等的改进，而线上评估可以全面了解该推荐模型带来的**用户点击率、留存时长、PV访问量等**的变化。这些都要由A/B测试进行全面评估。

#### A/B测试的“分桶”原则

在 A/B 测试分桶的过程中，需要注意的是**样本的独立性和采样方式的无偏性**: 同个用户在测试的全程**只能被分到同一个桶**中，在分桶过程中所用的**用户ID应是一个随机数**，这样才能保证桶中的样本是无偏的。
在实际的A/B测试场景中，同一个网站或应用往往要同时进行多组不同类型的 A/B测试，例如在前端进行不同 App界面的 A/B测试，在业务层进行不同中间件效率的A/B测试在算法层同时进行推荐场景1和推荐场景2的A/B测试。如果不制定有效的A/B测试原则则不同层的测试之间势必互相工扰，甚至同层测试也可能因分流策略不当导致指标的失真。谷歌关于其实验平台的论文Overlapping Experiment Infrastructure: More，Better，Faster Experimentation[2]详细地介绍了实验流量分层和分流的机制，它保证了宝贵的线上测试流量的高可用性。
**可以用两个原则简述A/B测试分层和分流的机制**
**(1) 层与层之间的流量“正交”**
**(2) 同层之间的流量“互斥”**

层与层之间的流量“正交”的具体含义为: 层与层之间的独立实验的流量是正交的，即实验中每组的流量穿越该层后，**都会被再次随机打散**，且**均匀地分布**在下层实验的每个实
验组中以图7-6为例，在X层的实验中，流量被随机平均分为X1 (蓝色) 和X(白色) 两部分。在 y层的实验中，X1和 X的流量应该被随机且均匀地分配给 Y层的两个桶Y和Y.如果Y1和Y的X层流量分配不均匀，那么Y层的样本将是有偏的，Y层的实验结果将被X层的实验影响，无法客观地反映Y层实验组和对照组变量的影响。所以穿过X1层和X的流量都应被随机打散，均匀分布在Y1组和Y组中。

![AB](https://sunjc911.github.io/assets/images/DeepRec/AB.png)

司层之间的流量“互斥”的具体含义为:
(1) 如果同层之间进行**多组 A/B测试**，那么**不同测试之间的流量是不重叠**的，即“互斥”的。
(2) **一组**A/B测试中**实验组和对照组的流量是不重叠**的，是“互斥”的。在基于用户的 A/B 测试中，“互斥”的含义应进一步解读为不同实验之间，以及A/B测试的实验组和对照组之间的用户应是不重叠的。特别是对推荐系统来说，用户体验的一致性很重要，推荐系统也应考虑用户的教育及引导过程，因此在A/B测试中保证同一用户始终分配到同一个组中是必要的。
**A/B测试的“正交”与“互斥”原则共同保证了A/B测试指标的客观性**。那么，与离线评估的指标相比，应该如何选取线上A/B测试的评估指标呢?

#### 线上A/B测试的评估指标

AB测是上线前的最后一道测试，通过后的模型将直接服务于线上用户，完成公司的商业目标。因此**AB测的指标与线上业务的核心指标保持一致。**

![AB1](https://sunjc911.github.io/assets/images/DeepRec/AB1.png)

读者应该已经注意到了，线上A/B测试的指标与离线评估的指标(如AUC、F1-score等)有较大差异。离线评估不具备直接计算业务核心指标的条件，因此退而求其次，选择了偏向于技术评估的模型相关指标。但在公司层面，更关心能够驱动业务发展的核心指标。**因此，在具备线上测试环境时，利用A/B测试验证模型对业务核心指标的提升效果是必要的。从这个意义上讲，线上 A/B测试的作用是离线评估永远无法替代的。**

### 快速线上评估方法——Interleaving

矛盾一-算法工程师日益增长的A/B测试需求和线上A/B测试资源严重不足之间的矛盾。

正对上述问题，Interleaving由此而生。Interleaving 方法被当作线上A/B测试的预选阶段(如图7-7所示) 进行候选算法的快速筛选，从大量初始想法中筛选出少量“优秀”的推荐算法。再对缩小的算法集合进行传统的A/B 测试，以测量它们对用户行为的长期影响。

![IL](https://sunjc911.github.io/assets/images/DeepRec/IL.png)

图 7-7 中用灯泡代表候选算法。其中，最优的获胜算法用红色灯泡表示。Interleaving张够快速地将最初的候选算法集合进行缩减，比传统的 A/B 测试更快的确定最优算法。笔者将以Netflix的应用场景为例，介绍Interleaving方法的原理和特点。

#### 传统AB测存在的统计学问题

除了效率问题还有统计学问题。

两组人可口百事盲喝

在总的测试人群中，对于可乐的消费习惯肯定各不相同，从几乎不喝可乐到每天喝大量可乐的人都有。可乐的重消费人群肯定只占总测试人群的一小部分，但他们可能占整体汽水消费的较大比例。
这个问题**导致A/B两组之间重度可乐消费者的微小不平衡，也可能对结论产生不成比例的影响**。
在互联网应用中，这样的问题同样存在。在 Netflix 的场景下，非常活跃用户的数量是少数，但其贡献的观看时长却占较大的比例，因此，在Netflix的A/B测试中，活跃用户被分在 A 组的多还是被分在 B 组的多，将对测试结果产生较大影响，从而掩盖了模型的
真实效果。如何解决这个问题呢?一个可行的方法是不对测试人群进行分组，而是让所有测试者都可以自由选择百事可乐和可口可乐(测试过程中仍没有品牌标签，但能区分是两种不同的可乐)。在实验结束时，统计每个人消费可口可乐和百事可乐的比例，然后对每个人的消费比例进行平均，得到整体的消费比例。

这个测试方案的优点在于:
(1) 消除了A/B组测试者自身属性分布不均的问题
(2) 通过给予每个人相同的权重，降低了重度消费者对结果的过多影响。

这种**不区分A/B组，而是把不同的被测对象同时提供给受试者，最后根据受试者喜好得出评估结果的方法**就是Interleaving方法。

#### Interleaving方法的实现

![IL1](https://sunjc911.github.io/assets/images/DeepRec/IL1.png)

在传统的 A/B 测试中，Netflix 会选择两组订阅用户:一组接受排序算法 A的推荐结果，另一组接受排序算法B的推荐结果
而在 Interleaving 方法中，只有一组订阅用户，这些订阅用户会收到通过混合算法A和B的排名生成的交替排名。
这就使得用户可以在一行里同时看到算法 A 和 B 的推荐结果 (用户无法区分一个物品是由算法A推荐的还是由算法B推荐的)，进而通过计算观看时长等指标来衡量到底是算法A的效果好还是算法B的效果好。

当然，在使用Interleaving方法进行测试的时候，**必须考虑位置偏差的存在，避免来自算法 A 的视频总排在第一位**。因此，需要以相等的概率让算法 A 和算法B交替领先。这类似于在野球场打球时，两个队长先通过扔硬币的方式决定谁先选人，再交替选队员的过程(如图7-9所示)

![IL2](https://sunjc911.github.io/assets/images/DeepRec/IL2.png)

厘清了 Interleaving 方法的具体评估过程后，还需要验证的是这个评估方法到底能不能替代传统的 A/B 测试，会不会得出错误的结果。Netflix 从两个方面进行了验证，一是Interleaving的“灵敏度”;二是Interleaving的“正确性”。

#### Interleaving方法与传统AB测的灵敏度比较

Netflix 进行的这组“灵敏度”实验希望验证的是 Interleaving 方法相比传统A/B 测试，**需要多少样本就能够验证出算法 A 和算法 B 的优劣**。由于线上测试的资源往往是受限的自然希望 Interleaving 方法能够利用较少的线上资源和较少的测试用户解决评估问题，这就是所谓的灵敏度比较。

![IL3](https://sunjc911.github.io/assets/images/DeepRec/IL3.png)

#### Interleaving方法指标与AB测试指标的相关性

除了能够利用小样本快速进行算法评估，**Interleaving方法的判断结果是否与A/B 测试一致，也是检验 Interleaving 方法能否在线上评估阶段取代 A/B 测试的关键。**

图7-11所示为Interleaving方法的指标与A/B测试指标之间的相关性。每个数据点代表-个推荐模型。可以发现，Interleaving 指标与 A/B 测试评估指标之间存在非常强的相关性，这就验证了在 Interleaving 实验中胜出的算法也极有可能在之后的A/B测试中胜出。

需要注意的是，虽然二者测试指标的相关性极强，但 Interleaving 方法的实验中所展示的页面并不是单独由算法 A 或者算法 B 生成的产品页面，**而仅仅是实验用的混合页面**.因此**如果要测试某算法的真实效果，Interleaving方法无法完全替代 A/B 测试**。如果希望得到**更全面、真实的线上测试指标，则 A/B 测试是最权威的测试方法。**

![IL4](https://sunjc911.github.io/assets/images/DeepRec/IL4.png)

#### 优缺点

优点：所需样本少、测试速度块、与传统AB测无明显差异。

缺点：比AB测复杂。实验逻辑和业务逻辑纠缠在一起，因此业务逻辑可能会被干扰。需要大量辅助性数据标识添加到整个数据流中。只是对“用户对算法推荐结果偏好程度”的相对测量，不能得出一个算法真实的表现。为此，网飞设**计Interleaving+AB测**两阶实验结构，完善整个线上测试的框架。

### 推荐系统的评估体系

本章依次介绍了推荐系统的主要评估方法及主要的评估指标。这些模型评估的方法并不是独立的，而是自成体系的。一**个成熟的推荐系统评估体系应综合考虑评估效率和正确性，利用较少的资源，快速地筛选出效果更好的模型**。本节在已介绍的所有推荐系统评估方法的基础上，系统性地讨论如何搭建一套成熟的推荐系统测试与评估体系。

7.3 节中讨论过，对一个公司来说，最公正也是最合理的评估方法是**进行线上测试,评估模型能否更好地达成公司或者团队的商业目标**。

既然这样，为什么不能对任何模型的改进都进行线上测试以确定改进是否合理呢? 原因在 7.5 节介绍 Interleaving 方法时已经给出，是因为线上 A/B 测试要**占用宝贵且有限的线上流量资源，还可能对用户体验造成损害**，因此有限的线上测试机会远不能满足算法工程师改进算法的需求。另外，线上测试往往需要持续几天甚至几周，这将使算法迭代的时间大大加长。

正因为**线上测试的种种限制**，**“离线测试”才成了算法工程师退而求其次的选择**。离线测试可以利用近乎无限的离线计算资源，快速得出评估结果，从而快速实现模型的迭代优化。

在线上 A/B 测试和传统离线测试之间，还有 Replay、Interleaving 等评估测试方法。Replay 方法能够最大程度地在离线状态下模拟线上测试过程，Interleaving方法则可以建立快速的线上测试环境。这种多层级的评估测试方法共同构成了完整的推荐系统评估体系如图7-12所示)，做到评测效率和正确性之间的平衡。

![76](https://sunjc911.github.io/assets/images/DeepRec/76.png)

在图 7-12 所示的评测体系示意图中，左侧是不同的评估方法，右侧是“金字塔”形的模型筛选过程。可以看出:**越是底层，越存在更多待筛选的模型和待验证的改进想法**。由于数量巨大，**“评估效率”就成了更关键的考虑因素**，对评估“正确性”的要求就没有那么苛刻，这时就应该使用**效率更高的离线评估方法。**

随着候选模型被一层层筛选出来，**越接近正式上线**的阶段，评估方法对评估“**正确性”的要求就越严格**。在模型正式上线前，应该以最接近真实产品体验的**A/B测试做最后的模型评估**，产生**最具说服力的在线指标之后，才能进行最终的模型上线**，完成模型改进的迭代过程。

## 第八章 深度学习推荐系统的前沿实践

### Facebook的深度学习推荐系统

GBDT+LR与DLRM

#### 推荐系统应用场景

Facebook 广告推荐系统的应用场景是一个**标准的 CTR 预估场景**，系统输入用户 (User）、广告 (Ad) 、上下文(Context) 的相关特征，预测 CTR，进而利用 CTR 进行广告排序和推荐。需要强调的是: Facebook 广告系统的其他模块需要利用CTR计算广告出价投资回报率(Returm on Investment，ROI) 等预估值，因此 **CTR 模型的预估值应是一个具有物理意义的精准的 CTR，而不是仅仅输出广告排序的高低关系(这一点是计算广告系统与推荐系统关键的不同之处)。**Facebook也特别介绍了CTR校正的方法，用于在CTR预估模型输出值与真实值有偏离时进行校正。

#### 以GBDT+LR组合模型为基础的CTR预估模型

简而言之，Facebook的 CTR预估模型采用了 GBDT+LR的模型结构，通过**GBDT自动进行特征筛选和组合，生成新的离散型特征向量，再把该特征向量当作LR模型的输入，预测CTR**。其中，使用 GBDT 构建特征工程和利用 LR 预测 CTR 两步是采用相同的优化目标独立训练的。所以不存在如何将LR的梯度回传到GBDT这类复杂的训练问题，这样的做法也符合Facebook一贯的实用主义的风格。

Facebook巨大的数据量及 **GBDT较难实施并行化**的特点，Facebook 的工程师在实际应用中采用了“**GBDT部分几天更新一次，LR部分准实时更新**”的模型更新策略，兼顾模型的实时性和复杂度。

#### 实时数据流架构

Facebook基于Scribe (由Facebook开发并开源的日志收集系统) 构建了实时数据流架构，被称为online data joiner模块(在线数据整合)，该模块与Facebook推荐系统其他模块的关系如图8-2所示。

![FB](https://sunjc911.github.io/assets/images/DeepRec/FB.png)

该模块最重要的作用是准实时地把来自不同数据流的数据整合起来，形成训练样本，并最终与点击数据进行整合，**形成完整的有标签样本**。在整个过程中，最应该注意的有以下三点。
1.waiting window (数据等待窗口)的设定
waiting window指的是在曝光 (impression) 发生后，要等待多久才能够判定一个曝光行为是否产生了对应的点击。如果waiting window过大，则数据实时性会受影响; 如果waiting window过小，则会有一部分点击数据来不及与曝光数据进行联结，导致样本 CTR 与真实值不符。这是一个工程调优的问题，需要有针对性地找到与实际业务相匹配的waitingwindow。除此之外，少量的点击数据遗漏是不可避免的，这就要求数据平台能够阶段性地对所有数据进行全量重新处理，避免流处理平台产生的误差积累。
2.分布式架构与全局统一的action id (行为id)为了实现分布式架构下曝光记录和点击记录的整合，Facebook除了为每个行为建立全局统一的request id (请求id) ，还建立了HashQueue(哈希队列) 用于缓存曝光记录。在HashQueue中的曝光记录，**如果在等待窗口过期时还没有匹配到点击，就会被当作负样本**。Facebook使用Scribe框架实现了这一过程，更多公司使用 Kafka 完成大数据缓存，使用 等流计算框架完成后续的实时计算。Flink、Spark Streaming
3.数据流保护机制
Facebook专门提到了online data joiner的保护机制，因为**一旦data joiner由于某些异常而失效**(如点击数据流由于action id的Bug无法与曝光数据流进行正确联结)，所有的样本都会成为负样本。由于模型实时进行训练和服务，模型准确度将立刻受到错误样本数据的影响，进而直接影响广告投放和公司利润，后果是非常严重的。为此，Facebook专门设立了**异常检测**机制，一旦发现实时样本流的数据分布发生变化，将立即切断在线学习的过程，防止预测模型受到影响。

#### 降采样与模型校正

为了**控制数据规模，降低训练开销**，Facebook实践了两种降采样的方法一uniform subsampling(均匀采样)和 negative down sampling (负样本降采样，以下简称负采样)均匀采样是对所有样本进行无差别的随机抽样，为选取最优的采样频率，Facebook 试验了 1%、10%、50%、100%四个采样频率，图 8-3 比较了不同采样频率下训练出的模型的损失。

![FB1](https://sunjc911.github.io/assets/images/DeepRec/FB1.png)

可以看到，当采样频率为 10%时，相比全量数据训练的模型(最右侧 100%的柱状图模型损失仅上升了 1%，而当采样频率降低到 1%时，模型损失大幅上升了 9%左右。因此，10%的采样频率是一个比较合适的平衡工程消耗和理论最优的选择。

另一种方法负采样则保留全量正样本，对负样本进行降采样。除了提高训练效率，**负采样还直接解决了正负样本不均衡的问题**，Facebook经验性地选择了从0.0001到0.1的负采样频率，试验效果如图8-4所示。

![FB2](https://sunjc911.github.io/assets/images/DeepRec/FB2.png)

选择0.0250

**负采样带来的问题是CTR预估值的漂移**，假设真实CTR是0.1%，进行0.01的负采样之后，CTR 将会攀升到 10%左右。为了进行准确的竟价及 ROI 预估，CTR 预估模型是要提供准确的、有物理意义的 CTR 值的，因此**在进行负采样后需要进行 CTR 的校正，使 CTR 模型的预估值的期望回到** 0.1%。校正的公式如(式 8-1) 所示。

![FB3](https://sunjc911.github.io/assets/images/DeepRec/FB3.png)

q矫正后ctr，p模型预估ctr，w负采样频率。

#### FB GBDT+LR组合模型的工程实践

Facebook基于GBDT+LR组合模型实现的广告推荐系统虽然已经是 2014年的工作，但我们仍能从中吸取不少模型改造和工程实现的经验，总结来讲最值得学习的有下面三点:
1.**特征工程模型化**
2014 年，在很多从业者还在通过调参经验尝试各种特征组合的时候，Facebook利用模型进行特征**自动组合和筛选**是相当创新的思路，也几乎是从那时起，各种深度学习和Embedding的思想开始爆发，发扬着特征工程模型化的思路。
2.模型**复杂性和实效性的权衡**
对GBDT和LR采用不同的更新频率是非常工程化且有价值的实践经验，也是对组合模型各部分优点最大化的解决方案。
3.**有想法要用数据验证**
在工作中，我们往往有很多直觉上的结论，比如数据和模型实时性的影响有多大，GBDT应该设置多少棵子树，到底用负采样还是随机采样。针对这些问题，Facebook告诉我们用数据说话，无论是多么小的一个选择，都应该用数据支撑，这才是一位工程师严谨的工作态度。

#### FB的深度学习模型DLRM

![FB4](https://sunjc911.github.io/assets/images/DeepRec/FB4.png)

特征工程:所有特征被分为两类:一类是将类别、id 类特征用 **one-hot编码生成的稀疏特征**(sparse features) ; 另一类是**数值型连续特征** (dense features)。
Embedding层: 每个类别型特征转换成one-hot向量后，用Embedding层将其转换成维度为n的Embedding向量。也就是说，**将稀疏特征转换成Embedding向量**。而年龄、收入等连续型特征将被连接(concat)成一个特征向量，输入图中黄色的 MLP 中，被转化成同样维度为n 的向量。至此，无论是类别型稀疏特征，还是连续型特征组成的特征向量，在经过Embedding层后，**都被转换成了n维的Embedding向量**。神经网络层(NNs 层): Embedding 层之上是由三角形代表的神经网络层。也就是说，得到 n 维的 Embedding 向量后，每类 Embedding 还有可能进一步通过神经网络层做转换。但这个过程是有选择性的，根据调参和性能评估的情况来决定是否引入神经网络层进行进一步的特征处理。
特征交互层 (interactions层): 这一层会将之前的Embedding两两做内积，再与之前连续型特征对应的 Embedding 连接，输入后续的 MLP。所以这一步其实与3.5节介绍的PNN一样，目的是让**特征之间做充分的交叉**，组合之后，再进入上层MLP做最终的目标拟合
目标拟合层:结构图中最上层的蓝色三角代表了另一个全连接多层神经网络，在最后一层使用 **sigmoid函数**给出最终的点击率预估，这也是非常标准的深度学习模型输出层的设置。

非常标准的工业界深度学习推荐模型

#### DLRM的并行训练方法

简单来说，DLRM 融合使用了模型并行和数据并行的方法，对 Embedding部分采用了模型并行，对 MLP 部分采用了数据并行。Embedding 部分采用模型并行的目的是减轻大量 Embedding 层参数带来的内存瓶颈问题。MLP 部分采用数据并行可以并行进行前向和反向传播。
其中，Embedding做模型并行训练指的是在一个 device (设备) 或者计算节点上，仅保存一部分Embedding层参数，每个设备进行并行mini batch梯度更新时，仅更新自己节点上的部分Embedding层参数。
MLP 层和特征交瓦层进行数据并行训练指的是每个设备上已经有了全部模型参数每个设备利用部分数据计算梯度，再利用全量规约(AIIReduce) 的方法汇总所有梯度进行参数更新。

#### DLRM的效果

谷歌的DCN为Baseline。区别在于特征交叉方式不同，DLRM采用不同特征域两两内积的交叉方式。DCN采用cross layer的特征交叉方式。DLRM在SGD方式下略胜一筹。

#### FB的深度学习推荐系统总结

非常工业化，简单直接，以解决问题为主。**第一个深度学习模型可以参考DLRM为标准。**

### Airbnb基于Embedding的实时搜索推荐系统

作为深度学习的“核心操作”之一，Embedding技术不仅能够将大量稀疏特征转换成稠密特征，便于输入深度学习网络，而且能够通过Embedding将物品的语义特征进行编码，直接通过相似度的计算进行相似物品的搜索。Airbnb正是充分挖掘了Embedding的这两点优势，基于Embedding构建了其实时搜索推荐系统。

#### 应用场景

Airbnb作为全世界最大的短租网站，提供了一个连接房主(host) 和短租客(guest/user)的中介平台。这样一个短租房中介平台的交互方式是一个典型的搜索推荐场景，租客输入地点、价位、关键词等信息后，Airbnb会给出房源的搜索推荐列表，如图8-8所示。

租客与房主的交互方式

![AI](https://sunjc911.github.io/assets/images/DeepRec/AI.png)

Airbnb的搜索团队正是基于这样的业务场景，利用几种交互方式产生的历史数据构建了实时搜索排序模型。为了捕捉用户的“短期”和“长期”兴趣，Airbnb并没有将用户历史数据中的点击房源id序列 (clicked listing ids) 或者预订房源id序列(booked listing ids) 直接输入排序模型，而是先对租客和房源分别进行Embeddig，进而利用Embedding的结果构建出诸多特征，作为排序模型的输入。
具体到Embedding方法上，Airbnb生成了两种不同的Embedding，分别对用户的“短期和“长期”兴趣进行编码。其中生成短期兴趣Embedding的目的是进行房源的相似推荐，以及对用户进行session(会话) 内的实时个性化推荐。生成长期兴趣 Embedding 的目的是在最终的推荐结果中照顾到用户之前的预订偏好，推荐更容易被用户预订的个性化房源。

#### 基于短期兴趣的Embedding方法

Airbnb 利用 Session 内点击数据对房源进行 Embedding，捕捉用户在一次搜索过程中的短期兴趣，其中 Session 内点击数据指的是一个用户在一次搜索过程中点击的房源序列，这个序列需要满足两个条件:一是只有在房源详情页停留超过30秒才算序列中的一个数据点;二是如果用户超过30分钟没有动作，那么这个序列会被打断，不再是一个序列。这么做的目的有二，一是**清洗噪声点和负反馈信号**;二是**避免非相关序列**的产生。

有了由点击房源组成的序列 (sequence) ，就可以像 4.3 节介绍的 Item2vec方法那样把这个序列当作一个“句子”样本，开始Embedding的过程。Airbnb选择了4.2节介绍的word2vec的skip-gram model作为Embedding方法的框架，通过修改Word2vec的目标函数(objective) 使其逼近Airbnb的业务目标。

Word2vec的skip-gram model的目标函数

![AI1](https://sunjc911.github.io/assets/images/DeepRec/AI1.png)

在原始Word2vec Embedding的基础上，针对其业务特点，Airbnb的工程师希望将预订信息引入Embedding。这样可以使Airbnb的搜索列表和相似房源列表更倾向于推荐之前预订成功Session中的房源。从这个动机出发，Airbnb把会话点击序列分成两类，最终产生预订行为的称为预订会话，没有的称为探索性会话 (exploratory session)每个预订会话中只有最后一个房源是被预订房源(booked listing)，为了将这个预订行为引入目标函数，不管这个被预订房源在不在Word2vec的滑动窗口中，都假设这个被预订房源与滑动窗口的中心房源相关，相当于引入了一个全局上下文(global context) 到目标函数中，因此，目标函数就变成了 (式8-5) 的样子。

![AI2](https://sunjc911.github.io/assets/images/DeepRec/AI2.png)

至此，房源Embedding的目标函数就定义完成了，Embedding的训练过程就是Word2vec使用负采样方法进行训练的标准过程，这里不再详述。
除此之外，论文中还介绍了解决冷启动问题的方法。简而言之，如果有新的房源缺失Embedding向量，就找附近的3个同样类型、相似价格的房源向量进行平均得到，这不失为一个实用的工程经验。

#### 基于长期兴趣的用户Embedding和房源Embedding

短期兴趣 Embedding 使用用户的点击数据构建了房源 Embedding，基于该Embedding可以很好地找出相似房源，但有所欠缺的是，该Embedding并没有包含用户的长期兴趣信息。比如用户6个月前预订过一个房源，其中包含了该用户对房屋价格、房屋类型等属性的长期偏好，但由于之前的 Embedding 只使用了**Session级别的点击数据，从而丢失了用户的长期兴趣信息**。
为了捕捉用户的长期偏好，Airbnb使用了预订会话序列。比如用户j在过去1年依次预订过 5个房源，那么其预订会话就是si= (li1，l2，li3，li4，li5) 。既然有了预订会话的集合，是否可以像之前对待点击会话 (click session) 那样将Word2vec的方法用到 Embedding 上呢? 答案是否定的，因为会遇到非常棘手的数据稀疏问题。具体地讲，预订会话的数据稀疏问题表现为以下3点:

(1) 预订行为的总体数量本身远远小于点击行为，所以预订会话集合的大小是远远小于点击会话的。
(2) 单一用户的预订行为很少，大量用户在过去1年甚至只预订过一个房源，这导致很多预订会话序列的长度仅仅为1。
(3) 大部分房源被预订的次数也少得可怜，要使 Word2vec 训练出较稳定有意义的Embedding，物品最少需要出现5~10次，但大量房源被预订的次数少于5次，根本无法得到有效的Embedding。
如何解决如此**严重的数据稀疏**问题，训练出有意义的用户Embedding和房源Embedding呢? Airbnb给出的答案是**基于某些属性规则做相似用户和相似房源的聚合**。举例来说，房源属性如表8-2所示。

![AI4](https://sunjc911.github.io/assets/images/DeepRec/AI4.png)

![AI5](https://sunjc911.github.io/assets/images/DeepRec/AI5.png)

**有了用户属性和房源属性，就可以用聚合数据的方式生成新的预订序列(booking session sequence)。直接用用户属性替代原来的user id，生成一个由所有该用户属性预订历史组成的预订序列。这种方法解决了用户预订数据稀疏的问题。**
在得到用户属性的预订序列之后，如何得到用户属性和房源属性的Embedding呢?为了让user type Embedding和listing type Embedding在同一个向量空间中生成，Airbnb采用了1种比较“反直觉”的方式。
针对某一userid按时间排序的booking session (l1，1，...， Im) ，用(user_type， listing_type) 组成的元组替换原来的listing item，原序列就变成了 ( (utypel，ltype1)， (utype2，ltype2)，...， (utypeM， ltypeM))，这里ltypel指的就是房源l1对应的房源属性utype1指的是该用户在预订房源11时的用户属性，由于用户的user type会随着时间变化
所以utype1，utype2不一定相同。有了该序列的定义，下面的问题是如何训练Embedding使得用户属性和房源属性在一个空间内。训练所用的目标函数完全沿用 8.2.2 节定义的目标函数的形式，但由于这里使用(user type，listing type) 元组替换了原来的listing，如何确定“中心词”(central item)就成了核心问题。事实上，Airbnb 在相关论文中并没有披露这里的技术细节，但结合其大致的介绍，本节将给出一种最接近论文原文的训练方式。
Airbnb分别给出了训练user type Embedding和listing type Embedding时，滑动窗口内“中心词”分别是user type (ur) 和listing type (I) 时的目标函数:

![AI6](https://sunjc911.github.io/assets/images/DeepRec/AI6.png)

其中，Dbook是中心词附近的用户属性和房源属性的集合。所以在训练过程中，用户属性和房源属性完全是被同等对待的，这两个目标函数也是完全一样的。
可以认为，Airbnb在训练user type Embedding和listing type Embedding时是把所有元组扁平化了，把用户属性和房源属性当作完全相同的词去训练Embedding，这样的方式保证了二者自然而然地在一个向量空间中生成。虽然整个过程浪费了一些信息，但不失为一个好的工程解决办法。
定义了Embedding的目标函数，用户和房源又被定义在同一向量空间中，利用 Word2vec 负采样的训练方法，可以同时得到用户和房源的 Embedding，二者之间的余弦相似度代表了用户对某房源的长期兴趣偏好。

#### Airbnb搜索词的Embedding

除了计算用户和房源的Embedding，Airbnb还在其搜索推荐系统中对搜索词(query)进行了Embedding，与用户Embedding的方法类似，通过把搜索词和房源置于同一向量空间进行Embedding，再通过二者之间的余弦相似度进行排序。从图8-12和图8-13中可以看出，采用Embedding方法生成的搜索排序和传统文本相似度方法的差别。

可以看出，在引入Embedding之前，搜索结果只能是输入的关键词，而引入Embedding之后，搜索结果甚至能够捕捉到搜索词的语义信息。例如，输入France Skiing(法国滑雪)，虽然结果中没有一个地点名带有Skiing这个关键词，但联想结果中都是法国的滑雪胜地，这无疑是更接近用户动机的结果。

#### Airbnb的实时搜索排序模型及特征工程

上面介绍了Airbnb 对用户短期和长期兴趣进行用户和房源Embedding的方法，需要强调的是，Airbnb并没有直接把Embedding相似度排名当作搜索结果，而是基于Embedding得到了不同的用户房源相关特征(user-listing pair feature) ，然后输入搜索排序模型，得到最终的排序结果。
那么 Airbnb 基于 Embedding 生成了哪些特征呢? 这些特征又是如何驱动搜索结果的“实时”个性化的呢?表8-4中列出了基于Embedding的所有特征。

![AI7](https://sunjc911.github.io/assets/images/DeepRec/AI7.png)

可以很清楚地看出，最后一个特征UserTypeListingTypeSim指的是用户属性和房源属性的相似度。该特征相似度就是使用user type和listing type的长期兴趣Embedding计算得到的。除此之外，其他特征都适用于短期兴趣 Embedding。例如，EmbClickSim指的是候选房源与用户最近点击过的房源的相似度。
细心的读者可能会有一个疑问-Airbnb强调的“实时”系统中的“实时”到底体现在哪儿?其实通过上面的特征设计就可以给出这个问题的答案了。在这些 Embedding 相关的特征中，Airbnb 加入了“最近点击房源的相似度(EmbClickSim) ”“最后点击房源的相似度(EmbLastLongClickSim)”这类特征。由于这类特征的存在，用户在点击浏览的过程中就可以得到实时的反馈，搜索结果也可以实时地根据用户的点击行为而改变。
在得到这些Embedding特征之后，会将Embedding类特征与其他特征一起输入搜索排序模型进行训练。这里，Airbnb采用的搜索排序模型是一个支持Pairwise Lambda Rank的GBDT模型[4]，并已由Airbnb的工程师开源。最后，表8-5所示为Airbnb对各特征重要度的评估结果，供读者参考。

![AI8](https://sunjc911.github.io/assets/images/DeepRec/AI8.png)

#### Airbnb实时搜索推荐系统总结

1.工程与理论结合得极佳
通过对经典的 Word2vec 方法进行改造，完成对用户和房源的 Embedding，并针对数据稀疏的问题，利用用户属性和房源属性聚合稀疏数据，这些极具实践价值的方法是算法工程师应该学习的思路。
2.业务与知识结合得极佳
在对 Embedding 目标函数的改造过程中，不止一次引入了与业务强相关的目标项，使算法的改造与公司业务和商业模型紧密结合，这往往是很多学术导向的算法工程师缺乏的能力。

### YouTube深度学习视频推荐系统

Deep Neural Networks for YouTube Recommenders

#### 应用场景

作为全球最大的视频分享网站，YouTube 平台中几乎所有的视频都来自UGC，这样的内容产生模式有两个特点。
(1) 商业模式不同。Netflix和国内的爱奇艺等流媒体，它们的大部分内容都是采购或自制的电影、剧集等头部内容，YouTube内容的头部效应没有那么明显。
(2) 由于YouTube的视频基数巨大，用户较难发现喜欢的内容。
YouTube内容的特点使推荐系统的作用相比其他流媒体重要得多。除此之外，YouTube的**利润来源主要来自视频广告，而广告的曝光机会与用户观看时长成正比**，因此YouTube推荐系统正是其商业模式的基础。
基于 YouTube 的商业模式和内容特点，其推荐团队构建了两个深度学习网络，分别**考虑召回率和准确率的要求，并构建了以用户观看时长为优化目标的排序模型，最大化用户观看时长，进而产生更多的广告曝光机会，**下面详细介绍YouTube推荐系统的模型结构和技术细节。

#### 推荐系统架构

前面已经提到YouTube视频基数巨大，这要求其推荐系统能在百万量级的视频规模下进行个性化推荐。考虑到在线系统的延迟问题，不宜用复杂网络直接对所有海量候选集进行排序，所以YouTube采用**两级深度学习模型完成整个推荐**过程(如图8-14所示)。

![YB](https://sunjc911.github.io/assets/images/DeepRec/YB.png)

第一级用候选集生成模型 (Candidate Generation Model) 完成候选视频的快速筛选，在这一步，候选视频集合由百万量级降至几百量级。这相当于经典推荐系统架构中的召回层。
第二级用排序模型!(Ranking Model) 完成几百个候选视频的精排。这相当于经典推荐系统架构中的排序层

#### 候选集生成模型

首先，介绍候选集生成模型的架构(如图8-15所示) 。自底而上地看这个网络，底层的输入是用户历史观看视频Embedding向量和搜索词Embedding向量。
为了生成视频 Embedding 和搜索词 Embedding，YouTube 采用的方法同 8.2节介绍的Airbnb Embedding 方法相似，利用用户的观看序列和搜索序列，采用Word2vec方法对视频和搜索词做Embedding，再作为候选集生成模型的输入，具体做法可以参考 8.2 节中 Aibnb 对房源进行 Embedding 的过程。除了进行预先Embedding，还可以直接在深度学习网络中增加 Embedding 层，与上层的 DNN一起进行端到端训练，两种方法孰优孰劣，4.5节已经讨论过。

![YB1](https://sunjc911.github.io/assets/images/DeepRec/YB1.png)

除了视频和搜索词Embedding向量，特征向量中还包括用户的地理属性特征Embeddin年龄、性别等。然后把所有特征连接起来，输入上层的 ReLU 神经网络进行训练。

三层神经网络过后，使用 softmax 函数作为输出层。读者**看到 softmax 函数就应知道该模型是一个多分类模型**。YouTube是把选择候选视频集这个问题看作用户推荐next watch(下一次观看视频)的问题，模型的最终输出是一个在所有候选视频上的概率分布，显然这是一个多分类问题，所以这里用 softax作为最终的输出层。
总的来讲，YouTube 推荐系统的候选集生成模型是一个标准的利用Embedding预训练特征的深度神经网络模型

#### 候选集生成模型独特的线上服务方法

细心的读者可能已经发现，架构图 8-15 左上角的模型服务方法与模型训练方法完全不同。在候选集生成网络的线上服务过程中，YouTube并没有直接采用训练时的模型进行预测，而是采用了一种最近邻搜索的方法，这是一个经典的工程和理论做权衡的结果。

具体来讲，在模型服务过程中，如果对每次推荐请求都端到端地运行一遍候选集生成网络的推断过程，那么由于网络结构比较复杂，参数数量特别是输出层的参数数量非常巨大，整个推断过程的开销会很大。因此，在通过“候选集生成模型”得到用户和视频的Embedding后，通过Embedding最近邻搜索的方法进行模型服务的效率会高很多。这样甚至不用把模型推断的逻辑搬上服务器，只需将用户Embedding和视频Embedding存到Redis等内存数据库或者服务器内存中就好。如果采用4.6节介绍的局部敏感哈希等最近邻搜索的方法，那么甚至可以把模型服务的计算复杂度降至常数级别。这对百万量级规模的候选集生
成过程的效率提升是巨大的。如果继续深挖，还能得到非常有意思的信息。架构图中从 softmax向模型服务模块画了个箭头，代表视频 Embedding 向量的生成。这里的视频 Embedding是如何生成的呢?由于最后的输出层是softmax，该softmax层的参数本质上是一个mxn维的矩阵，其中m指的是最后一层(ReLU层)的维度，n指的是分类的总数，也就是YouTube所有视频的总数为n。那么视频Embedding就是这个mxn维矩阵的各列向量。这样的 Embedding生成方法其实
和Word2vec中词向量的生成方法相同。除此之外，用户向量的生成就非常好理解了，因为输入的特征向量全部都是用户相关的特征，所以在使用某用户  的特征向量作为模型输入时，最后一层ReLU层的输出向量可以当作该用户的Embedding向量。在模型训练完成后，逐个输入所有用户的特征向量到模型中，就可以得到所有用户的 Embedding向量，之后导入线上Embedding数据库。在预测某用户的视频候选集时，先得到该用户的Embedding向量，再在视频Embedding向量空间中利用局部敏感哈希等方法搜索该用户Embedding向量的Top K近邻，就可以快速得到k个候选视频集合。

#### 排序模型

通过候选集生成模型，得到几百个候选视频集合，然后利用排序模型进行精排序，YouTube推荐系统的排序模型如图5-9所示。
第一眼看上去，读者可能会认为排序模型的网络结构与候选集生成模型没有太大区别在模型结构上确实是这样的，这里需要重点关注模型的输入层和输出层，即排序模型的特征工程和优化目标。
相比候选集生成模型需要对几百万候选集进行粗筛，排序模型只需对几百个候选视频进行排序，因此可以引入更多特征进行精排。具体地讲，输入层从左至右的特征依次是:
(1)当前候选视频的Embedding (impression video ID embedding)。
(2) 用户观看过的最后 N 个视频 Embedding 的平均值(watched video IDs average embedding)。
(3)用户语言的 Embedding 和当前候选视频语言的 Embedding (language embedding
(4) 该用户自上次观看同频道视频的时间 (time since last watch)
(5) 该视频已经被曝光给该用户的次数 ( #previous impressions)
上面5个特征中，前3个的含义是直观的，这里重点介绍第4个和第5个特征。因为这两个特征很好地引入了YouTube对用户行为的观察。

![YB2](https://sunjc911.github.io/assets/images/DeepRec/YB2.png)

第4个特征time since last watch表达的是用户观看同类视频的间隔时间。从用户的角度出发，假如某用户刚看过“DOTA比赛经典回顾”这个频道的视频，那么用户大概率会继续看这个频道的视频，该特征很好地捕捉到了这一用户行为。
第5个特征# previous impressions则在一定程度上引入了5.7节介绍的“探索与利用”机制，避免同一个视频对同一用户的持续无效曝光，尽量增加用户看到新视频的可能性。需要注意的是，**排序模型不仅针对第4个和第5个特征引入了原特征值，还进行了平方和开方的处理。作为新的特征输入模型，这一操作引入了特征的非线性，提升了模型对特征的表达能力。**

经过三层ReLU网络之后，排序模型的输出层与候选集生成模型又有所不同。候选集生成模型选择softmax作为其输出层，而排序模型选择加权逻辑回归作为模型输出层。与此同时，模型服务阶段的输出层选择的是 e(wx+b) 函数。YouTube为什么分别在训练和服务阶段选择了不同的输出层函数呢?
从YouTube的商业模式出发，增加用户观看时长才是其推荐系统最主要的优化目标，所以在训练排序模型时，每次曝光期望观看时长 (expected watch time per impression)应该作为更合理的优化目标。因此，为了能直接预估观看时长，YouTube将正样本的观看时长作为其样本权重，用加权逻辑回归进行训练，就可以让模型学到用户观看时长的信息。假设一件事情发生的概率是p，这里引入一个新的概念--Odds(机会比)，它指件事情发生和不发生的比值。
对逻辑回归来说，一件事情发生的概率p由sigmoid函数得到，如(式8-9) 所示:

![YB3](https://sunjc911.github.io/assets/images/DeepRec/YB3.png)

可以看出，变量 Odds 本质上的物理意义就是每次曝光期望观看时长，这正是排序模型希望优化的目标。因此，利用加权逻辑回归进行模型训练，利用eWx+b进行模型服务是最符合优化目标的技术实现。

#### 训练和测试样本的处理

事实上，为了能够提高模型的训练效率和预测准确率，YouTube采取了诸多处理训练样本的工程措施，主要有以下3点经验供读者借鉴。
(1) 候选集生成模型把推荐问题转换成多分类问题，在预测下一次观看的场景中每一个备选视频都会是一个分类，因此总共的分类有数百万之巨，使用softmax对其进行训练无疑是低效的，这个问题YouTube是如何解决的呢?
YouTube 采用了 **Word2vec 中常用的负采样训练方法减少了每次预测的分类数量，从而加快了整个模型的收敛速度**，具体的方法在4.1节已经有所介绍。此外，YouTube也尝试了Word2vec另一种常用的训练方法hierarchical softax (分层softmax)，但并没有取得很好的效果，因此在实践中选择了更为简便的负采样方法。
(2) 在对训练集的预处理过程中，YouTube没有采用原始的用户日志，而是对每个用户提取等数量的训练样本，这是为什么呢?
YouTube这样做的目的是**减少高度活跃用户对模型损失的过度影响，使模型过于偏向活跃用户的行为模式，忽略数量更广大的长尾用户的体验**。
(3)在处理测试集的时候，YouTube为什么不采用经典的随机留一法(random holdout)，而是一定要以用户最近一次观看的行为作为测试集呢?
**只留最后一次观看行为做测试集主要是为了避免引入未来信息 (future information)，产生与事实不符的数据穿越问题。**
可以看出，YouTube对于训练集和测试集的处理过程也是基于对业务数据的观察理解的，这是非常好的工程经验。

#### 如何处理用户对新视频的偏好

对 UGC 平台来说，用户对新内容的偏好很明显。对绝大多数内容来说，刚上线的那段时间是其流量高峰，然后快速衰减，之后趋于平稳(如图 8-16 中绿色曲线所示)。YouTube 的内容当然也不例外，因此，能否处理好用户对新视频的偏好直接影响了预测的准确率。

![YB4](https://sunjc911.github.io/assets/images/DeepRec/YB4.png)

为了拟合用户对新内容的偏好，YouTube推荐系统引入了Example Age这个特征，该特征的定义是**训练样本产生的时刻距离当前时刻的时间**。例如，24小时前产生的训练样本，Example Age的特征值就是24。在做模型服务的时候，不管候选视频是哪个，可以直接将这个特征值设成0，甚至是一个很小的负值，因为这次的训练样本将在不久的未来产生这次推荐结果的时候实际生成。
YouTube选择这样一个时间特征来反映内容新鲜程度的逻辑并不容易理解，读者可以仔细思考这个做法的细节和动机。笔者对这个特征的理解是: **该特征本身并不包含任何信息，但当该特征在深度神经网络中与其他特征做交叉时，就起到了时间戳的作用，通过这个时间戳和其他特征的交叉，保存了其他特征随时间变化的权重，也就让最终的预测包含了时间趋势的信息。**
YouTube通过试验验证了Example Age特征的重要性，图8-16中蓝色曲线是引入 Example Age 前的模型预估值，可以看出与时间没有显著关系，而引入Example Age后的模型预
估十分接近经验分布。
通常“新鲜程度”这一特征会定义为视频距离上传时间的天数(Days since Upload)比如虽然是24小时前产生的样本，但样本的视频已经上传了90小时，该特征值就应是90。那么在做线上预估时，这个特征的值就不会是0，而是当前时间与每个视频上传时间的间隔。这无疑是一种保存时间信息的方法，YouTube显然没有采用这种方法，笔者推测该方法效果不好的原因是这种做法会导致Example Age的分布过于分散，在训练过程中会包含刚上传的视频，也会包含上传已经1年，甚至5年的视频，这会导致Example Age无法集中描述近期的变化趋势。当然，推荐读者同时实现这两种做法，并通过效果评估得出最终的结论。

#### YB视频推荐系统总结

实践内容最丰富的一篇工程导向的推荐系统论文。**强烈建议看论文搞细节。**

### 阿里巴巴深度学习推荐系统的进化

LS-PLM、DIN、DIEN、MIMN

#### 应用场景

阿里巴巴的应用场景读者可能比较熟悉，无论是天猫还是淘宝，阿里巴巴推荐系统的主要功能是根据**用户的历史行为、输入的搜索词及其他商品和用户信息，在网站或App的不同推荐位置为用户推荐感兴趣的商品。**
在解决推荐问题时，熟悉场景中的细节要素和用户操作的不同阶段是重要的。例如，某用户希望在天猫中购买一个“无线鼠标”，从登录天猫到购买成功，一般需要经历以下几个阶段 (图8-17展示了用户搜索“无线鼠标”时的推荐结果)。

(1) 登录。
(2) 搜索
(3) 浏览
(4) 点击。
(5) 加入购物车。
(6) 支付。
(7) 购买成功。
每一步都存在着用户的流失，又以“**浏览-点击”，“点击-加入购物车”最为关键。**那么到底应该为这两个阶段的行为单独建立CTR模型和CVR模型，还是统一建模呢? 5.4节介绍的多目标优化模型ESMM[10]给出了阿里巴巴技术人员对这个问题的思考

在推荐过程中，可利用的商品信息是多样的，既有文本类的描述信息，又有数字类的价格、购买量等信息，还有不可忽视的商品图片信息，这么多“模态”的信息在一起，如何更好地驱动推荐引擎呢?阿里巴巴技术团队在多模态 CTR模型一文中 ( Image Matters: Visually modeling user behaviors using Advanced Model Server[11]) 给出了解决方案除此之外，在推荐系统主模型的迭代过程中，从最开始的LS-PLM到基础深度学习模型，再到引入了注意力机制的DIN及后续进化版本DIEN，以及MIMN，阿里巴巴一直进行着推荐模型的快速迭代升级。

#### 阿里巴巴的推荐模型体系

![AL](https://sunjc911.github.io/assets/images/DeepRec/AL.png)

#### 阿里深度学习推荐模型的进化过程

不谈阿里巴巴在前深度学习时代的推荐模型 LS-PLM (2.7 节已经详细介绍了其原理其深度学习推荐模型演化的4个阶段。
1.基础深度学习模型
基于经典的 Embedding+MLP 深度学习模型架构，将用户行为历史的Embedding简单地通过加和池化操作叠加，再与其他用户特征、广告特征、场景特征连接后输入上层神经网络进行训练，模型结构如图8-19 (a) 所示。

2.DIN模型
利用注意力机制替换基础模型的Sum Pooling操作，根据候选广告和用户历史行为之间的关系确定每个历史行为的权重，模型结构如图8-19 (b) 所示。

3.DIEN模型
在DIN的基础上，进一步改进对用户行为历史的建模，使用序列模型在用户行为历史之上抽取用户兴趣并模拟用户兴趣的演化过程，模型结构如图8-19 (c) 所示。

4.MIMN模型

在DIEN的基础上，将用户的兴趣细分为不同兴趣通道，进一步模拟用户在不同兴趣通道上的演化过程，生成不同兴趣通道的记忆向量，再利用注意力机制作用于多层神经网络，模型结构如图8-19 (d) 所示。

![AL1](https://sunjc911.github.io/assets/images/DeepRec/AL1.png)

阿里巴巴推荐模型进化过程的重点在于对**用户历史行为**的利用。一方面，用户历史行为确实在推荐中扮演着至关重要的作用:另一方面，得益于阿里巴巴极高的数据质量，其在电商领域的领先地位决定了它的数据能够保存大部分用户的购买兴趣特征，从而有效地对其建模。图 8-20 所示为某女性用户的购买历史。这个例子(每个图片代表该用户购买过的一个商品) 很好地解释了阿里巴巴不同推荐模型对用户行为的建模原理

![AL2](https://sunjc911.github.io/assets/images/DeepRec/AL2.png)

图8-20(a) 是基础深度学习模型对待用户行为的办法，即一视同仁，不分重点;从图 8-20()中可以看出，每个商品开始有了一个用进度条表示的权重，这个权重是基于该商品与候选商品的关系，通过注意力机制学习出来的。这就让模型具备了有重点地看待不同用户行为的能力;图8-20 (c) 中的用户行为有了时间维度，行为历史按照时间轴被排列成了一个序列，DIEN 模型开始考虑用户行为和用户兴趣随时间变化的趋势，这让模型真正具备了下次购买的预测能力: 图 8-20 (d) 中的用户行为不仅被排成了序列，而且根据商品种类的不同被排列成了多个序列，这使得 MIMN 模型开始对用户多个“兴趣通道”进行建模，更精准地把握用户的兴趣变迁过程，避免不同兴趣之间相互干扰。可以看到，阿里巴巴推荐模型抓住了“用户兴趣”这个关键点进行了数次改进，整个改进过程让模型对用户兴趣的理解越来越精准，进而让模型的效果越来越好。从各模型在淘宝数据集和亚马逊数据集的 AUC 表现(如表 8-6 所示) 来看，阿里巴巴针对用户兴趣对模型的改进是成功的。

![AL3](https://sunjc911.github.io/assets/images/DeepRec/AL3.png)

#### 模型服务模块的技术架构

针对复杂模型，模型服务一直是业界的难点。使用一些近似的手段简化模型，会让模型效果受损:端到端地将复杂模型搬到线上，使服务的延迟率居高不下，影响用户体验。这一两难的问题同样困扰着阿里巴巴的工程师。对于 DIEN 和MIMN这类带有序列结构的模型来说，这个问题尤为突出，**因为模型中的序列结构意味着串行的推断过程，模型无法被并行加速，使得模型服务成了整个推荐过程的瓶颈。**
那么，如何解决这个棘手的问题的呢? MIMN的论文原文公开了相关的解决方案(如图8-21所示)。

![AL4](https://sunjc911.github.io/assets/images/DeepRec/AL4.png)

图8-21 (a) 和(b) 分别代表了两种不同的模型服务架构，两图中部横向的虚线代表了在线环境和离线环境的分隔。两种架构的区别主要在于左部处理用户行为事件的方法有以下两点主要区别:

1.用户兴趣表达模块
b架构将a架构的“用户行为特征 (User Behavior Features) 在线数据库”替换成了“用户兴趣表达(User Interest Representation) 在线数据库”。这一变化对模型推断过程非常重要。无论是DIEN还是MIMN，它们表达用户兴趣的最终形式都是兴趣Embedding向量。如果在线获取的是用户行为特征序列，那么对实时预估服务器(Real-time Prediction Server)来说，还需要运行复杂的序列模型推断过程生成用户兴趣向量。如果在线获取的是用户兴趣向量，那么实时预估服务器就可以跳过序列模型阶段，直接开始MLP阶段的运算。MLP的层数相较序列模型大大减少，而且便于并行计算，因此整个实时预估的延迟可以大幅减少。
2.用户兴趣中心模块b架构增加了一个服务模块一-用户兴趣中心 (User Interest Center，UIC) 。UIC用于根据用户行为序列生成用户兴趣向量，对DIEN和MIMN来说，UIC运行着生成用户兴趣向量的部分模型。与此同时，实时用户行为事件(realtime user behavior event) 的更新方式也发生着变化，对a架构来说，一个新的用户行为事件产生时，该事件会被插入用户行为特征数据库中，而对b架构来说，新的用户行为事件会触发 VIC 的更新逻辑，UIC 会利用该事件更新对应用户的兴趣Embedding向量。

在理解了用户兴趣表达模块和 UIC 的作用之后，其他模块的作用在 a 和 b架构中是基本一致的，其离线部分和在线部分的运行逻辑如下:

离线部分:学习模块 (Learner) 定期利用系统日志 (Logs) 训练并更新模型 (Model模型更新之后，新模型在 a 架构中被直接部署在实时预估服务器中，而b 架构则对模，型进行拆分，生成用户兴趣向量的部分(图 8-21 (b) 左侧部分) 部署在UIC，其余部分(图8-21 (b) 右侧灰色部分) 部署在实时预估服务器。
在线部分:在线部分的运行流程如下。
(1) 流量请求 (traffic request) 到来，其中携带了用户ID (User ID) 和待排序的候选商品ID (Ad ID)。
(2) 实时预估服务器根据用户 ID 和候选商品 ID 获取用户和商品特征(Ad Features，用户特征具体包括用户的人口属性特征(User Demography Features) 和用户行为特征
(a架构) 或用户兴趣表达向量 (b架构)。(3) 实时预估服务器利用用户和商品特征进行预估和排序，返回最终排序结果给请求方。
b架构对最耗时的序列模型部分进行了拆解，因此大幅降低了模型服务的总延迟，根据阿里巴巴公开的数据，每个服务节点在500 OPS (Oueries Per Second，每秒查询次数)的压力下，DIEN模型的预估时间从200毫秒降至19毫秒。这无疑是从工程角度优化模型服务过程的功劳。
熟悉之前章节的读者肯定也联想到了6.5节介绍的深度学习推荐模型线上部署方法。事实上，a架构本质上采用了 TensorFlow Serving 或自研模型这种端到端的部署方案，而 b架构则采用了 Embedding+轻量级线上模型的部署方案。阿里巴巴的实践给这几种线上部署方案提供了最好的案例。

#### 阿里技术总结

1.工程实践性很强

工程实践性强的文章有两个特点，一是**应用场景来源于实际，二是解决问题的方案更容易落地**。这得益于阿里巴巴得天独厚的业务和数据环境，再加上有优秀工程师的持续输出，让我们看到很多“实践出真知”的解决方案。
2.对用户行为的观察非常精准

在改进推荐系统的过程中，只有将**用户的行为和习惯揣摩到位**，才能以此出发，从技术上映射用户的习惯。DIN、DIEN、MIMN等一系列针对用户兴趣的推荐模型，精准地抓住了用户的行为习惯，这样的工作是细致且有效的。
3.模型的微创新
从低维到高维是创新，从离散到连续是创新，从单一到融合也是创新，阿里巴巴的一系列模型将在自然语言处理领域大行其道的注意力机制、序列模型引入推荐领域，是另一种典型且**有效的创新**手段。除此之外，每次模型的迭代更新都不是推倒重建，而是**基于之前模型的微创新**，这往往是一个成熟团队进行高效技术迭代的成果。

## 第九章 构建属于你的推荐系统知识框架

本章是本书的最后一章，在结束了所有推荐系统技术细节的讨论之后，希望读者能够可到推荐系统架构上来，从更高的角度俯瞰推荐系统整体的知识框架。
笔者在第1章描述推荐系统的技术架构图时曾提到，读者可以暂时忽略技术架构图中的细节，仅留一个框架在心中，随着不同模块的技术细节逐渐在具体的章节中展开，相信每位读者都会以自己的方式逐一填充心中的技术架构图。
针对某一领域，构建属于自己的知识框架是最重要的，只有建立了知识框架，才能在这个框架的基础上查漏补缺，开枝散叶;只有建立了知识框架，在思考领域相关问题时才能见微知著，深入细节而不忘整体。希望本书为你带来的不仅是解决推荐系统技术问题的
具体方法，而是行业内有一定高度的技术格局。本章将通过3种方式回顾本书的所有技术内容，建立它们之间的逻辑联系9.1 节将在第 1 章推荐系统技术架构图的基础上，进一步主富技术细节，形成最终的“推荐系统整体知识架构图”。
9.2节针对架构图中最核心的推荐模型部分，以时间线的方式回顾模型发展，特别是深度学习模型发展进化的过程。
9.3 节将从推荐系统算法工程师的角度，谈一谈合格的推荐系统算法工程师应该具备的核心素质。

### 推荐系统的整体知识架构图

![91](https://sunjc911.github.io/assets/images/DeepRec/91.png)

**读者可以把该图当作全书的技术索引，看到图中的每个模块，甚至每一个名词就能回忆起相应技术要点的细节**。在打仗时，将军常说“不谋全局者，不足谋一域”，虽然工程师的职责可能不如将军重要，但心中也不可缺少技术系统的“全局”，只有有了“全局”，才能在管理“一域”时找到最佳的解决方案，做到真正的全局最优。

### 推荐模型发展的时间线

![92](https://sunjc911.github.io/assets/images/DeepRec/92.png)

### 如何成为一名优秀的推荐工程师

作为一名推荐工程师，笔者希望与读者探讨优秀的推荐工程师应具备哪些基本素质。作为一名推荐工程师，所擅长的**不应仅仅是机器学习相关知识，更应该从业务实践的角度出发，提升自己各方面的能力**。

#### 推荐工程师的4项能力

知识、工具、逻辑、业务

![93](https://sunjc911.github.io/assets/images/DeepRec/93.png)

简单来说，任何推荐系统相关的工程师都应该满足4项技能的最小要求，因为在成为名“优秀”的推荐工程师之前，首先应该是一名合格的工程师。不仅应具有领域相关的知识，还应具有把知识转换成实际系统的能力。一位笔者面试的推荐工程师职位候选人曾发表过一些机器学习相关的论文和专利，从领域“知识”的角度看，他是不错的人选，但当验证他的工程能力时，他明确表示不愿意写代码。也许当时不愿意写代码另有隐情，但对面试官来说，这位候选人使用“工具”的能力无法被验证，他的能力可能严重“偏科”，自然不是一名合格的推荐工程师。在笔者看来，推荐系统相关的从业者应该具备的最小能力要求如下:
知识: 具备基本的推荐系统领域相关知识。
·工具:具备编程能力，了解推荐系统相关的工程实践工具

**逻辑:具备算法基础，思考的逻辑性、条理性较强。**

业务:对推荐系统的业务场景有所了解。在最小要求的基础上，不同岗位对能力的要求也有所不同。结合图9-3所示的技能雷达，不同岗位的能力特点如下:
。算法工程师:算法工程师的能力要求是相对全面的。作为算法模型的实现者和应用者，要求算法工程师有扎实的机器学习基础，改进和实现算法的能力，对工具的运用能力及对业务的洞察。
·大数据工程师:更注重大数据工具和平台的改进，需要维护推荐系统相关的整个数据链路，因此对运用工具的能力要求最高。
·算法研究员:担负着提出新算法、新模型结构等研究任务，因此对算法研究员的知识和逻辑能力的要求最高。
·能力“偏科”的工程师:有些读者平时不注重对工具使用、业务理解方面的知识积累找工作时临时抱佛脚恶补知识、刷算法题，在一些面试场合下也许是奏效的，但要想成为一名优秀的推荐工程师，还需要补齐自己的能力短板。
当然，只用“知识”“工具”“逻辑”“业务”这 4 个词描述荐工程师所需的能力过于形而上，接下来具体解释这4个技能。
· 知识: 主要指推荐系统相关知识和理论的储备，比如**主流的推荐模型、Embedding的主要方法**等。
工具:运用工具将推荐系统的知识应用于实际业务的能力，推荐系统相关的工具主要包括 **TensorFlow、PyTorch** 等模型训练工具，**Spark、Flink** 等大数据处理工具，以及些模型服务相关的工具。

·逻辑:举一反三的能力，解决问题的条理性，发散思维的能力，聪明程度，通用算法的掌握程度。
·业务:理解推荐系统的应用场景、商业模式;从业务中发现用户动机，制定相应的优化目标并改进模型算法的能力。
请读者根据自己的具体岗位、具体项目有针对性地学习相关技能

#### 能力的深度和广度

在一项具体的工作面前，优秀的推荐工程师所具备的能力应该是综合的一一能够从“深度”和“广度”两个方面提供解决方案。例如，公司希望改进目前的推荐模型，于是你提出了以DIN为主要结构的模型改进方案。这就要求你在深度和广度两个方面对DIN的原理和实现方案有全面的了解。
深度方面，需要了解从模型动机到实现细节的一系列问题，一条从概括到具体的学习路径的例子如下:
·DIN 模型提出的动机是什么?是否适合自己公司当前的场景和数据特点。(业务理解能力。)
·DIN 模型的模型结构是什么? 具体实现起来有哪些工程上的难点。(知识学习能力工具运用能力。)

DIN 模型强调的注意力机制是什么?为什么在推荐系统中使用注意力机制能够有效果上的提升?(业务理解能力，知识学习能力。)
DIN模型将用户和商品进行了Embedding，在实际使用中，应该如何实现Embedding过程? (知识学习能力，逻辑思维能力。)
·是通过改进现有模型实现 DIN 模型，还是使用全新的离线训练方式训练DIN模型?(工具运用能力，逻辑思维能力。)
线上部署和服务 DIN 模型有哪些潜在问题，有哪些解决方案? (工具运用能力。)从这个例子中读者可以看到，一套完备的模型改进方案的形成需要推荐工程师深入了解新模型的细节。缺少了深度的钻研，改进方案就会在实现过程中遇到方向性的错误，增
加纠错成本。
推荐工程师除了要深入了解所采用技术方案的细节，还需要在广度上了解各种可能的备选方案的优劣，做到通过综合权衡得出当前客观环境下的最优解。接着上文模型改进的例子，推荐工程师应该从以下方面在广度上进行知识储备:
与DIN类似的模型有哪些，是否适合当前的使用场景?
·DIN 模型使用的 Embedding 方法有哪些，不同 Embedding 方法的优劣是什么?
·训练和上线DIN的技术方案有哪些? 如何与自己公司的技术栈融合?在深度了解了一个技术方案的前提下，对其他方向的了解可以是概要式的，但也要清楚每种技术方案的要点和特点，必要时可通过A/B测试、业界交流咨询、原型系统试验等
方式排除候选方案，确定目标方案。除此之外，6.6 节提到的工程和理论之间的权衡能力也是推荐工程师不可或缺的技能点之一。只有具备了这一点，才能在现实和理想之间进行合理的妥协，完成成熟的技术方案。

#### 能力总结

想要成为一名优秀的推荐工程师，甚至一名优秀的算法工程师，应该在“知识”“工具”“逻辑”“业务”这 4 个方面综合提高自己的能力，对某一技术方案应该有“深度”和“广度”上的技术储备，在客观技术环境的制约下，针对问题做出权衡和取舍，最终得出可行且合理的技术方案。

## 后记

推荐工程师是一份挣扎在随时被淘汰边缘的工作